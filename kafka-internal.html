<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2021-06-28 Mon 11:43 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>kafka-internal</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="harrifeng@outlook.com" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/src/readtheorg_theme/js/readtheorg.js"></script>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
</head>
<body>
<div id="content">
<h1 class="title">kafka-internal</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgaf86151">1. 第一章: 初识Kafka</a>
<ul>
<li><a href="#orgeb0d460">1.1. 基本概念</a></li>
<li><a href="#org9b1c687">1.2. 安装与配置</a>
<ul>
<li><a href="#orgff75a0e">1.2.1. 安装JAVA环境</a></li>
<li><a href="#org6b1f9c7">1.2.2. 配置ZooKeeper</a></li>
<li><a href="#org8830bca">1.2.3. Kafka的安装与配置</a></li>
</ul>
</li>
<li><a href="#org22d1c81">1.3. 生产与消费</a></li>
<li><a href="#org948980f">1.4. 服务端参数配置</a>
<ul>
<li><a href="#orgf2b15ea">1.4.1. zookeeper.connect</a></li>
<li><a href="#orge32a0c4">1.4.2. listeners</a></li>
<li><a href="#org704d6f8">1.4.3. broker.id</a></li>
<li><a href="#org504f71a">1.4.4. log.dir和log.dirs</a></li>
<li><a href="#org72204e5">1.4.5. message.max.bytes</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org50d6e22">2. 第二章 生产者</a>
<ul>
<li>
<ul>
<li><a href="#org1b5cbae">2.0.1. 客户端开发</a></li>
<li><a href="#orgb0c08e1">2.0.2. 必要的参数配置</a></li>
<li><a href="#orgfd13fd2">2.0.3. 消息的发送</a></li>
<li><a href="#orgb0d97a8">2.0.4. 序列化</a></li>
<li><a href="#org991871f">2.0.5. 分区器</a></li>
<li><a href="#orga8947e1">2.0.6. 生产者拦截器</a></li>
</ul>
</li>
<li><a href="#org661a995">2.1. 原理分析</a>
<ul>
<li><a href="#org8730dc3">2.1.1. 整体架构</a></li>
<li><a href="#orgbe2c046">2.1.2. 元数据的更新</a></li>
</ul>
</li>
<li><a href="#org5f75196">2.2. 重要的生产者参数</a>
<ul>
<li><a href="#org18e226a">2.2.1. acks</a></li>
<li><a href="#org9c81309">2.2.2. max.request.size</a></li>
<li><a href="#orgbee58d9">2.2.3. retries和retry.backoff.ms</a></li>
<li><a href="#org4f9b488">2.2.4. compression.type</a></li>
<li><a href="#org56312c8">2.2.5. connections.max.idle.ms</a></li>
<li><a href="#org6f0c39a">2.2.6. linger.ms</a></li>
<li><a href="#orgd5aefde">2.2.7. receive.buffer.bytes</a></li>
<li><a href="#orga61382a">2.2.8. send.buffer.byts</a></li>
<li><a href="#orgb8f5df5">2.2.9. request.timeout.ms</a></li>
</ul>
</li>
<li><a href="#orgbde597e">2.3. 其他常见参数意义</a></li>
</ul>
</li>
<li><a href="#orgd52857c">3. 第三章 消费者</a>
<ul>
<li><a href="#org042d537">3.1. 消费者与消费组</a></li>
<li><a href="#org05ad1aa">3.2. 客户端开发</a>
<ul>
<li><a href="#orgef440ce">3.2.1. 必要的参数设置</a></li>
<li><a href="#orgf7cb8d6">3.2.2. 订阅主题与分区</a></li>
<li><a href="#org8d81869">3.2.3. 反序列化</a></li>
<li><a href="#orgb8a5fa7">3.2.4. 消息消费</a></li>
<li><a href="#org1c7daa3">3.2.5. 位移提交</a></li>
<li><a href="#org622e5a8">3.2.6. 控制或关闭消费</a></li>
<li><a href="#org2d6a2cc">3.2.7. 指定位移消费</a></li>
<li><a href="#org1e2b570">3.2.8. 再均衡</a></li>
<li><a href="#org255854e">3.2.9. 消费者拦截器</a></li>
<li><a href="#orgbee25aa">3.2.10. 多线程实现</a></li>
<li><a href="#org618508b">3.2.11. 重要的消费者参数</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org024fe1b">4. 第四章 主题与分区</a>
<ul>
<li><a href="#org87ce8ee">4.1. 主题的管理</a>
<ul>
<li><a href="#orgbc1d3e8">4.1.1. 创建主题</a></li>
<li><a href="#orge97186f">4.1.2. 分区副本的分配</a></li>
<li><a href="#org9165994">4.1.3. 查看主题</a></li>
<li><a href="#orgc4ceb2c">4.1.4. 修改主题</a></li>
<li><a href="#org163681c">4.1.5. 配置管理</a></li>
<li><a href="#orga927c9e">4.1.6. 主题端参数</a></li>
<li><a href="#org2ca0330">4.1.7. 删除主题</a></li>
</ul>
</li>
<li><a href="#orgfe16065">4.2. 初识KafkaAdminClient</a>
<ul>
<li><a href="#org9d0239c">4.2.1. 基本使用</a></li>
</ul>
</li>
<li><a href="#org624b7a3">4.3. 分区的管理</a>
<ul>
<li><a href="#org21a9ab2">4.3.1. 优先副本的选举</a></li>
<li><a href="#org3d3837b">4.3.2. 分区重新分配</a></li>
<li><a href="#orgbb25dd8">4.3.3. 复制限流</a></li>
<li><a href="#orgc353262">4.3.4. 修改副本因子</a></li>
</ul>
</li>
<li><a href="#orgd38a69b">4.4. 如何选择合适的分区数</a>
<ul>
<li><a href="#orga1e2090">4.4.1. 性能测试工具</a></li>
<li><a href="#orge7b7778">4.4.2. 分区数的上限</a></li>
<li><a href="#orgd683b49">4.4.3. 考量因素</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orga50dd59">5. 第五章: 日志存储</a>
<ul>
<li><a href="#orgaa8a192">5.1. 文件目录布局</a></li>
<li><a href="#org81446a1">5.2. 日志格式的演变</a>
<ul>
<li><a href="#org96b82e3">5.2.1. v0版本</a></li>
<li><a href="#org4ab3d50">5.2.2. V1版本</a></li>
<li><a href="#orgba0129f">5.2.3. V2版本</a></li>
<li><a href="#org225c57b">5.2.4. 消息压缩</a></li>
<li><a href="#org3ce504c">5.2.5. 变长字段</a></li>
</ul>
</li>
<li><a href="#orgaf593bc">5.3. 日志索引</a>
<ul>
<li><a href="#org95d83b5">5.3.1. 偏移量索引</a></li>
<li><a href="#org3445710">5.3.2. 时间戳索引</a></li>
</ul>
</li>
<li><a href="#orgcb65ec3">5.4. 日志清理</a>
<ul>
<li><a href="#org41c622a">5.4.1. 日志删除</a></li>
<li><a href="#org0eef95b">5.4.2. 日志压缩</a></li>
</ul>
</li>
<li><a href="#orgbc57758">5.5. 磁盘存储</a>
<ul>
<li><a href="#org6119b56">5.5.1. 页缓存</a></li>
<li><a href="#orgf281d26">5.5.2. 零拷贝</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org8499379">6. 第六章: 深入服务端</a>
<ul>
<li><a href="#org1abb69f">6.1. 协议设计</a></li>
<li><a href="#org5a30526">6.2. 时间轮:</a></li>
<li><a href="#org90d4854">6.3. 延时操作</a></li>
<li><a href="#orgada1d03">6.4. 控制器</a>
<ul>
<li><a href="#orgc559461">6.4.1. 控制器的选举及异常恢复</a></li>
<li><a href="#orgaea8259">6.4.2. 如何优雅的关闭</a></li>
<li><a href="#orgeac90fa">6.4.3. 分区leader的选举</a></li>
</ul>
</li>
<li><a href="#org52b77e8">6.5. 参数解密</a>
<ul>
<li><a href="#orgb1435bc">6.5.1. broker.id</a></li>
<li><a href="#orge6b481b">6.5.2. bootstrap.servers</a></li>
<li><a href="#orgf647bd2">6.5.3. 服务端参数列表:</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgcdd35c0">7. 第7章 深入客户端</a>
<ul>
<li><a href="#org43136a1">7.1. 分区分配策略</a>
<ul>
<li><a href="#org89e4781">7.1.1. RangeAssignor分配策略</a></li>
<li><a href="#orgf9d3e85">7.1.2. RoundRobinAssignor分配策略</a></li>
<li><a href="#orgc2ce938">7.1.3. StickyAssignor分配策略</a></li>
</ul>
</li>
<li><a href="#orgdd72592">7.2. 消费者协调器和组协调器</a>
<ul>
<li><a href="#org49c2018">7.2.1. 旧版消费者客户端的问题</a></li>
<li><a href="#org61b5d11">7.2.2. 再均衡的原理</a></li>
</ul>
</li>
<li><a href="#org4c644c0">7.3. __consumer_offsets剖析</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-orgaf86151" class="outline-2">
<h2 id="orgaf86151"><span class="section-number-2">1</span> 第一章: 初识Kafka</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li>kafka被定为为一个分布式流处理平台</li>
<li>kfaka之所以受到青睐,与它扮演的三大角色分不开:
<ul class="org-ul">
<li>消息系统: 与传统消息系统类似,kafka具备系统解耦,冗余存储,流量削峰,缓冲等功能,
与此同时,kafka还提供大多数消息系统难以实现的消息顺序性保障和回溯消费功能</li>
<li>存储系统: kafka把消息持久化到磁盘,相比于其他基于内存存储的系统而言,有效降低
了数据丢失的风险.我们甚至可以把kafka作为长期的数据存储系统来使用,需要设置数据
保留策略为"永久",或者,启用topic的日志压缩功能</li>
<li>流式处理平台: kafka还提供了kafka stream</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orgeb0d460" class="outline-3">
<h3 id="orgeb0d460"><span class="section-number-3">1.1</span> 基本概念</h3>
<div class="outline-text-3" id="text-1-1">
<ul class="org-ul">
<li>一个典型的kafka体系包括:
<ul class="org-ul">
<li>若干Producer: 负责将消息发送给Broker</li>
<li>若干Broker: 负责将收到的消息存储到磁盘</li>
<li>若干Consumer</li>
<li>一个ZooKeeper集群: 负责集群元数据的管理</li>
</ul></li>
<li>整个Kafka体系结构引入了如下三个术语:
<ul class="org-ul">
<li>Producer: 生产者,也就是发送消息的一方,生产者负责创建消息,然后将其投递到Kafka中</li>
<li>Consumer: 消费者,也就是接受消息的一方</li>
<li>Broker: 服务代理节点,一般来说,一台服务器上部署一个kafka实例,就是一个broker,多个
broker组成一个kafka集群</li>
</ul></li>
<li>kafka中还有特别重要的概念Topic(主题)和Partition(分区)</li>
<li>kafka中的消息以topic为单位进行分类:
<ul class="org-ul">
<li>生产者发送的时候,就知道topic,并且发往特定的topic</li>
<li>消费者负责订阅特定的topic,并且进行消费</li>
</ul></li>
<li><p>
topic是一个逻辑上的概念,在实现上一般是分成多个partition(分区)的,也就是说:
</p>
<pre class="example" id="org09379ff">
partition是topic的实现方法, topic是partition的抽象集合
</pre></li>
<li>一个分区只属于单个主题,同一个主题下的不同分区包含的消息是不同的</li>
<li>在存储层面,分区可以看做是一个可以追加的log文件,message(消息)在被追加到这个
log文件的时候,都会被分配一个特定的偏移量(offset)</li>
<li><p>
如图1-2,主题有四个分区,消息被顺序追缴到每个分区日志文件的尾部
</p>

<div id="org98e6018" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-1-2.jpg" alt="ki-1-2.jpg" />
</p>
<p><span class="figure-number">Figure 1: </span>kafka/ki-1-2.jpg</p>
</div></li>
<li>kafka的分区可以分布在不同的broker上,从逻辑上来看,就是主题可以横跨多个broker</li>
<li>每一条消息发送到broker之前,会根据分区规则选择到底到哪个分区,分区规则尽可能
是要把消息平均的分配到分区上.</li>
<li>分区数目是可以动态调整的</li>
<li>kafka为分区引入了多副本机制,通过增加副本的数量来提高容灾能力:
<ul class="org-ul">
<li>同意个分区的不同副本保存的是相同的信息(当然同一时刻,由于sync的关系不一定
能保证完全一致,但从较长时间来看,主副内容一致)</li>
<li>副本之间是"一主多从"的关系:
<ol class="org-ol">
<li>leader副本负责处理读写请求</li>
<li>follower副本只负责与leader副本同步消息</li>
<li>所有副本都处于不同的broker,当leader副本出现故障时,从剩下的follower副本里面
重新选举新的leader副本对外提供服务.这样能保证集群中某个broker失效后依然
能够保证服务可用.</li>
</ol></li>
</ul></li>
<li>下图的kafka集群:
<ul class="org-ul">
<li><p>
图1-3
</p>

<div id="orgcddfe2f" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-1-3.jpg" alt="ki-1-3.jpg" />
</p>
<p><span class="figure-number">Figure 2: </span>kafka/ki-1-3.jpg</p>
</div></li>
<li>有四个broker</li>
<li>某个topic有三个分区</li>
<li>副本因子(也就是副本数也是3), 那么就有1个leader副本,2个follower副本.</li>
<li>生产者和消费者只与leader副本进行交互,follower副本只负责消息的同步,follower
副本中消息相对leader副本有一定滞后</li>
</ul></li>
<li>kafka消费端也具有一定容灾能力,因为消费端是pull模式从服务端拉取,如果一旦宕机,
恢复上线时可以根据之前保存的消费位置(这个位置存在kafka)重新拉取,不会造成丢失</li>
<li>分区中的follower副本统称为AR(Assigned Replicas)</li>
<li>所有与leader副本保持一定程度同步的副本(包括leader副本在内)组成了ISR(In-Sync Replicas)</li>
<li>ISR集合是AR集合的一个子集</li>
<li><p>
与leaser副本同步滞后过多的副本组成OSR(Out-of-Sync Replicas),所以得到:
</p>
<pre class="example" id="orgc7c5980">
AR = ISR+OSR
</pre></li>
<li>消息会先发送到leader副本, follower副本才能从leader副本拉取消息同步,所以follower
有一定程度的滞后</li>
<li>这个"一定程度的滞后",是可以用参数进行配置的.</li>
<li>leader副本负责维护ISR和OSR:
<ul class="org-ul">
<li>如果ISR里面的follower副本落后太多,就把他移到OSR</li>
<li>如果OSR里面的follower副本追上了,就把他移动到ISR</li>
</ul></li>
<li>只有在ISR集合中的副本才有资格被选举为新的leader. OSR集合中的是没有机会的(虽然可以
通过修改规则来改变)</li>
<li><p>
ISR还和HW(High Watermark)有关系
</p>
<pre class="example" id="org8b785a4">
High Watermark中文为高水位,标识了特定的消息偏移量(offset),消费者
只能拉取这个offset之前的消息
</pre></li>
<li><p>
和HW类似的概念是LEO(Log End Offset),它标识日志文件中下一条待写入消息的offset.换句话说,
</p>
<pre class="example" id="orge106aae">
HW是读取的边界,而LEO是写入的边界
</pre></li>
<li>下图就是一个标识HW和LEO关系的图:
<ul class="org-ul">
<li><p>
图1-4
</p>

<div id="org42e3975" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-1-4.jpg" alt="ki-1-4.jpg" />
</p>
<p><span class="figure-number">Figure 3: </span>kafka/ki-1-4.jpg</p>
</div></li>
<li>第一条offset为0</li>
<li>最后一条offset为8</li>
<li>下一条写入的offset为LEO</li>
<li>HW位置为6,那么0-5的位置能够被消费者拉取</li>
<li>note:很多资料会把5错误理解成HW的位置,8错误理解成LEO的位置</li>
</ul></li>
<li>ISR和HW的关系,我们需要使用例子来解释</li>
<li>第一个图:
<ul class="org-ul">
<li><p>
图1-5
</p>

<div id="org9661287" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-1-5.jpg" alt="ki-1-5.jpg" />
</p>
<p><span class="figure-number">Figure 4: </span>kafka/ki-1-5.jpg</p>
</div></li>
<li>上图中某个分区ISR有三个副本(一个leader副本和两个follower副本)</li>
<li>此时分区的LEO和HW都为3</li>
<li>消息3和4从生产者发出后,会被先存入leader副本</li>
</ul></li>
<li>第二个图:
<ul class="org-ul">
<li><p>
图1-6
</p>

<div id="org3027325" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-1-6.jpg" alt="ki-1-6.jpg" />
</p>
<p><span class="figure-number">Figure 5: </span>kafka/ki-1-6.jpg</p>
</div></li>
<li>在写入leader副本之后,follower副本会发送请求来sync</li>
<li>这个时候HW还是在3,LEO在5</li>
</ul></li>
<li>第三个图:
<ul class="org-ul">
<li><p>
图1-7
</p>

<div id="orgafe3c80" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-1-7.jpg" alt="ki-1-7.jpg" />
</p>
<p><span class="figure-number">Figure 6: </span>kafka/ki-1-7.jpg</p>
</div></li>
<li>在同步过程中,不同的follower副本的同步效率也不尽相同,比如此图中follower1已
经完全跟上了leader副本,但是follower2只同步到3</li>
<li>此时leader副本的LEO是5, follower1副本的LEO是5,follower2副本的LEO是4</li>
<li>当前整个分区的HW最小值是4,也就是消费者可以拉取0到3之间的消息</li>
</ul></li>
<li>第四个图
<ul class="org-ul">
<li><p>
图1-8
</p>

<div id="orgeb7e448" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-1-8.jpg" alt="ki-1-8.jpg" />
</p>
<p><span class="figure-number">Figure 7: </span>kafka/ki-1-8.jpg</p>
</div></li>
<li>所有副本都成功写入了消息3和消息4,整个分区的HW和LEO都是5了</li>
<li>消费者可以读取到offset为4的消息了</li>
</ul></li>
<li>kafka的这种复制机制,让我们可以通过设置来达到同步和异步两种复制
<ul class="org-ul">
<li>同步复制: 要求所有能工作的follower副本都复制完成,这条消息才会被确认为提交成功</li>
<li>异步复制: 数据只要被leader副本写入就被认为是成功提交,follower副本这时候异步
的从leader副本中复制数据.相比于同步复制,异步复制提高了性能,但是损失了一部分
的可靠性:如果follower副本还没有复制完并落后于leader副本,如果leader副本宕机,
则会造成数据丢失</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org9b1c687" class="outline-3">
<h3 id="org9b1c687"><span class="section-number-3">1.2</span> 安装与配置</h3>
<div class="outline-text-3" id="text-1-2">
<ul class="org-ul">
<li>以Linux的centos为例子来介绍下如何如何搭建Kafka运行环境:</li>
</ul>
</div>
<div id="outline-container-orgff75a0e" class="outline-4">
<h4 id="orgff75a0e"><span class="section-number-4">1.2.1</span> 安装JAVA环境</h4>
<div class="outline-text-4" id="text-1-2-1">
<ul class="org-ul">
<li>安装JDK</li>
<li>配置JAVA_HOME</li>
</ul>
</div>
</div>
<div id="outline-container-org6b1f9c7" class="outline-4">
<h4 id="org6b1f9c7"><span class="section-number-4">1.2.2</span> 配置ZooKeeper</h4>
<div class="outline-text-4" id="text-1-2-2">
<ul class="org-ul">
<li><p>
下载zookeepr,解压到如下文件夹
</p>
<div class="org-src-container">
<pre class="src src-shell">/opt/zookeeper-3.4.12
</pre>
</div></li>
<li><p>
向/etc/profile配置文件中添加如下内容
</p>
<div class="org-src-container">
<pre class="src src-shell"><span style="color: #e39b7b;">export</span> <span style="color: #87c095; font-style: italic;">ZOOKEEPER_HOME</span>=/opt/zookeeper-3.4.12
<span style="color: #e39b7b;">export</span> <span style="color: #87c095; font-style: italic;">PATH</span>=$<span style="color: #87c095; font-style: italic;">PATH</span>:$<span style="color: #87c095; font-style: italic;">ZOOKEEPER_HOME</span>/bin
</pre>
</div></li>
<li><p>
修改ZooKeeper的配置文件,进入$ZOOKEEPER_HOME/conf,并将zoo_sample.cfg文件修改为
zoo.cfg
</p>
<div class="org-src-container">
<pre class="src src-shell">cp zoo_sample.cfg zoo.cfg
</pre>
</div></li>
<li><p>
zoo.cfg文件内容如下
</p>
<div class="org-src-container">
<pre class="src src-shell"><span style="color: #87c095; font-style: italic;">tickTIme</span>=2000
<span style="color: #87c095; font-style: italic;">initLimit</span>=10
<span style="color: #87c095; font-style: italic;">syncLimit</span>=5
<span style="color: #87c095; font-style: italic;">dataDir</span>=/tmp/zookeeper/data
<span style="color: #87c095; font-style: italic;">dataLogDir</span>=/tmp/zookeeper/log
<span style="color: #87c095; font-style: italic;">clientPort</span>=2181
</pre>
</div></li>
<li><p>
启动Zookeeper服务
</p>
<div class="org-src-container">
<pre class="src src-shell">zkServer.sh start
</pre>
</div></li>
<li><p>
可以通过如下命令查看zookeeper服务状态
</p>
<div class="org-src-container">
<pre class="src src-shell">zkServer.sh status
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-org8830bca" class="outline-4">
<h4 id="org8830bca"><span class="section-number-4">1.2.3</span> Kafka的安装与配置</h4>
<div class="outline-text-4" id="text-1-2-3">
<ul class="org-ul">
<li>下载kafka_2.11-2.0.0.tgz,将其复制到/opt</li>
<li><p>
接下来修改配置文件$KAFKA_HOME/conf/server.properties
</p>
<div class="org-src-container">
<pre class="src src-conf"><span style="color: #87c095; font-style: italic;">broker.id</span>=0
<span style="color: #87c095; font-style: italic;">listeners</span>=PLAINTEXT://localhost:9092
<span style="color: #87c095; font-style: italic;">log.dirs</span>=/tmp/kafka-logs
<span style="color: #87c095; font-style: italic;">zookeeper.connect</span>=localhost:2181/kafka
</pre>
</div></li>
<li><p>
在$KAFKA_HOME目录下执行如下命令就可以启动kafka
</p>
<div class="org-src-container">
<pre class="src src-shell">bin/kafka-server-start.sh config/server.properties
</pre>
</div></li>
<li><p>
后台运行命令如下
</p>
<div class="org-src-container">
<pre class="src src-shell">bin/kafka-server-start.sh --daemon config/server.properties
</pre>
</div></li>
<li><p>
使用jps来查看进程
</p>
<div class="org-src-container">
<pre class="src src-shell">jps -l
</pre>
</div></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org22d1c81" class="outline-3">
<h3 id="org22d1c81"><span class="section-number-3">1.3</span> 生产与消费</h3>
<div class="outline-text-3" id="text-1-3">
<ul class="org-ul">
<li>生产者将消息发送至kafka的topic(更加准确的是topic的partition)中,而消费者也是
通过订阅主题而消费消息的.</li>
<li><p>
在$KAFKA_HOME/bin目录中,有很多实用脚本,比如下例使用kafka-topics.sh创建一个
分区数为4,副本因子为3的主题topic-demo
</p>
<div class="org-src-container">
<pre class="src src-shell">bin/kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-demo --replication-factor 3 --partitions 4
</pre>
</div></li>
<li><p>
可以使用&#x2013;describe来查看主题
</p>
<div class="org-src-container">
<pre class="src src-shell">bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-demo
</pre>
</div></li>
<li>创建集群之后,我们可以再:
<ul class="org-ul">
<li><p>
使用kafka-console-consumer.sh来订阅主题topic-demo,注意这里我们不再使用
&#x2013;zookeeper来指定zookeeper地址了,转而使用&#x2013;bootstrap-server来指定bootstrap
地址
</p>
<div class="org-src-container">
<pre class="src src-shell">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic-demo
</pre>
</div></li>
<li><p>
上述终端会等待,直到有message传入,我们使用kafka-console-producer.sh来发送
message
</p>
<div class="org-src-container">
<pre class="src src-shell">bin/kafka-console-producer.sh --broker-list localhost:9092 --tpoic topic-demo
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org948980f" class="outline-3">
<h3 id="org948980f"><span class="section-number-3">1.4</span> 服务端参数配置</h3>
<div class="outline-text-3" id="text-1-4">
<ul class="org-ul">
<li>kafka服务端有很多参数,虽然这些参数在大多数情况下不需要更改,但了解这些参数,以
及在特殊应用需求情况下的调优,对于我们更改的利用kafka有很大帮助</li>
<li>下面讲的参数都配置在$KAFKA_HOME/config/server.properties文件中</li>
</ul>
</div>
<div id="outline-container-orgf2b15ea" class="outline-4">
<h4 id="orgf2b15ea"><span class="section-number-4">1.4.1</span> zookeeper.connect</h4>
<div class="outline-text-4" id="text-1-4-1">
<ul class="org-ul">
<li>该参数指明broker要连接的zookeeper集群的服务地址,没有默认值,此参数为必填</li>
<li><p>
如果只有一个参数可以配置为
</p>
<div class="org-src-container">
<pre class="src src-conf">localhost:2181
</pre>
</div></li>
<li><p>
如果多个参数,可以使用逗号分开
</p>
<div class="org-src-container">
<pre class="src src-conf">localhost1:2181,localhost2:2181,localhost3:2181
</pre>
</div></li>
<li><p>
最佳实践是再加一个chroot路径(而不是使用zookeeper的root路径)
</p>
<div class="org-src-container">
<pre class="src src-conf">localhost1:2181,localhost2:2181,localhost3:2181/kafka
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-orge32a0c4" class="outline-4">
<h4 id="orge32a0c4"><span class="section-number-4">1.4.2</span> listeners</h4>
<div class="outline-text-4" id="text-1-4-2">
<ul class="org-ul">
<li><p>
该参数指定broker监听客户端连接的地址列表,也就是客户端要连接的broker地址,配置
格式为
</p>
<div class="org-src-container">
<pre class="src src-conf">protocol1://hostname1:port1,protocol2://hostnam2:port2,
</pre>
</div></li>
<li>其中,protocol代表协议类型,当前kafka支持的协议类型有:
<ul class="org-ul">
<li>PLAINTEXT(为开启安全认证,使用这个就好)</li>
<li>SSL</li>
<li>SASL_SSL</li>
</ul></li>
<li><p>
比如,一个参数例子为:
</p>
<div class="org-src-container">
<pre class="src src-conf">PLAINTEXT://198.162.0.2:9092
</pre>
</div></li>
<li>注意,如果不指定主机,则表示绑定默认网卡,而默认网卡有可能是127.0.0.1,这样一来
则无法对外提供服务,所以不知道主机情况下,也不要空着,可以指定0.0.0.0,这样一来
表示绑定所有网卡.</li>
<li>与listeners类似的参数还有advertised.listeners,默认值也是null,与listeners的区别如下:
<ul class="org-ul">
<li>advertised.listeners主要用来绑定公网IP,供外部客户端使用</li>
<li>listeners主要用来绑定私有网络IP,用来供broker之间的通信使用</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org704d6f8" class="outline-4">
<h4 id="org704d6f8"><span class="section-number-4">1.4.3</span> broker.id</h4>
<div class="outline-text-4" id="text-1-4-3">
<ul class="org-ul">
<li>kafka集群中的每个broker都有一个唯一标识,默认值为-1,如果没有设置,kafka会自动
生成一个标识.</li>
</ul>
</div>
</div>
<div id="outline-container-org504f71a" class="outline-4">
<h4 id="org504f71a"><span class="section-number-4">1.4.4</span> log.dir和log.dirs</h4>
<div class="outline-text-4" id="text-1-4-4">
<ul class="org-ul">
<li>kafka把所有消息都保存在磁盘上,这两个参数来配置kafka日志存放的根目录:
<ul class="org-ul">
<li>log.dir用来配置单个目录,默认值为/tmp/kafka-logs</li>
<li>log.dirs用来配置多个目录(以逗号分隔),优先级高于log.dir</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org72204e5" class="outline-4">
<h4 id="org72204e5"><span class="section-number-4">1.4.5</span> message.max.bytes</h4>
<div class="outline-text-4" id="text-1-4-5">
<ul class="org-ul">
<li>该参数用来指定broker能够接收消息的最大值,默认值为976.6KB</li>
<li>如果Producer发送的消息待遇这个值,那么Producer就会报RecordTooLargeException异常</li>
<li>如果需要修改这个参数,那么还要考虑如下参数的影响:
<ul class="org-ul">
<li>客户端参数max.request.size</li>
<li>topic端参数max.message.bytes</li>
</ul></li>
<li>为避免修改此参数带来的连锁效应,建议分拆消息以适应976.6KB大小,而不是更改
message.max.bytes</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org50d6e22" class="outline-2">
<h2 id="org50d6e22"><span class="section-number-2">2</span> 第二章 生产者</h2>
<div class="outline-text-2" id="text-2">
<ul class="org-ul">
<li>生产者就是负责向kafka发送消息的应用程序,kafka有两个大版本的生产者客户端:
<ul class="org-ul">
<li>使用Scale编写的老版本的客户端(已经不再使用)</li>
<li>使用Java开发的科幻(从kafka 0.9.x版本开始),我们主要介绍这个客户端</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org1b5cbae" class="outline-4">
<h4 id="org1b5cbae"><span class="section-number-4">2.0.1</span> 客户端开发</h4>
<div class="outline-text-4" id="text-2-0-1">
<ul class="org-ul">
<li>一个生产逻辑需要如下几个步骤:
<ol class="org-ol">
<li>配置生产者客户端参数,创建生产者实例</li>
<li>构建待发送的消息</li>
<li>发送消息</li>
<li>关闭生产者实例</li>
</ol></li>
<li><p>
下面就是一个生产者的实例代码
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">package</span> org.harri.kafka.<span style="color: #d3a0bc;">demo_2_1</span>;

<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">producer</span>.<span style="color: #d9bb80;">KafkaProducer</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">producer</span>.<span style="color: #d9bb80;">ProducerRecord</span>;

<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d9bb80;">Properties</span>;

<span style="color: #e68183;">public</span> <span style="color: #e68183;">class</span> <span style="color: #d9bb80;">KafkaProducerAnalysis</span> {
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">brokerList</span> = <span style="color: #87af87;">"127.0.0.1:9092"</span>;
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span> = <span style="color: #87af87;">"harri-test-topic"</span>;

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095;">initConfig</span>() {
        <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">Properties</span>();
        props.put(<span style="color: #87af87;">"bootstrap.servers"</span>, brokerList);
        props.put(<span style="color: #87af87;">"key.serializer"</span>,
                <span style="color: #87af87;">"org.apache.kafka.common.serialization.StringSerializer"</span>);
        props.put(<span style="color: #87af87;">"value.serializer"</span>,
                <span style="color: #87af87;">"org.apache.kafka.common.serialization.StringSerializer"</span>
        );
        props.put(<span style="color: #87af87;">"client.id"</span>, <span style="color: #87af87;">"producer.client.id.demo"</span>);
        <span style="color: #e68183;">return</span> props;
    }

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">main</span>(<span style="color: #d9bb80;">String</span>[] <span style="color: #87c095; font-style: italic;">args</span>) {
        <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span> = initConfig();
        <span style="color: #d9bb80;">KafkaProducer</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">producer</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaProducer</span>&lt;&gt;(props);
        <span style="color: #d9bb80;">ProducerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">record</span> =
                <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">ProducerRecord</span>&lt;&gt;(topic, <span style="color: #87af87;">"hello, kafka!"</span>);

        <span style="color: #e68183;">try</span> {
            <span style="color: #5b5b5b;">// </span><span style="color: #5b5b5b;">Warning!!! now get here, might not get the result from consumer</span>
            producer.send(record);
        } <span style="color: #e68183;">catch</span> (<span style="color: #d9bb80;">Exception</span> <span style="color: #87c095; font-style: italic;">e</span>) {
            e.printStackTrace();
        }
        System.out.println(<span style="color: #87af87;">"Done"</span>);
        <span style="color: #e68183;">try</span> {
            Thread.sleep(1000);
        } <span style="color: #e68183;">catch</span> (<span style="color: #d9bb80;">Exception</span> <span style="color: #87c095; font-style: italic;">e</span>) {
            e.printStackTrace();
        }
    }
}

</pre>
</div></li>
<li>我们来解释下上面的代码:
<ul class="org-ul">
<li>ProducerRecord不是单纯意义上的消息,它包含了多个属性:
<ol class="org-ol">
<li>而value属性,也就是要发送的内容,是最重要的属性.我们这里给value属性设置
了"hello kafka!"</li>
<li>ProducerRecord的另外一个重要属性是topic,我们在代码里面使用了topic变量来赋予</li>
<li>header属性是0.11.x版本才引入的,用来设定一些与应用相关的信息</li>
<li>key属性是用来执行消息的附加信息(和value是一对kv),key还用来计算分区号:同一个key
的message,在分区不改变的情况下,每次都发往同一个分区.</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgb0c08e1" class="outline-4">
<h4 id="orgb0c08e1"><span class="section-number-4">2.0.2</span> 必要的参数配置</h4>
<div class="outline-text-4" id="text-2-0-2">
<ul class="org-ul">
<li>在创建真正的生产者实例前,需要配置相应的参数,我们这里使用initConfig()方法来
初始化props变量,然后让props变量来初始化KafkaProducer</li>
<li>KafkaProducer有三个参数是必填的:
<ul class="org-ul">
<li>bootstrap.servers:
<ol class="org-ol">
<li><p>
该参数用来指定生产者客户端连接kafka所需要的broker地址,具体地址样式为
</p>
<div class="org-src-container">
<pre class="src src-conf">host1:prot1,host2:port2
</pre>
</div></li>
<li>注意这里并非要填上所有的broker地址,因为生产者在知道一个broker地址后,可以
从这个broker地址里面查找其他broker的信息,不过建议最少设置两个以上的broker
地址,以防止有一个宕机</li>
</ol></li>
<li>key.serializer和value.serializer:
<ol class="org-ol">
<li>broker端接受的消息必须是byte[]形式存在的,虽然我们的KafkaProducer&lt;String, String&gt;
和ProducerRecord&lt;String, String&gt;里面泛型指定了key和value的类型,但是真
正发送给broker之前,要做序列化来生成字节数组</li>
<li>key.serializer是用来指定key的序列化器</li>
<li>value.serializer是用来指定value的序列化器</li>
<li><p>
这两个参数都没有默认值,还必须写全称,比如这段代码里面写的
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">common</span>.<span style="color: #d3a0bc;">serialization</span>.StringSerializer
</pre>
</div></li>
</ol></li>
</ul></li>
<li>我们这里还额外设置了client.id,这个参数代表KafkaProducer对应的id, 如果不设置,
KafkaProducer会自动生成类似"producer-1", "producer-2"这样的字符串</li>
<li><p>
上例中的参数的书写,使用了字符串,但是常见的配置还好,有些配置可能容易拼错(比如
max.request.size),所以我们可以使用ProducerConfig类来做预防,如下(key.serializer
和value.serializer也使用了容错写法)
</p>
<div class="org-src-container">
<pre class="src src-java">props.put(<span style="color: #d3a0bc;">ProducerConfig</span>.<span style="color: #d9bb80;">KEY_SERIALIZER_CLASS_CONFIG</span>,
          StringSerializer.<span style="color: #e68183;">class</span>.<span style="color: #d9bb80;">getName</span>());
</pre>
</div></li>
<li>KafkaProducer是线程安全的,可以在多个线程中共享单个KafkaProducer实例,也可以
将KafkaProducer实例进行池化来供其他线程调用</li>
<li><p>
KafkaProducer中有多个构造方法,比如props里面没有设置key.serializer和value.serializer,
那么就要如下设置
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #d9bb80;">KafkaProducer</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">producer</span> =
    <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaProducer</span>&lt;&gt;(props,
                        <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">StringSerializer</span>());
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-orgfd13fd2" class="outline-4">
<h4 id="orgfd13fd2"><span class="section-number-4">2.0.3</span> 消息的发送</h4>
<div class="outline-text-4" id="text-2-0-3">
<ul class="org-ul">
<li>创建完生产者实例后,接下来的工作就是构建消息</li>
<li><p>
ProducerRecord里面只有topic属性和value属性是必须的,其他都是可选的,所以会有
非常多的构建方法:
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #87c095;">ProducerRecord</span>(<span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span>,
                      <span style="color: #d9bb80;">Integer</span> <span style="color: #87c095; font-style: italic;">partition</span>,
                      <span style="color: #d9bb80;">Long</span> <span style="color: #87c095; font-style: italic;">timestamp</span>,
                      <span style="color: #d9bb80;">K</span> <span style="color: #87c095; font-style: italic;">key</span>,
                      <span style="color: #d9bb80;">V</span> <span style="color: #87c095; font-style: italic;">value</span>,
                      <span style="color: #d9bb80;">Iterable</span>&lt;<span style="color: #d9bb80;">Header</span>&gt; <span style="color: #87c095; font-style: italic;">headers</span>)

<span style="color: #e68183;">public</span> ProducerRecord(<span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span>, <span style="color: #d9bb80;">K</span> <span style="color: #87c095; font-style: italic;">key</span>, <span style="color: #d9bb80;">V</span> <span style="color: #87c095; font-style: italic;">value</span>)

<span style="color: #e68183;">public</span> ProducerRecord(<span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span>, <span style="color: #d9bb80;">V</span> <span style="color: #87c095; font-style: italic;">value</span>)
</pre>
</div></li>
<li>我们上面使用了最简单的一种,就是只设置topic和value,其他field都是null</li>
<li>创建完生产者实例和构建消息之后,就可以开始发送消息了,发送消息有三种模式:
<ul class="org-ul">
<li>发后即忘(fire-and-forget)</li>
<li>同步(sync)</li>
<li>异步(async)</li>
</ul></li>
<li>代码2-1就是发后即忘的方式,它只管往kafka中发送消息但并不关心消息是否正确到达.
大多数情况下没有问题,但是有些时候会造成消息的丢失,这种发送方式性能最高,可靠
性也最差</li>
<li>KafkaProducer的send()方法返回值不是void,而是Future&lt;RecordMetadata&gt;:
<ul class="org-ul">
<li><p>
重载方法1:
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">Future</span>&lt;<span style="color: #d9bb80;">RecordMetadata</span>&gt; <span style="color: #87c095;">send</span>(<span style="color: #d9bb80;">ProducerRecord</span>&lt;<span style="color: #d9bb80;">K</span>, <span style="color: #d9bb80;">V</span>&gt; <span style="color: #87c095; font-style: italic;">record</span>)
</pre>
</div></li>
<li><p>
重载方法2
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">Future</span>&lt;<span style="color: #d9bb80;">RecordMetadata</span>&gt; <span style="color: #87c095;">send</span>(<span style="color: #d9bb80;">ProducerRecord</span>&lt;<span style="color: #d9bb80;">K</span>, <span style="color: #d9bb80;">V</span>&gt; <span style="color: #87c095; font-style: italic;">record</span>,
                                   <span style="color: #d9bb80;">Callback</span> <span style="color: #87c095; font-style: italic;">callback</span>)
</pre>
</div></li>
</ul></li>
<li><p>
要实现同步的发送方式,需要利用Future对象,调用这个对象的get函数
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">try</span> {
    producer.send(record).get();
} <span style="color: #e68183;">catch</span> (ExecutionException | InterruptedException e) {
    e.printStackTrace();
}
</pre>
</div></li>
<li>send()函数是异步的,但是返回Future对象的get()函数是同步的,上面的例子中,get()
函数会一直阻塞,直到发送成功,或者发生异常</li>
<li><p>
get()还有一些重载函数,能够实现可超时的阻塞
</p>
<div class="org-src-container">
<pre class="src src-java">get(<span style="color: #d9bb80;">long</span> <span style="color: #87c095; font-style: italic;">timeout</span>, <span style="color: #d9bb80;">TimeUnit</span> <span style="color: #87c095; font-style: italic;">unit</span>)
</pre>
</div></li>
<li>KafkaProducer一般会发生两种类型的异常:
<ul class="org-ul">
<li>可重试异常,比如:
<ol class="org-ol">
<li>NetworkException: 网络瞬时故障造成的异常,一般重试可以解决</li>
<li>LeaderNotAvailableException: 表示partition的leader副本不可用,通常是leader
副本下线后,新的leader副本还没有选举出来,一般重试也可以解决</li>
<li>UnknownTopicOrPartitionException</li>
<li>NotEnoughReplicasException</li>
<li>NotCoordinatorException</li>
</ol></li>
<li>不可重试异常,(此类异常一概不重试,直接抛出异常)比如:
<ol class="org-ol">
<li>REcordTooLargeException:</li>
</ol></li>
</ul></li>
<li><p>
对于可重试异常,如果配置了retries参数,那么只要在规定重试次数内恢复了,就不会
在抛出异常(retires默认值是0):
</p>
<div class="org-src-container">
<pre class="src src-java">props.put(<span style="color: #d3a0bc;">ProducerConfig</span>.<span style="color: #d9bb80;">RETRIES_CONFIG</span>, 10);
</pre>
</div></li>
<li>同步发送的方式可靠性高,要么成功,要么发生异常,异常还可以捕获处理,但是同步发送
的性能会差很多(相比发后即忘).要阻塞等待一条发送后,才能发送下一条</li>
<li><p>
最后我们来看看异步发送的方式:一般是在send()方法里面指定一个callback回调函数
如下
</p>
<div class="org-src-container">
<pre class="src src-java">producer.send(<span style="color: #d9bb80;">record</span>, <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">Callback</span>() {
        <span style="color: #d3a0bc;">@Override</span>
        <span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">onCompletion</span>(<span style="color: #d9bb80;">RecordMetadata</span> <span style="color: #87c095; font-style: italic;">metadat</span>, <span style="color: #d9bb80;">Execption</span> <span style="color: #87c095; font-style: italic;">exception</span>) {
            <span style="color: #e68183;">if</span> (exception != <span style="color: #d3a0bc;">null</span>) {
                exception.printStackTrace();
            } <span style="color: #e68183;">else</span> {
                System.out.println(metadat.topic + <span style="color: #87af87;">"-"</span> +
                                   metadata.partition() + <span style="color: #87af87;">":"</span> +
                                   metadata.offset());
            }
        }
    });
</pre>
</div></li>
<li>onCompletion()方法的两个参数是互斥的:
<ul class="org-ul">
<li>发送成功时,exception为null, metadata不为null</li>
<li>发送不成功时,exception不为null, metadata为null</li>
</ul></li>
<li><p>
kafkaProducer发送完多条消息后,要使用close()方法来回收资源
</p>
<div class="org-src-container">
<pre class="src src-java">producer.close();
</pre>
</div></li>
<li>close()方法会阻塞等待前面素有发送请求完成后再关闭KafkaProducer</li>
<li><p>
KafkaProducer提供IG带超时时间的close()方法
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">close</span>(<span style="color: #d9bb80;">long</span> <span style="color: #87c095; font-style: italic;">timeout</span>, <span style="color: #d9bb80;">TimeUnit</span> <span style="color: #87c095; font-style: italic;">timeUnit</span>);
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-orgb0d97a8" class="outline-4">
<h4 id="orgb0d97a8"><span class="section-number-4">2.0.4</span> 序列化</h4>
<div class="outline-text-4" id="text-2-0-4">
<ul class="org-ul">
<li>生产者需要使用序列化器(Serializer)把对象转化为字节数组才能通过网络发送给Kafka</li>
<li>消费者需要反序列化器(Deserializer)把从Kafka收到的字节数组转化为相应的对象</li>
<li>kafka客户端自带的序列化器实现了如下几个类型:
<ul class="org-ul">
<li>ByteArray</li>
<li>ByteBuffer</li>
<li>Bytes</li>
<li>Double</li>
<li>Integer</li>
<li>Long</li>
</ul></li>
<li><p>
Kafka客户端自带的序列化器实现了如下的接口org.apache.kafka.common.serialzation.Serializer
其内部有这么几个函数
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">config</span>(<span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">String</span>, ?&gt; <span style="color: #87c095; font-style: italic;">config</span>, <span style="color: #d9bb80;">boolean</span> <span style="color: #87c095; font-style: italic;">isKey</span>)
<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">byte</span>[ serialize(<span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span>, <span style="color: #d9bb80;">T</span> <span style="color: #87c095; font-style: italic;">data</span>)
<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> close()
</pre>
</div></li>
<li>生产者和消费者使用的反序列化器需要一一对应的,否则无法解析出想要的数据</li>
<li>如果kafka客户端提供的几种序列化器都无法满足应用需求,则可以选择使用其他开源
的序列化工具:
<ul class="org-ul">
<li>Avro</li>
<li>JSON</li>
<li>Thrift</li>
<li>ProtoBuf</li>
<li>Protostuff</li>
</ul></li>
<li>我们也可以实现自己的序列化器</li>
</ul>
</div>
</div>
<div id="outline-container-org991871f" class="outline-4">
<h4 id="org991871f"><span class="section-number-4">2.0.5</span> 分区器</h4>
<div class="outline-text-4" id="text-2-0-5">
<ul class="org-ul">
<li>消息在通过send()方法发送到broker的过程中,有可能需要经过如下器:
<ul class="org-ul">
<li>拦截器(interceptor): 一般不是必须的</li>
<li>序列化器(Serializer): 是必须的</li>
<li>分区器(Partitioner)</li>
</ul></li>
<li>如果ProducerRecord中指定了partition字段,那么就不需要分区器,否则就需要依赖
分区器</li>
<li><p>
分区器的作用就是根据key的值来计算partition的值.kafka默认的分区器是DefaultPartitioner,
这个类实现了如下接口:org.apache.kafka.clients.producer.Partitioner
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">int</span> <span style="color: #87c095;">partition</span>(<span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span>, <span style="color: #d9bb80;">Object</span> <span style="color: #87c095; font-style: italic;">key</span>, <span style="color: #d9bb80;">byte</span>[] <span style="color: #87c095; font-style: italic;">keyBytes</span>,
                     <span style="color: #d9bb80;">Object</span> <span style="color: #87c095; font-style: italic;">value</span>, <span style="color: #d9bb80;">byte</span>[] <span style="color: #87c095; font-style: italic;">valueBytes</span>, <span style="color: #d9bb80;">Cluster</span> <span style="color: #87c095; font-style: italic;">cluster</span>);
<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">close</span>();
</pre>
</div></li>
<li>partition()是计算partition的主要函数:
<ul class="org-ul">
<li>如果key不会null,那么默认分区器会对key进行哈希,最终得到哈希值来%分区总数,
得到分区ID</li>
<li>如果key为null,那么就会以轮询方式发往可用的分区</li>
</ul></li>
<li>这里注意一个区别:
<ul class="org-ul">
<li>如果key不为null,计算得到的分区好为所有分区中的一个(即便这个分区不可用了
也必须是这个,因为前面相同key值的已经分发到这个分区了)</li>
<li>如果key为null,计算得到的分区是可用分区中的任意一个(不包括不可用!)</li>
</ul></li>
<li>一旦增加了分区,那么就难以保证key与分区之间的关系了</li>
</ul>
</div>
</div>
<div id="outline-container-orga8947e1" class="outline-4">
<h4 id="orga8947e1"><span class="section-number-4">2.0.6</span> 生产者拦截器</h4>
<div class="outline-text-4" id="text-2-0-6">
<ul class="org-ul">
<li>拦截器分为:
<ul class="org-ul">
<li>生产者拦截器</li>
<li>消费者拦截器</li>
</ul></li>
<li>生产者拦截器用来在消息发送前做一些准备工作,比如按照规则过滤不符合要求的消息,
修改消息等.</li>
<li><p>
想实现一个拦截器接口,需要实现ProducerInterceptor接口,如下
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">ProducerRecord</span>&lt;<span style="color: #d9bb80;">K</span>, <span style="color: #d9bb80;">V</span>&gt; <span style="color: #87c095;">onSend</span>(<span style="color: #d9bb80;">ProducerRecord</span>&lt;<span style="color: #d9bb80;">K</span>, <span style="color: #d9bb80;">V</span>&gt; <span style="color: #87c095; font-style: italic;">record</span>);
<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">onAcknowledgement</span>(<span style="color: #d9bb80;">RecordMetadata</span> <span style="color: #87c095; font-style: italic;">metadata</span>, <span style="color: #d9bb80;">Exception</span> <span style="color: #87c095; font-style: italic;">exception</span>);
<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">close</span>();
</pre>
</div></li>
<li>kafkaProducer会在序列化和计算分区之前调用onSend()方法,来对消息进行定制</li>
<li>一般来说不要修改ProducerRecord的topic, key, partition信息(可以修改value)</li>
<li>KafkaProducer会在消息被应答之前或消息发送失败时调用生产者拦截器的onAcknowledgement()
方法,优先于Callback执行.由于在Producer I/O线程中执行,这个方法要快速结束</li>
<li>close()方法用于在关闭拦截器时,做一些资源清理的工作</li>
</ul>
</div>
</div>
<div id="outline-container-org661a995" class="outline-3">
<h3 id="org661a995"><span class="section-number-3">2.1</span> 原理分析</h3>
<div class="outline-text-3" id="text-2-1">
</div>
<div id="outline-container-org8730dc3" class="outline-4">
<h4 id="org8730dc3"><span class="section-number-4">2.1.1</span> 整体架构</h4>
<div class="outline-text-4" id="text-2-1-1">
<ul class="org-ul">
<li>下图是生产者客户端的整体架构</li>
<li>整个生产者客户端有两个线程协调运行:
<ul class="org-ul">
<li>主线程: 由KafkaProducer创建消息,然后通过可能的拦截器,序列化器和分区器的
作用之后,缓存到消息累加器(RecordAccumulator)</li>
<li>Sender线程: 负责从RecordAccumulator中获取消息并且发送到Kafka中</li>
</ul></li>
<li>RecordAccumulator主要用来缓存消息以便Sender线程可以批量发送,这样可以减少网
络传输消耗的资源以提升性能.</li>
<li>RecordAccumulator缓存大小可以通过生产者客户端参数buffer.memory配置,默认为32MB</li>
<li>如果生产者发送消息的速度超过发送到服务器的速度,会导致RecordAccumulator空间
不足,这个时候,send()方法会阻塞,超过max.block.ms(6000也就是60秒)的配置,会抛出
异常</li>
<li>主线程发送过来的消息会被追加到RecordAccumulator的Deque里面</li>
<li>RecordAccumulator为每个分区都准备了一个Deque</li>
<li>Deque里面的内容为ProducerBatch:
<ul class="org-ul">
<li>消息写入时,追加到Deque的尾部</li>
<li>消息读取时,从Deque的头部读取</li>
</ul></li>
<li>Deque里面存的是ProducerBatch, ProducerBatch中可以包含一个或者多个ProducerRecord:
<ul class="org-ul">
<li>ProducerRecord是生产者创建的</li>
<li>ProducerBatch是指一个消息批次,ProducerRecord会被包含在ProducerBatch里面,
这样可以使字节更加紧凑</li>
</ul></li>
<li>消息在网络上都是以byte的形式传输的,在发送之前需要创建一块内存区域来保存对应
的消息,对应到kafka客户端里面,就是使用java.io.ByteBuffer来存储</li>
<li>ByteBuffer的频繁创建和释放很浪费资源,所以在RecordAccumulator内部还有一个
BufferPool来实现对ByteBuffer的复用</li>
<li>BufferPoll只针对特定大小的ByteBuffer进行管理,其他大小的ByteBuffer不会缓存
进BufferPool中.所谓特定大小的ByteBuffer的大小由batch.size,默认是16KB</li>
<li>ProducerBatch的大小和batch.size参数也有密切的关系:
<ul class="org-ul">
<li>一条ProducerRecord流入RecordAccumulator的时候,会先寻找自己的partition所
对应的Deque</li>
<li>在这个Deque尾部获取一个ProducerBatch,看看这个ProducerBatch是否还可以写入
这个ProducerRecord,可以的话,直接写入.</li>
<li>如果不可以,则需要新建一个ProducerBatch,新建的ProducerBatch必须要能容得下
这个ProducerRecord:
<ol class="org-ol">
<li>如果这个ProducerRecord小于batch.size,那么我们就可以以batch.size来创建
ProducerBatch,并且能够使用BufferPool的cache功能</li>
<li>如果这个ProducerRecord大于batch.size,那么就以ProducerRecord的实际大小
来创建ProducerBatch,内存复用功能不能够被使用.</li>
</ol></li>
</ul></li>
<li>Sender从RecordAccumulator中获取缓存的消息之后,会进一步进行如下转换:
<ul class="org-ul">
<li>从&lt;分区,Deque&lt;ProducerBatch&gt;&gt;的保存形式</li>
<li>转化为&lt;Node, List&lt;ProducerBatch&gt;&gt;的形式,其中Node表示kafka集群的broer节点,
因为对于网络连接来说,它是和具体的broker节点建立连接</li>
<li>最后再转化为&lt;Node, Request&gt;的形式,这样就可以将Request请求发往各个Node了</li>
</ul></li>
<li>Request在从Sender线程发往Kafka之前,还会保存到InFlightRequest中,InFlightRequest
保存对象的具体格式是Map&lt;NodeId, Deque&lt;Request&gt;&gt;</li>
<li>InFlightRequest的主要作用,是缓存了已经发出去,但是还没有收到响应的请求</li>
<li>由于InFlightRequest能够缓存请求,所以它可以控制能够缓存的request的最大数目,
这个配置为max.in.flight.requests.per.connection.默认值为5,也就是说每个连接
最多只能缓存5个未响应的请求,超过该数值之后,就不能再向这个连接发送更多请求了.</li>
<li>如果一个Node有太多为相应的请求,说明这个Node节点的负载已经比较大,或者网络连
接有问题了,继续增加发送请求只会继续增大请求超时的可能</li>
</ul>
</div>
</div>
<div id="outline-container-orgbe2c046" class="outline-4">
<h4 id="orgbe2c046"><span class="section-number-4">2.1.2</span> 元数据的更新</h4>
<div class="outline-text-4" id="text-2-1-2">
<ul class="org-ul">
<li>上一节提及的InFlightRequest还可以获得leastLoadedNode(也就是Node中负载最小的)
这个leastLoadedNode是通过查看InFlightRequest中还未确认的request数目来决定的</li>
<li>选择出leastLoadedNode的重要性在于我们知道它的负载最小,网络最好,一些场景,比如查询
元数据的时候,我们要从负载最下,网络最好的Node下手.</li>
<li>我们创建ProducerRecord的时候,只知道topic,而KafkaProducer却要将此消息追加到
指定主题的,特定分区的,对应的leader副本所在的broker的节点地址和端口,才能建立
连接</li>
<li>之前我们说过,不需要在bootstrap.server参数里面把所有的broker都写上,写两个就
可以了,因为客户端可以自己发现其他broker节点,与此同时,broker节点的其他meta信息
也可以获取,而且其他meta信息变化的还很频繁,比如分区数量,leader副本分布</li>
<li>总结起来说,Kafka集群的元数据有下:
<ul class="org-ul">
<li>集群中有哪些主题</li>
<li>这些主题有哪些分区</li>
<li>每个分区上的leader副本分配再哪些节点</li>
<li>follower副本在哪些节点</li>
<li>哪些部分在AR,ISR集合中</li>
<li>集群中有哪些节点,控制节点又是哪一个</li>
</ul></li>
<li>客户端会在如下两种情况下发起更新元数据的操作:
<ul class="org-ul">
<li>客户端没有需要使用的元数据</li>
<li>超过metadata.max.age.ms时间没有更新元数据</li>
</ul></li>
<li>元数据的更新操作是在客户端内部进行的,对外部使用者不可见,这时候就会使用到"负载
最小,网络最好"的的leastLoadedNode,然后向这个Node发送MetadataRequest请求获
取具体的元数据信息</li>
<li>MetadataRequest是由Sender线程发起的,MetadataRequest也会和其他的普通Request
一样,放入到InFlightRequests来看看是否收到response</li>
<li>主线程也会时刻从Sender线程这里同步元数据的信息</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org5f75196" class="outline-3">
<h3 id="org5f75196"><span class="section-number-3">2.2</span> 重要的生产者参数</h3>
<div class="outline-text-3" id="text-2-2">
<ul class="org-ul">
<li>在KafkaProducer中除了之前讲过的参数,大部分参数都有合理的默认值,一般不需要修
改他们,不过了解他们也有助于我们了解客户端,更容易的进行debug</li>
</ul>
</div>
<div id="outline-container-org18e226a" class="outline-4">
<h4 id="org18e226a"><span class="section-number-4">2.2.1</span> acks</h4>
<div class="outline-text-4" id="text-2-2-1">
<ul class="org-ul">
<li>这个参数用来指定分区中必须要有多少个副本收到这条消息后,生产者才会任务这条
消息正确的写入了.这个参数设计消息的可靠性和吞吐量之间的权衡</li>
<li>acks参数有三种类型的值(都是字符串类型):
<ul class="org-ul">
<li>acks=1:
<ol class="org-ol">
<li>是默认值</li>
<li>生产者发送消息后,只要分区leader副本写入成功,那么就会收到来自服务端的成功相应</li>
<li>如果消息无法写入leader副本,比如leader副本崩溃,或者重新选举leader副本中,
那么生产者就会收到一个错误响应,生产者设置了retries的话,一般会重发</li>
<li>在某种情况下这个消息会丢失:成功写入leader副本,并且返回成功相应给生产者,
但是在被其他follower部分拉取之前leader副本崩溃,那么此消息就丢失了</li>
<li>acks设置为1,是消息可靠性和吞吐量之间的折中</li>
</ol></li>
<li>acks=0:
<ol class="org-ol">
<li>生产者发送消息之后不需要等待服务端的任何相应,丢了就丢了</li>
<li>acks设置为0,可以达到最大的吞吐量</li>
</ol></li>
<li>acks=-1或acks=all:
<ol class="org-ol">
<li>生产者发送消息之后,要等待ISR中所有副本都成功写入消息后才能收到来自服务
端的成功响应</li>
<li>acks设置为-1(all)可以达到最大可靠性,但并不意味着一定可靠,因为ISR中可能
只有leader副本,这就退化成acks=1的情况</li>
<li>要获得更高可靠性,需要配合min.insync.replicas等参数</li>
</ol></li>
</ul></li>
<li>acks参数配置的值是一个字符串,而不是证书类型</li>
</ul>
</div>
</div>
<div id="outline-container-org9c81309" class="outline-4">
<h4 id="org9c81309"><span class="section-number-4">2.2.2</span> max.request.size</h4>
<div class="outline-text-4" id="text-2-2-2">
<ul class="org-ul">
<li>这个参数用来限制生产者客户端能够发送的消息(request)的最大值,默认值为1MB</li>
<li>绝大多数情况下,这个值够了,并不建议读者盲目的增大这个参数,因为这个参数还涉
及其他参数的联动,比如:
<ul class="org-ul">
<li>broker端的message.max.bytes</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgbee58d9" class="outline-4">
<h4 id="orgbee58d9"><span class="section-number-4">2.2.3</span> retries和retry.backoff.ms</h4>
<div class="outline-text-4" id="text-2-2-3">
<ul class="org-ul">
<li>retries参数用来配置生产者重试的次数,默认值为0,即发生异常的时候不进行任何重试</li>
<li>可以设置retries为大于0的数字,让可以重试的异常不要抛给应用程序,让客户端自己重试.</li>
<li>有些异常不能重试,比如消息太大,超过max.request.size</li>
<li>retries还和另外一个参数retry.backoff.ms有关:
<ul class="org-ul">
<li>这个参数用来设置两次重试之间的时间间隔</li>
<li>默认值为100</li>
<li>可以估算一下可能的异常恢复时间,可以设定总的重试时间大于这个异常恢复时间,
以此避免生产者过早的放弃重试</li>
</ul></li>
<li>kafka可以保证同一个分区中的消息是有序的.如果生产者按照一定的顺序发送消息,
那么这些消息也会顺序的写入分区,对于某些应用,顺序特别重要,比如MySQL的binlog</li>
<li>需要保证顺序的场合(注意,这里是同一分区消息的有序)需要把:
<ol class="org-ol">
<li>max.in.flight.requests.per.connection 配置为1,这种情况下retries可以是任意值,
但是推荐非0值,否则直接设置retries为0,那就可以保证顺序(因为失败了不会重试)</li>
<li>retries=0,也可以做到有顺序,但是牺牲了完整性(可能发送失败)</li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org4f9b488" class="outline-4">
<h4 id="org4f9b488"><span class="section-number-4">2.2.4</span> compression.type</h4>
<div class="outline-text-4" id="text-2-2-4">
<ul class="org-ul">
<li>这个参数用来指定消息的压缩方式,默认是"none"也就是不会被压缩</li>
<li>该参数还可以被设置为:
<ul class="org-ul">
<li>gzip</li>
<li>snappy</li>
<li>lz4</li>
</ul></li>
<li>对消息压缩可以极大的减少网络传输量,降低网络IO,提高整体性能</li>
<li>消息压缩是一种使用时间(cpu)换空间的优化方式,如果对时延有一定要求,则部队件</li>
</ul>
</div>
</div>
<div id="outline-container-org56312c8" class="outline-4">
<h4 id="org56312c8"><span class="section-number-4">2.2.5</span> connections.max.idle.ms</h4>
<div class="outline-text-4" id="text-2-2-5">
<ul class="org-ul">
<li>参数指定多机之后关闭限制的连接,默认值是9分钟</li>
</ul>
</div>
</div>
<div id="outline-container-org6f0c39a" class="outline-4">
<h4 id="org6f0c39a"><span class="section-number-4">2.2.6</span> linger.ms</h4>
<div class="outline-text-4" id="text-2-2-6">
<ul class="org-ul">
<li>这个参数用来指定生产者发送ProducerBatch之前等待更多ProducerRecord加入的时间</li>
<li>默认值为0</li>
<li>生产者客户端会在ProducerBatch被填满,或者等待时间超过linger.ms后发送出去</li>
<li>增大这个值会增加效益 延迟,但是能提升一定的吞吐量</li>
</ul>
</div>
</div>
<div id="outline-container-orgd5aefde" class="outline-4">
<h4 id="orgd5aefde"><span class="section-number-4">2.2.7</span> receive.buffer.bytes</h4>
<div class="outline-text-4" id="text-2-2-7">
<ul class="org-ul">
<li>用来设置Socket接受消息缓冲区(SO_RECBUF)的大小</li>
<li>默认是32KB</li>
<li>如果设置为-1,则使用操作系统默认</li>
<li>如果Producer与Broker处于不同机房,可以适当调大这个参数值</li>
</ul>
</div>
</div>
<div id="outline-container-orga61382a" class="outline-4">
<h4 id="orga61382a"><span class="section-number-4">2.2.8</span> send.buffer.byts</h4>
<div class="outline-text-4" id="text-2-2-8">
<ul class="org-ul">
<li>用来设置Socket发送消息缓冲区(SO_SNDBUF)的大小</li>
<li>默认值是128KB</li>
<li>如果设置为-1,则使用操作系统默认</li>
</ul>
</div>
</div>
<div id="outline-container-orgb8f5df5" class="outline-4">
<h4 id="orgb8f5df5"><span class="section-number-4">2.2.9</span> request.timeout.ms</h4>
<div class="outline-text-4" id="text-2-2-9">
<ul class="org-ul">
<li>用来配置Producer等待请求响应的最长时间,默认值是30000(ms),超时后可以重试</li>
<li>这个参数要比borker端参数replica.lag.time.max.ms要大,这样才能减小因客户端重
试而引起的消息重复的概率</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgbde597e" class="outline-3">
<h3 id="orgbde597e"><span class="section-number-3">2.3</span> 其他常见参数意义</h3>
<div class="outline-text-3" id="text-2-3">
<ul class="org-ul">
<li>还有很多其他生产者参数在这里列举一下:
<ul class="org-ul">
<li>bootstrap.servers:默认值:""; kafka集群的broker地址</li>
<li>key.serializer:默认值:"";消息中key对应的序列化类</li>
<li>value.serializer:默认值:"";消息中value对应的序列化类</li>
<li>buffer.memory:默认值:32MB;生产者客户端中用于缓存消息的,缓冲区的大小</li>
<li>batch.size:默认值:16KB;ProducerBatch可以复用内存区域的大小</li>
<li>client.id:默认值:"";KafkaProducer对应的客户端id</li>
<li>max.block.ms:默认值:60000;控制KafkaProducer中send()方法和partitionsFor()方
法的阻塞时间.当生产者的发送缓存已满,或者没有可用的元数据,这些方法就会阻塞</li>
<li>partitioner.class:默认值:DefaultPartitioner;用来指定分区器</li>
<li>enable.idempotence:默认值:false;是否开启幂等性功能</li>
<li>interceptor.class:默认值:"";用来设定生产者拦截器</li>
<li>max.in.flight.requests.per.connection:默认值:5;限制每个连接(客户端和Node
之间)最多缓存的请求数</li>
<li>metadata.max.age.ms:默认值300,000(5分钟);如果在这个时间内元数据没有更新的
话会被强制更新</li>
<li>transactional.id:默认值:null;设置事务id,必须唯一</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd52857c" class="outline-2">
<h2 id="orgd52857c"><span class="section-number-2">3</span> 第三章 消费者</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-org042d537" class="outline-3">
<h3 id="org042d537"><span class="section-number-3">3.1</span> 消费者与消费组</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li>消费者(Customer)负责订阅Kafka中的主题(Topic)</li>
<li>与其他消息中间件不同的是,Kafka在消费的时候,还有一层消费组(Consumer Group)的概念:
<ul class="org-ul">
<li>每个消费者都属于一个消费组</li>
<li>当消息发布到主题后,只会被投递给每个(订阅这个主题的)消费组中的一个消费者</li>
</ul></li>
<li>如下图所示:
<ul class="org-ul">
<li><p>
图3-1
</p>

<div id="org99754dc" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-3-1.jpg" alt="ki-3-1.jpg" />
</p>
<p><span class="figure-number">Figure 8: </span>kafka/ki-3-1.jpg</p>
</div></li>
<li>某个主题公有4个分区:P0,P1,P2,P3</li>
<li>有两个消费组A,B都订阅了这个主题</li>
<li>消费组A有四个消费者C0,C1,C2,C3</li>
<li>消费组B有两个消费者C4,C5</li>
<li>按照kafka的规则,消费组A中的每个消费者分配到1个分区,消费组B中的每个消费者
分配到2个分区</li>
<li>每个消费者只能消费被分配的分区中的消息,换句话说,每个分区只能被一个消费组中
的一个消费者消费</li>
</ul></li>
<li>我们再来看看消费组内消费者个数变化时候对应分区的演变:</li>
<li><p>
下图3-2中开始消费组中只有一个消费者C0,他订阅了一个主题,包含7个分区P0~P6
</p>

<div id="orgacd07f7" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-3-2.jpg" alt="ki-3-2.jpg" />
</p>
<p><span class="figure-number">Figure 9: </span>kafka/ki-3-2.jpg</p>
</div></li>
<li><p>
下图3-3中消费者组内又加了新的消费者C1,按照鸡丁逻辑,会把C0之前的部分分区分配给C1消费
</p>

<div id="org1facc63" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-3-3.jpg" alt="ki-3-3.jpg" />
</p>
<p><span class="figure-number">Figure 10: </span>kafka/ki-3-3.jpg</p>
</div></li>
<li><p>
下图3-4中,又加入了C2,那么又会根据规则把一部分分区分给C2
</p>

<div id="orgdfe4059" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-3-4.jpg" alt="ki-3-4.jpg" />
</p>
<p><span class="figure-number">Figure 11: </span>kafka/ki-3-4.jpg</p>
</div></li>
<li>消费者和消费组这种模型,可以让整体的消费能力具备横向伸缩性,我们可以增加(或减
少)消费者的个数来提高(或降低)整体的消费能力</li>
<li>但是这个消费者的增加有上限的,就是消费者个数不能大于分区的个数,如果消费者个数
大于了分区个数,那么就会有消费者分配不到任何分区,如上图中的C7</li>
<li>上面的分配分区策略都是由partition.assignment.strategy来确定的</li>
<li>对于市面上的绝大多数消息中间件来说,一般有两种消息投递模式:
<ul class="org-ul">
<li><p>
点对点(P2P)模式: 这种模式基于队列,生产商发送消息到队列,消费者从队列中接收
消息,这种模式下
</p>
<pre class="example" id="org05af7c7">
每条消息只会被一个消费者消费(因为队列只能存取一次),kafka通过把所有消费者放到
同一个消费组里面来达到这个效果.因为消费者都在一个消费组里,所以每个消费者得到
一部分消息,而一个消息只会发送给消费组中的一个消费者
</pre></li>
<li><p>
发布/订阅(Pub/Sub)模式:这种模式基于topic(主题),发布者将消息发布到主题,订
阅者从主题中订阅消息,这种模式下
</p>
<pre class="example" id="org9424a67">
每条消息会重复的发送给所有的消费者(如果消费者订阅了topic),kafka通过把每个消费
者放到不同的消费组里面来达到消息.因为每个消费者在不同的消费组里面,因为每个消费组
都会得到一遍消息,那么每个消费组里面的消费者都能得到一遍所有消息
</pre></li>
</ul></li>
<li>消费组是一个逻辑上的概念,每个消费者只能隶属于一个消费组</li>
<li>每一个消费组都会有一个固定的名字,可以通过group.id来配置</li>
<li>和消费组不同,消费者不是逻辑上的概念,其为实际的实例,可以是一个县城,也可以是一
个进程.</li>
<li>同一个消费组内的消费者既可以部署在同一台机器上,也可以部署在不同的机器上</li>
</ul>
</div>
</div>
<div id="outline-container-org05ad1aa" class="outline-3">
<h3 id="org05ad1aa"><span class="section-number-3">3.2</span> 客户端开发</h3>
<div class="outline-text-3" id="text-3-2">
<ul class="org-ul">
<li>本文主要介绍新消费者Java语言编写的新客户端</li>
<li>一个正常的消费逻辑需要具备以下几个步骤:
<ol class="org-ol">
<li>配置消费者客户端参数,创建消费者实例</li>
<li>订阅主题</li>
<li>拉取消息并消费</li>
<li>提交消费位移</li>
<li>关闭消费者实例</li>
</ol></li>
<li><p>
全部代码如下
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">package</span> org.harri.kafka.<span style="color: #d3a0bc;">demo_3_1</span>;


<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">consumer</span>.<span style="color: #d9bb80;">ConsumerRecord</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">consumer</span>.<span style="color: #d9bb80;">ConsumerRecords</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">consumer</span>.<span style="color: #d9bb80;">KafkaConsumer</span>;

<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">time</span>.<span style="color: #d9bb80;">Duration</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d9bb80;">Arrays</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d9bb80;">Properties</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d3a0bc;">concurrent</span>.<span style="color: #d3a0bc;">atomic</span>.<span style="color: #d9bb80;">AtomicBoolean</span>;


<span style="color: #e68183;">public</span> <span style="color: #e68183;">class</span> <span style="color: #d9bb80;">KafkaConsumerAnalysis</span> {
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">brokerList</span> = <span style="color: #87af87;">"127.0.0.1:9092"</span>;
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span> = <span style="color: #87af87;">"harri-test-topic"</span>;
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">groupId</span> = <span style="color: #87af87;">"group.demo"</span>;
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">AtomicBoolean</span> <span style="color: #87c095; font-style: italic;">isRunning</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">AtomicBoolean</span>(<span style="color: #d3a0bc;">true</span>);

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095;">initConfig</span>() {
        <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">Properties</span>();
        props.put(<span style="color: #87af87;">"key.deserializer"</span>,
                <span style="color: #87af87;">"org.apache.kafka.common.serialization.StringDeserializer"</span>);
        props.put(<span style="color: #87af87;">"value.deserializer"</span>,
                <span style="color: #87af87;">"org.apache.kafka.common.serialization.StringDeserializer"</span>);
        props.put(<span style="color: #87af87;">"bootstrap.servers"</span>, brokerList);
        props.put(<span style="color: #87af87;">"group.id"</span>, groupId);
        props.put(<span style="color: #87af87;">"client.id"</span>, <span style="color: #87af87;">"consumer.client.id.demo"</span>);
        <span style="color: #e68183;">return</span> props;
    }

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">main</span>(<span style="color: #d9bb80;">String</span>[] <span style="color: #87c095; font-style: italic;">args</span>) {
        <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span> = initConfig();
        <span style="color: #d9bb80;">KafkaConsumer</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">consumer</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaConsumer</span>&lt;&gt;(props);
        consumer.subscribe(Arrays.asList(topic));

        <span style="color: #e68183;">try</span> {
            <span style="color: #e68183;">while</span> (isRunning.get()) {
                <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span> =
                        consumer.poll(Duration.ofMillis(1000));
                <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">record</span> : records) {
                    System.out.println(<span style="color: #87af87;">"topic = "</span> + record.topic()
                            + <span style="color: #87af87;">", partition = "</span> + record.partition()
                            + <span style="color: #87af87;">", offset = "</span> + record.offset()
                    );
                    System.out.println(<span style="color: #87af87;">"key = "</span> + record.key() + <span style="color: #87af87;">", value = "</span> + record.value());
                }
            }
        } <span style="color: #e68183;">catch</span> (<span style="color: #d9bb80;">Exception</span> <span style="color: #87c095; font-style: italic;">e</span>) {
            e.printStackTrace();
        } <span style="color: #e68183;">finally</span> {
            consumer.close();
        }
    }
}
</pre>
</div></li>
<li>我们后面来具体分析下代码</li>
</ul>
</div>
<div id="outline-container-orgef440ce" class="outline-4">
<h4 id="orgef440ce"><span class="section-number-4">3.2.1</span> 必要的参数设置</h4>
<div class="outline-text-4" id="text-3-2-1">
<ul class="org-ul">
<li>在Kafka消费者客户端KafkaConsumer中有四个参数是必填的:
<ul class="org-ul">
<li>bootstrap.servers:
<ol class="org-ol">
<li>该参数的释义和生产者客户端KafkaProducer中的相同</li>
<li>默认值为:""</li>
<li>可以设置多个地址,以逗号隔开</li>
</ol></li>
<li>group.id:
<ol class="org-ol">
<li>消费者隶属的消费组的名称</li>
<li>默认值为:""</li>
<li>这个参数一般设置为有一定业务意义的名称</li>
</ol></li>
<li>key.deserializer, value.deserializer:
<ol class="org-ol">
<li>消费者从broker获取的消息都是字节数组,需要执行相应的反序列化操作才能还
原成原有对象格式</li>
<li>默认值无</li>
</ol></li>
<li>client.id:
<ol class="org-ol">
<li>设置对应的客户端id</li>
<li>默认值为:""</li>
<li>如果不设置,KafkaConsumer会自动生成一个非空字符串,比如"consumer-"</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgf7cb8d6" class="outline-4">
<h4 id="orgf7cb8d6"><span class="section-number-4">3.2.2</span> 订阅主题与分区</h4>
<div class="outline-text-4" id="text-3-2-2">
<ul class="org-ul">
<li>我们使用subscribe()方法来订阅:
<ul class="org-ul">
<li><p>
可以以集合的形式订阅多个主题
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">subscribe</span>(<span style="color: #d9bb80;">Collection</span>&lt;<span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">topics</span>);
</pre>
</div></li>
<li><p>
也可以以正则表达式的形式订阅特定模式的主题
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">subscribe</span>(<span style="color: #d9bb80;">Pattern</span> <span style="color: #87c095; font-style: italic;">pattern</span>)
</pre>
</div></li>
</ul></li>
<li><p>
如果subscribe的参数是一个collection,那么就意味着订阅了几个topic,比如下面的
代码,当前消费者订阅了topic1和topic2两个topic
</p>
<div class="org-src-container">
<pre class="src src-java">consumer.subscribe(Arrays.asList(topic1, topic2));
</pre>
</div></li>
<li><p>
而下面的代码,则意味着最终订阅的只是topic2(后一次的设置会覆盖前一次的设置)
</p>
<div class="org-src-container">
<pre class="src src-java">consumer.subscribe(Arrays.<span style="color: #d9bb80;">asList</span>(<span style="color: #d9bb80;">topic1</span>));
consumer.subscribe(Arrays.asList(topic2));
</pre>
</div></li>
<li><p>
如果采用的是正则表达式的方式(subscrie(pattern)订阅,在这之后的过程中,如果有
人创建了新的topic,并且这个topic能够匹配正则表达式,那么这个消费者就可以消费
到新添加的topic中的消息,比如下面的消费者可以消费topic-a,topic-b, topic-c
这种topic名字
</p>
<div class="org-src-container">
<pre class="src src-java">consumer.subscribe(Patthern.compile(<span style="color: #87af87;">"topic-.*"</span>));
</pre>
</div></li>
<li>subscribe还可以带第二个参数,这个参数是用来设施再均衡监听器的</li>
<li><p>
消费者还可以通过assign()方法来具体订阅到某个分区
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">assign</span>(<span style="color: #d9bb80;">Collection</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">partitions</span>)
</pre>
</div></li>
<li><p>
其中的TopicParttion的定义如下:
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #e68183;">final</span> <span style="color: #e68183;">class</span> <span style="color: #d9bb80;">TopicPartition</span> <span style="color: #e68183;">implements</span> <span style="color: #d9bb80;">Serializable</span> {
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">int</span> <span style="color: #87c095; font-style: italic;">partition</span>;
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span>;
}
</pre>
</div></li>
<li><p>
我们可以使用partitionsFor来获取某个topic的详细信息(就包括分区信息),这样就
可以在assign函数里面设置不同分区啦.下面例子就是介绍如何订阅所有分区
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #d9bb80;">List</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">partitions</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">ArrayList</span>&lt;&gt;();
<span style="color: #d9bb80;">List</span>&lt;<span style="color: #d9bb80;">PartitionInfo</span>&gt; <span style="color: #87c095; font-style: italic;">partitionInfos</span> = consumer.partitionsFor(topic);
<span style="color: #e68183;">if</span> (partitionInfos != <span style="color: #d3a0bc;">null</span>) {
    <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">PartitionInfo</span> <span style="color: #87c095; font-style: italic;">tpInfo</span>: partitionInfos) {
        partitions.add(<span style="color: #e68183;">new</span> <span style="color: #d9bb80;">TopicPartition</span>(tpInfo.topic(), tpInfo.partition()));
    }
}
consumer.assign(partitions);
</pre>
</div></li>
<li>取消订阅有很多种方式:
<ul class="org-ul">
<li>使用unsubscribe();</li>
<li>使用subscribe()订阅其他的topic-new,就自动取消订阅了老的topic</li>
<li>使用assign()订阅新的partition-new,就自动取消订阅了之前老的topic</li>
</ul></li>
<li>如果没有订阅任何主题或分区,那么再执行消费程序的时候会报IllegalStateException</li>
<li><p>
通过subscribe()方法订阅主题具有消费者自动再均衡的功能
</p>
<pre class="example" id="org9f986e1">
在多个消费者的情况下,可以根据分区分配策略来自动分配各个消费者与分区的关系
当消费组内的消费者增加或者减少时,分区分配关系会自动调整,以实现消费负载均衡
极故障自动转移
</pre></li>
<li>通过assign()方法订阅分区,是不具备消费者自动均衡功能的</li>
</ul>
</div>
</div>
<div id="outline-container-org8d81869" class="outline-4">
<h4 id="org8d81869"><span class="section-number-4">3.2.3</span> 反序列化</h4>
<div class="outline-text-4" id="text-3-2-3">
<ul class="org-ul">
<li>和序列化的内容比较相似</li>
<li>如无特殊需要,作者不建议使用自定义的序列化器或反序列化器</li>
<li>对于普通类型,比如String,Kafka提供了非常好的序列化器,但是对于Company这种专用
类型而言,自己实现Serializer和Deserializer是非常困难的,所以在实际应用中,推荐
使用如下的序列化工具来进行序列化:
<ul class="org-ul">
<li>Avro</li>
<li>JSON</li>
<li>Thrift</li>
<li>ProtoBuf</li>
<li>Protostuff</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgb8a5fa7" class="outline-4">
<h4 id="orgb8a5fa7"><span class="section-number-4">3.2.4</span> 消息消费</h4>
<div class="outline-text-4" id="text-3-2-4">
<ul class="org-ul">
<li>kafka的消费是基于拉(Pull)模式的</li>
<li>从前面的代码可以看出,kafka的消费是一个不断轮询的过程,消费者所要做的就是重复
的调用poll()</li>
<li><p>
对于poll()方法而言,如果订阅的所有分区都没有可以消费的信息,那么poll()方法返
回空的消息集合
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">K</span>, <span style="color: #d9bb80;">V</span>&gt; <span style="color: #87c095;">poll</span>(<span style="color: #e68183;">final</span> <span style="color: #d9bb80;">Duration</span> <span style="color: #87c095; font-style: italic;">timeout</span>);
</pre>
</div></li>
<li>timeout用来控制poll()方法阻塞的时间,这个时间取决于应用程序对相应速度的要求:
<ul class="org-ul">
<li>比如需要快速相应的,可以设置为0</li>
<li>比如不需要快速响应,那么就设置为Long.MAX_VALUE</li>
</ul></li>
<li><p>
消费者处理的消息类型为ConsumerRecord(单数),相比于ProducerRecord,其内容更加丰富
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #e68183;">class</span> <span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">K</span>, <span style="color: #d9bb80;">V</span>&gt; {
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span>;
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">int</span> <span style="color: #87c095; font-style: italic;">partition</span>;
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">long</span> <span style="color: #87c095; font-style: italic;">offset</span>;
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">long</span> <span style="color: #87c095; font-style: italic;">timestamp</span>;
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">TimeStampType</span> <span style="color: #87c095; font-style: italic;">timestampType</span>;
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">int</span> <span style="color: #87c095; font-style: italic;">serializedKeySize</span>;
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">int</span> <span style="color: #87c095; font-style: italic;">serializedValueSize</span>;
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">Headers</span> <span style="color: #87c095; font-style: italic;">headers</span>;
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">K</span> <span style="color: #87c095; font-style: italic;">key</span>;
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">V</span> <span style="color: #87c095; font-style: italic;">value</span>;
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">volatile</span> <span style="color: #d9bb80;">Long</span> <span style="color: #87c095; font-style: italic;">checksum</span>;
}
</pre>
</div></li>
<li><p>
poll()返回的类型是ConsumerRecords(复数),表示一次拉取的消息集,IM包含了若干
ConsumerRecord,可以使用其iterator()方法来遍历:
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">Iterator</span>&lt;<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">K</span>, <span style="color: #d9bb80;">V</span>&gt;&gt; <span style="color: #87c095;">iterator</span>();
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-org1c7daa3" class="outline-4">
<h4 id="org1c7daa3"><span class="section-number-4">3.2.5</span> 位移提交</h4>
<div class="outline-text-4" id="text-3-2-5">
<ul class="org-ul">
<li>对于kafka中的分区而言,它的每条消息都有唯一的offset,用来表示其在分区中的位置</li>
<li>对于消费者而言,它也有一个offset的概念,用来表示消费到某个位置</li>
<li>中文可以对这两个offset进行区分:
<ul class="org-ul">
<li>对于消息在分区中的位置:我们将offset翻译为"偏移量"</li>
<li>对于消费者消费到的位置:我们将offset翻译为"位移"或者"消费位移"</li>
</ul></li>
<li>每次调用poll()方法的时候,它返回的是还没有被消费过的消息集合,要做到这一点就
需要记录上一次的消费位移,并且要持久化存储,不能放在内存里面,否则消费者重启
后就无法知晓之前的消费位移</li>
<li>有新消费者加入的时候,由于要做均衡操作,对于一个分区而言,如果不持久化消费位移,
那么一旦把这个分区分配给新消费者,则无法通知新消费者消费位移</li>
<li>在旧的消费者客户端中,消费位移是存储在ZooKeeper中的</li>
<li>而在新消费者客户端中,消费位移存储在Kafka内部的主题__consumer_offset中</li>
<li><p>
我们把消费位移存储起来(持久化)的动作称之为"提交"
</p>
<pre class="example" id="org7bbfcfe">
消费者在消费完之后需要执行消费位移的提交
</pre></li>
<li>下图就是一个消费位移的解释:
<ul class="org-ul">
<li><p>
图3-6
</p>

<div id="org4b276a8" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-3-6.jpg" alt="ki-3-6.jpg" />
</p>
<p><span class="figure-number">Figure 12: </span>kafka/ki-3-6.jpg</p>
</div></li>
<li>x表示某次拉取操作,此分区的最大偏移量</li>
<li>当前消费者需要提交的消费位移,则是x+1,也就是上图position的位置</li>
<li>position位置也是下一条要拉取的消息的位置</li>
</ul></li>
<li>我们来用一个例子来看下如下三个概念的关系:
<ul class="org-ul">
<li>lastConsumedOffset: 如果没消费过,就是-1</li>
<li>commited offset</li>
<li>position</li>
</ul></li>
<li><p>
代码如下
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">package</span> org.harri.kafka.<span style="color: #d3a0bc;">demo_3_2</span>;

<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">consumer</span>.*;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">common</span>.<span style="color: #d9bb80;">TopicPartition</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">common</span>.<span style="color: #d3a0bc;">serialization</span>.<span style="color: #d9bb80;">StringDeserializer</span>;

<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d9bb80;">Arrays</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d9bb80;">List</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d9bb80;">Properties</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d3a0bc;">concurrent</span>.<span style="color: #d3a0bc;">atomic</span>.<span style="color: #d9bb80;">AtomicBoolean</span>;


<span style="color: #e68183;">public</span> <span style="color: #e68183;">class</span> <span style="color: #d9bb80;">CheckOffsetAndPosition</span> {
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">brokerList</span> = <span style="color: #87af87;">"localhost:9092"</span>;
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span> = <span style="color: #87af87;">"harri-test-topic"</span>;
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">groupId</span> = <span style="color: #87af87;">"group.demo"</span>;
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">AtomicBoolean</span> <span style="color: #87c095; font-style: italic;">running</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">AtomicBoolean</span>(<span style="color: #d3a0bc;">true</span>);

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095;">initConfig</span>() {
        <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">Properties</span>();
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.KEY_DESERIALIZER_CLASS_CONFIG,
                StringDeserializer.<span style="color: #e68183;">class</span>.getName());
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.VALUE_DESERIALIZER_CLASS_CONFIG,
                StringDeserializer.<span style="color: #e68183;">class</span>.getName());
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.BOOTSTRAP_SERVERS_CONFIG, brokerList);
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.GROUP_ID_CONFIG, groupId);
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.AUTO_OFFSET_RESET_CONFIG, <span style="color: #87af87;">"earliest"</span>);
        <span style="color: #e68183;">return</span> props;
    }

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">main</span>(<span style="color: #d9bb80;">String</span>[] <span style="color: #87c095; font-style: italic;">args</span>) {
        <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span> = initConfig();
        <span style="color: #d9bb80;">KafkaConsumer</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">consumer</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaConsumer</span>&lt;&gt;(props);


        <span style="color: #d9bb80;">TopicPartition</span> <span style="color: #87c095; font-style: italic;">tp</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">TopicPartition</span>(topic, 0);
        consumer.assign(Arrays.asList(tp));
        <span style="color: #d9bb80;">long</span> <span style="color: #87c095; font-style: italic;">lastConsumedOffset</span> = -1;
        <span style="color: #e68183;">while</span> (<span style="color: #d3a0bc;">true</span>) {
            <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span> = consumer.poll(1000);
            <span style="color: #e68183;">if</span> (records.isEmpty()) {
                <span style="color: #e68183;">break</span>;
            }
            <span style="color: #d9bb80;">List</span>&lt;<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt;&gt; <span style="color: #87c095; font-style: italic;">partitionRecords</span>
                    = records.records(tp);
            lastConsumedOffset = partitionRecords
                    .get(partitionRecords.size() - 1).offset();
            consumer.commitSync();<span style="color: #5b5b5b;">//</span><span style="color: #5b5b5b;">&#21516;&#27493;&#25552;&#20132;&#28040;&#36153;&#20301;&#31227;</span>
        }
        System.out.println(<span style="color: #87af87;">"comsumed offset is "</span> + lastConsumedOffset);
        <span style="color: #d9bb80;">OffsetAndMetadata</span> <span style="color: #87c095; font-style: italic;">offsetAndMetadata</span> = consumer.committed(tp);
        System.out.println(<span style="color: #87af87;">"commited offset is "</span> + offsetAndMetadata.offset());
        <span style="color: #d9bb80;">long</span> <span style="color: #87c095; font-style: italic;">posititon</span> = consumer.position(tp);
        System.out.println(<span style="color: #87af87;">"the offset of the next record is "</span> + posititon);
    }
}

<span style="color: #5b5b5b;">// </span><span style="color: #5b5b5b;">&lt;===================OUTPUT===================&gt;</span>
<span style="color: #5b5b5b;">// </span><span style="color: #5b5b5b;">comsumed offset is 37</span>
<span style="color: #5b5b5b;">// </span><span style="color: #5b5b5b;">commited offset is 38</span>
<span style="color: #5b5b5b;">// </span><span style="color: #5b5b5b;">the offset of the next record is 38</span>
</pre>
</div></li>
<li>我们可以看到,在这个例子中:
<ul class="org-ul">
<li>最大消费偏移是37,也就是消费到了37</li>
<li>执行同步commit之后的commited offset是38</li>
<li>position是38,也就是37的下一个位置(当前position和commited offset一致,但是
以后可能会不一样)</li>
</ul></li>
<li>对于位移提交的具体世纪把握很有讲究,比如下图的例子:
<ul class="org-ul">
<li><p>
图3-7
</p>

<div id="org67962d7" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-3-7.jpg" alt="ki-3-7.jpg" />
</p>
<p><span class="figure-number">Figure 13: </span>kafka/ki-3-7.jpg</p>
</div></li>
<li>当前poll()拉取的是[x+2,x+7]</li>
<li>其中x+2是last commited offset,说明x+1之前的(包括x+1)都已经消费完了</li>
<li>当前消费的是x+5</li>
<li>如果现在就去commit offset,那么提交的位置是x+8</li>
<li>如果commit x+8之后遇到了异常,那么重新恢复后,是从x+8开始的,[x+5,x+7]之间就丢失了</li>
<li>如果是消费完x+7之后,才提交offset,那么当我们处理x+5的时候遇到crash,那么下
次还是从x+2开始,也就是说[x+2,x+4]就重复消费了.</li>
<li>实践当中还有更加复杂的情况</li>
</ul></li>
<li>kafka默认的消费位移的提交方式是自动提交,这个是有消费者客户端的参数enable.auto.commit配置,默认值为true</li>
<li>自动提交不是每消费一条就提交一次,而是定期提交,定期的时间由auto.commit.interval.ms
配置,默认为5秒.此参数生效的默认前提是enable.auto.commit为true</li>
<li>默认情况下,消费者会把当前分区的最大消息位移提交</li>
<li>自动提交的逻辑是在poll()里面完成的,每次发起请求拉取新数据之前,会检查是否可
以提交位移,可以的话,就会提交上一次轮询的位移</li>
<li>自动提交有可能在提交的那一刻,消费者crash,重新recover的时候,会从上次的commited
offset开始,所以很容易造成重复消费.</li>
<li>减小位移提交的时间间隔能够减小重复消费的概率,但是不能杜绝,还会带来更加频繁的提交</li>
<li>自动提交也可能会发生丢失消息,特别是拉取和消费分开的情况下,如下图:
<ul class="org-ul">
<li><p>
图3-8
</p>

<div id="org5ee03fb" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-3-8.jpg" alt="ki-3-8.jpg" />
</p>
<p><span class="figure-number">Figure 14: </span>kafka/ki-3-8.jpg</p>
</div></li>
<li>线程A负责从kafka拉取消息,并且auto commit (在poll函数里面)</li>
<li>线程A自己不消费,放到BlockingQueue里面让其他线程消费</li>
<li>线程B消费BlockingQueue</li>
<li>线程A第y次成功拉取后,把数据放到BlockingQueue里面,然后由于queue里面还有位
置,就进行第y+1次拉取,这次拉取会commit x+6</li>
<li>当前线程B还在处理x+3,如果发生crash,那么下次来,就只能从x+6开始了,[x+3,x+6]
就丢失了</li>
</ul></li>
<li>自动位移提交在正常情况下不会发生消息丢失或重复消费.但是在"异常"情况下,无法
避免.而异常(exception)对于程序来说,是无法避免的</li>
<li>另外自动位移提交也无法做到精确的位移管理</li>
<li>基于以上两条原因,kafka还提供了手动位移提交的方式</li>
<li><p>
前面说过,kafka客户端是在poll的时候,commit上次拉取的位移,这是基于一种假设
</p>
<pre class="example" id="org6bc79ab">
在拉取新的数据之前,老的数据已经消费完毕了
</pre></li>
<li>但是在很多时候,上面的假设是不成立的,因为真正成功消费数据,可能需要写入数据库,
存入缓存,或者更加复杂的业务处理</li>
<li>手动提交就可以让应用开发者,在业务层面确认消费完毕后再合适的地方进行位移提交</li>
<li><p>
开启手动提交功能的前提是消费者客户端参数enable.auto.commit设置为false
</p>
<div class="org-src-container">
<pre class="src src-java">props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.<span style="color: #d9bb80;">ENABLE_AUTO_COMMIT_CONFIG</span>, <span style="color: #d3a0bc;">false</span>);
</pre>
</div></li>
<li>手动提交又分:
<ul class="org-ul">
<li>同步提交
<ol class="org-ol">
<li><p>
方法定义如下:
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">commitSync</span>()
</pre>
</div></li>
<li><p>
最简单的用法就是每次消费完就同步提交
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">while</span> (isRunning.get()) {
    <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span> = consumer.poll(1000);
    <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">record</span>: records) {
        <span style="color: #5b5b5b;">// </span><span style="color: #5b5b5b;">do some logical processing.</span>
        consumer.commitSync();
    }
}
</pre>
</div></li>
<li><p>
深入一点,可以使用批量处理+批量提交的方式
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">final</span> <span style="color: #d9bb80;">int</span> <span style="color: #87c095; font-style: italic;">minBatchSize</span> = 200;

<span style="color: #d9bb80;">List</span>&lt;<span style="color: #d9bb80;">ConsumerRecord</span>&gt; <span style="color: #87c095; font-style: italic;">buffer</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">ArrayList</span>&lt;&gt;();
<span style="color: #e68183;">while</span> (isRunning.get()) {
    <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span> = consumer.poll(1000);
    <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">record</span>: records) {
        buffer.add(record);
    }
    <span style="color: #e68183;">if</span> (buffer.size() &gt;= minBatchSize) {
        <span style="color: #5b5b5b;">// </span><span style="color: #5b5b5b;">do some logical processing with buffer.</span>
        consumer.commitSync();
        buffer.clear();
    }
}
</pre>
</div></li>
<li>上面两个例子都有重复消费的问题:在业务逻辑处理之后,在同步唯一提交之前,
如果程序崩溃,那么回复之后,还是要从上次commit的位移处重新消费一次.</li>
<li>commitSync()在提交的时候,只要没有发生不可恢复的错误(Unrecoverable Error),
它就会block当前的消费线程(或者进程),知道位移提交完成</li>
<li>commitSync()可以捕获如下异常,并做针对性处理:
<ul class="org-ul">
<li>CommitFiledException</li>
<li>WakeupException</li>
<li>InterruptException</li>
<li>AuthenticationException</li>
<li>AuthorizationException</li>
</ul></li>
<li><p>
对于commitSync()的无参数方法来说,其只能提交poll提供的位移,显得不够灵活,
如果想要更灵活的提交,需要更细粒度的commitSync()的另外一个重载函数
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">commitSync</span>(<span style="color: #e68183;">final</span> <span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">OffsetAnMetaata</span>&gt; <span style="color: #87c095; font-style: italic;">offsets</span>)
</pre>
</div></li>
<li><p>
我们看一个上面函数的例子:
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">while</span> (isRnning.get()) {
    <span style="color: #d9bb80;">ConsumerRcords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span> = consumer.poll(1000);
    <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">record</span>: records) {
        <span style="color: #d9bb80;">long</span> <span style="color: #87c095; font-style: italic;">offset</span> = record.offset();
        <span style="color: #d9bb80;">TopicPartition</span> <span style="color: #87c095; font-style: italic;">partition</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">TopicPartition</span>(record.topic(), record.partition());
        consumer.commitSync(Collections.singletonMap(partition, <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">OffsetAndMetadata</span>(offset+1)));
    }
}
</pre>
</div></li>
<li>上面的例子把commit的粒度应该是最小了,每个message都有一次提交.这种粒度
的场景基本不存在,因为commitSync()本来就是同步执行,会消耗性能,而每个message
一次性能的消耗,会让整个代码的性能降低的非常厉害</li>
<li><p>
更多的时候,提交的粒度不需要到message,到分区就已经足够了
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">main</span>(<span style="color: #d9bb80;">String</span>[] <span style="color: #87c095; font-style: italic;">args</span>) {
    <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span> = initConfig();
    <span style="color: #d9bb80;">KafkaConsumer</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">consumer</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaConsumer</span>&lt;&gt;(props);
    consumer.subscribe(Arrays.asList(topic));

    <span style="color: #e68183;">try</span> {
        <span style="color: #e68183;">while</span> (running.get()) {
            <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span> = consumer.poll(1000);
            <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">TopicPartition</span> <span style="color: #87c095; font-style: italic;">partition</span> : records.partitions()) {
                <span style="color: #d9bb80;">List</span>&lt;<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt;&gt; <span style="color: #87c095; font-style: italic;">partitionRecords</span> =
                        records.records(partition);
                <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">record</span> : partitionRecords) {
                    <span style="color: #5b5b5b;">//</span><span style="color: #5b5b5b;">do some logical processing.</span>
                }
                <span style="color: #d9bb80;">long</span> <span style="color: #87c095; font-style: italic;">lastConsumedOffset</span> = partitionRecords
                        .get(partitionRecords.size() - 1).offset();
                consumer.commitSync(Collections.singletonMap(partition,
                        <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">OffsetAndMetadata</span>(lastConsumedOffset + 1)));
            }
        }
    } <span style="color: #e68183;">finally</span> {
        consumer.close();
    }
}
</pre>
</div></li>
</ol></li>
<li>异步提交
<ol class="org-ol">
<li>与commitSync()相反,异步提交在执行的时候,消费者线程(或进程)不阻塞,可能
提交消费位移还没成功,poll就已经开始拉取新的数据了</li>
<li><p>
异步提交commitAsync有三个重载方法
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">commitAsync</span>();
<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">commitAsync</span>(<span style="color: #d9bb80;">OffsetCommitCallback</span> <span style="color: #87c095; font-style: italic;">callback</span>);
<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">commitAsync</span>(<span style="color: #e68183;">final</span> <span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">OffsetAndMetadata</span>&gt; <span style="color: #87c095; font-style: italic;">offset</span>,
                        <span style="color: #d9bb80;">OffsetCommitCallback</span> <span style="color: #87c095; font-style: italic;">callback</span>);

</pre>
</div></li>
<li><p>
参数中的callback是一个回调,当位移提交之后,回去调用OffsetCommitCallback
中的onComplete()方法
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">while</span> (running.get()) {
    <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span> = consumer.poll(1000);
    <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">record</span> : records) {
        <span style="color: #5b5b5b;">//</span><span style="color: #5b5b5b;">do some logical processing.</span>
    }
    consumer.commitAsync(<span style="color: #e68183;">new</span> <span style="color: #d9bb80;">OffsetCommitCallback</span>() {
        <span style="color: #d3a0bc;">@Override</span>
        <span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">onComplete</span>(<span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">OffsetAndMetadata</span>&gt; <span style="color: #87c095; font-style: italic;">offsets</span>,
                               <span style="color: #d9bb80;">Exception</span> <span style="color: #87c095; font-style: italic;">exception</span>) {
            <span style="color: #e68183;">if</span> (exception == <span style="color: #d3a0bc;">null</span>) {
                System.out.println(offsets);
            } <span style="color: #e68183;">else</span> {
                log.error(<span style="color: #87af87;">"fail to commit offsets {}"</span>, offsets, exception);
            }
        }
    });
}
</pre>
</div></li>
<li>commitAsync()提交的时候,如果发生了失败,那么不要去重试,因为:
<ul class="org-ul">
<li>commit 第N次提交位置X失败,准备重试</li>
<li>重试还没有成功的时候,commit N+1次成功提交了位置X+Y</li>
<li>重试成功,commit X成功</li>
<li>最终的结果是位移从X+Y,返回了X</li>
</ul></li>
<li>一个可能的改进是记录每次的commit值,在失败需要重试的时候,检查这个值,如
果这个值已经大于自己要重试的位移,那么我们就不需要再次提交老位移了</li>
<li>如果位移提交失败的情况经常发生,那么系统肯定出现了问题</li>
<li>一般情况下,位移提交失败的情况很少发生,也就不需要重试,因为后面的提交也会成功</li>
<li><p>
消费者在正常退出的情况下,可以在退出之前使用同步提交的方式做最后的把关
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">main</span>(<span style="color: #d9bb80;">String</span>[] <span style="color: #87c095; font-style: italic;">args</span>) {
    <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span> = initConfig();
    <span style="color: #d9bb80;">KafkaConsumer</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">consumer</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaConsumer</span>&lt;&gt;(props);
    consumer.subscribe(Arrays.asList(topic));

    <span style="color: #e68183;">try</span> {
        <span style="color: #e68183;">while</span> (running.get()) {
            <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span> = consumer.poll(1000);
            <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">record</span> : records) {
                <span style="color: #5b5b5b;">//</span><span style="color: #5b5b5b;">do some logical processing.</span>
            }
            consumer.commitAsync(<span style="color: #e68183;">new</span> <span style="color: #d9bb80;">OffsetCommitCallback</span>() {
                <span style="color: #d3a0bc;">@Override</span>
                <span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">onComplete</span>(<span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">OffsetAndMetadata</span>&gt; <span style="color: #87c095; font-style: italic;">offsets</span>,
                                       <span style="color: #d9bb80;">Exception</span> <span style="color: #87c095; font-style: italic;">exception</span>) {
                    <span style="color: #e68183;">if</span> (exception == <span style="color: #d3a0bc;">null</span>) {
                        System.out.println(offsets);
                    } <span style="color: #e68183;">else</span> {
                        log.error(<span style="color: #87af87;">"fail to commit offsets {}"</span>, offsets, exception);
                    }
                }
            });
        }
    } <span style="color: #e68183;">finally</span> {
        consumer.close();
    }

    <span style="color: #5b5b5b;">//</span>
    <span style="color: #e68183;">try</span> {
        <span style="color: #e68183;">while</span> (running.get()) {
            <span style="color: #5b5b5b;">//</span><span style="color: #5b5b5b;">poll records and do some logical processing.</span>
            consumer.commitAsync();
        }
    } <span style="color: #e68183;">finally</span> {
        <span style="color: #e68183;">try</span> {
            consumer.commitSync();
        } <span style="color: #e68183;">finally</span> {
            consumer.close();
        }
    }
}
</pre>
</div></li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org622e5a8" class="outline-4">
<h4 id="org622e5a8"><span class="section-number-4">3.2.6</span> 控制或关闭消费</h4>
<div class="outline-text-4" id="text-3-2-6">
<ul class="org-ul">
<li>KafkaConsumer提供了对消费速度进行控制的方法,有些应用场景下,可能需要暂停某些
分区消费而先消费其他分区,使用的api是:
<ul class="org-ul">
<li><p>
pause(): 暂停某些分区拉取数据返回给客户端
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">pause</span>(<span style="color: #d9bb80;">Collection</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">partitions</span>)
</pre>
</div></li>
<li><p>
resume(): 恢复某些分区想客户端返回数据
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">resume</span>(<span style="color: #d9bb80;">Collection</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">partitions</span>)
</pre>
</div></li>
</ul></li>
<li><p>
KafkaConsumer还提供了一个无参数的paused()方法来返回被暂停的分区结合
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">Set</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095;">paused</span>()
</pre>
</div></li>
<li>我们在while循环里面运行poll(),如何退出这个while循环有几种思路:
<ul class="org-ul">
<li>我们前面代码中的while(isRunning.get()), 这样可以在其他的线程里面设置isRunning.set(false)</li>
<li>调用KafkaConsumer wakeup()方法: wakeup方法是KafkaConsumer中位移可以从其他
线程里安全调用的方法. wakeup()可以退出poll()逻辑,并且抛出WakeupException异常,
这个异常我们不需要处理,这只不过是一种跳出循环的方式</li>
</ul></li>
<li>关闭KafkaConsumer的方法是close(),有三个重载:
<ul class="org-ul">
<li><p>
最多等待30秒的关闭
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">close</span>()
</pre>
</div></li>
<li><p>
设置超时的close
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">close</span>(<span style="color: #d9bb80;">Duration</span> <span style="color: #87c095; font-style: italic;">timeout</span>)
</pre>
</div></li>
<li><p>
已经不再使用的方法
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #d3a0bc;">@Deprecated</span>
<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">close</span>(<span style="color: #d9bb80;">long</span> <span style="color: #87c095; font-style: italic;">timeout</span>, <span style="color: #d9bb80;">TimeUnit</span> <span style="color: #87c095; font-style: italic;">timeUnit</span>)
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org2d6a2cc" class="outline-4">
<h4 id="org2d6a2cc"><span class="section-number-4">3.2.7</span> 指定位移消费</h4>
<div class="outline-text-4" id="text-3-2-7">
<ul class="org-ul">
<li>前面我们讲了如何进行消费位移的提交,正是因为消费位移的持久化,才能让消费者在
关闭,崩溃或者遇到再均衡的时候,可以让接替的消费者能够根据存储的消费位移继续进行消费</li>
<li>一个新的消费者,通常会在开始的时候,去__consumer_offsets里面查找当前消费组的
的位移信息,但是这个__consumer_offset的位移信息可能会因为过期而被删除</li>
<li>一旦__consumer_offset的位移信息因为过期而被删除,当消费者找不到持久化的消费
位移的情况下,会根据客户端参数auto.offset.reset来决定如何消费:
<ul class="org-ul">
<li>latest(默认值):表示从分区末尾开始消费(如果能查找到提交的消费位移,从提交的
消费位移开始,新的消费组因为没有提交的消费位移,自然是从最新开始)</li>
<li>earliest:表示消费者从起始处开始消费(如果能查找到提交的消费位移,从提交的
消费位移开始,新的消费组因为没有提交的消费位移,自然是从最老开始)</li>
<li>none: 查找不到消费位移的情况下,直接报NoOffsetForPartitionException异常</li>
</ul></li>
<li>只有上面三个值是可配置的,写任何其他的字符串会报ConfigException异常</li>
<li><p>
前面的poll()方法提交消费位移同时拉取新数据,其执行是一个黑盒,如果我们想要一
种更细粒度的掌控,我们可以从特定的位移处开始拉取消息,KafkaConsumer的seek()
方法提供了这个功能
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">seek</span>(<span style="color: #d9bb80;">TopicPartition</span> <span style="color: #87c095; font-style: italic;">partition</span>, <span style="color: #d9bb80;">long</span> <span style="color: #87c095; font-style: italic;">offset</span>)
</pre>
</div></li>
<li>seek()方法中的参数partition表示分区,offset表示分区中哪个位置开始</li>
<li>seek()方法的partition需要是消费者被分配到的分区,而这个分配过程是在poll()里
面实现的,所以换句话说在执行seek()方法之前,要执行一次poll()方法,之后才能知道
自己的分区,才能重置offset</li>
<li><p>
下面代码是seek的使用方法
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #d9bb80;">KafkaConsumer</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">consumer</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaConsumer</span>&lt;&gt;(props);
consumer.subscribe(Arrays.asList(topic));
consumer.poll(Duration.ofMillis(10000));
<span style="color: #d9bb80;">Set</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">assignment</span> = consumer.assignment();
<span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">TopicPartition</span> <span style="color: #87c095; font-style: italic;">tp</span> : assignment) {
    consumer.seek(tp, 10);
}

<span style="color: #e68183;">while</span> (<span style="color: #d3a0bc;">true</span>) {
    <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span> =
        consumer.poll(Duration.ofMillis(1000));
}
</pre>
</div></li>
<li><p>
上面直接设置了10000毫秒来获取分区信息,这个太久了,但是到底设置多少合适呢?我
们可以使用下面的逻辑来每100毫秒来测试下是否获取到了topic
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #d9bb80;">KafkaConsumer</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">consumer</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaConsumer</span>&lt;&gt;(props);
consumer.subscribe(Arrays.asList(topic));
<span style="color: #d9bb80;">Set</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">assignment</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">HashSet</span>&lt;&gt;();

<span style="color: #e68183;">while</span> (assignment.size() == 0) {
    consumer.poll(Duration.ofMillis(100));
    assignment = consumer.assignment();
}

<span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">TopicPartiton</span> <span style="color: #87c095; font-style: italic;">tp</span> : assignment) {
    consumer.seek(tp, 10);
}

<span style="color: #e68183;">while</span> (<span style="color: #d3a0bc;">true</span>) {
    <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span> =
        consumer.poll(Duration.ofMillis(1000));
    <span style="color: #5b5b5b;">// </span><span style="color: #5b5b5b;">consume the record</span>
}
</pre>
</div></li>
<li>如果对未分配的分区执行seek(),那么会爆出IllegalStateException异常:
<ul class="org-ul">
<li><p>
异常代码: subscribe之后里面seek
</p>
<div class="org-src-container">
<pre class="src src-java">consumer.subscribe(Arrays.<span style="color: #d9bb80;">asList</span>(<span style="color: #d9bb80;">topic</span>));
consumer.seek(<span style="color: #e68183;">new</span> <span style="color: #d9bb80;">TopicPartition</span>(topic, 0), 10);
</pre>
</div></li>
</ul></li>
<li><p>
我们前面说过
</p>
<pre class="example" id="orgb7bd4d5">
auto.offset.reset设置起作用的前提,是消费者在启动的时候找不到消费位移
</pre></li>
<li><p>
如果启动的时候,消费者找到了位移,那么如果还想指定从头(或者从尾)开始消费,就需要seek()方法了
下面就是一个从尾开始消费的例子
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #d9bb80;">KafkaConsumer</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">consumer</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaConsumer</span>&lt;&gt;(props);
consumer.subscrib(Arrays.asList(topic));
<span style="color: #d9bb80;">Set</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">assignment</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">HashSet</span>&lt;&gt;();
<span style="color: #e68183;">while</span> (assignment.size() == 0) {
    consumer.poll(Duration.ofMillis(100));
    assignment = consumer.assignment();
}
<span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">Long</span>&gt; <span style="color: #87c095; font-style: italic;">offsets</span> = consumer.endOffsets(assignment);
<span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">TopicPartition</span> <span style="color: #87c095; font-style: italic;">tp</span> : assignment) {
    consumer.seek(tp, offsets.get(tp));
}
</pre>
</div></li>
<li><p>
上面例子的endOffsets()函数是用来获取指定分区末尾消息的位置
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #5b5b5b;">// </span><span style="color: #5b5b5b;">timeout &#19981;&#35774;&#32622;,&#20250;&#20351;&#29992;request.timeout.ms,&#40664;&#35748;&#20540;&#26159;30000</span>
<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">Long</span>&gt; <span style="color: #87c095;">endOffsets</span>(<span style="color: #d9bb80;">Collection</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">partitions</span>);


<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">Long</span>&gt; <span style="color: #87c095;">endOffsets</span>(<span style="color: #d9bb80;">Collection</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">partitions</span>,
                                            <span style="color: #d9bb80;">Duration</span> <span style="color: #87c095; font-style: italic;">timeout</span>);



</pre>
</div></li>
<li><p>
与此对应的是还有beginningOffsets()函数,注意beginningOffsets的返回值并不一定是0,
因为日志清理动作会清理旧的数据,所以其起始位置也会变化
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #5b5b5b;">// </span><span style="color: #5b5b5b;">timeout &#19981;&#35774;&#32622;,&#20250;&#20351;&#29992;request.timeout.ms,&#40664;&#35748;&#20540;&#26159;30000</span>
<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">Long</span>&gt; <span style="color: #87c095;">beginningOffsets</span>(<span style="color: #d9bb80;">Collection</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">partitions</span>);


<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">Long</span>&gt; <span style="color: #87c095;">beginningOffsets</span>(<span style="color: #d9bb80;">Collection</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">partitions</span>,
                                            <span style="color: #d9bb80;">Duration</span> <span style="color: #87c095; font-style: italic;">timeout</span>);



</pre>
</div></li>
<li><p>
由于seek开头和seek结尾的操作过于常用,系统还提供了两种方法来实现查找头或者尾,并且马上seek
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">seekToBeginning</span>(<span style="color: #d9bb80;">Collection</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">partitions</span>);
<span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">seekToEnd</span>(<span style="color: #d9bb80;">Collection</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>&gt; <span style="color: #87c095; font-style: italic;">partitions</span>);
</pre>
</div></li>
<li><p>
大多数情况下,我们并不知道offset的位置,我们只知道一个相关的时间点(比如程序在这个点崩溃的)
KafkaConsumer同样考虑到了这种情况,提供了一个offsetsForTimes()的方法,可以通过timestamp
来查询与此对应的分区位置
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">OffsetAndTimeStamp</span>&gt; <span style="color: #87c095;">offsetsForTimes</span>(<span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">Long</span>&gt; <span style="color: #87c095; font-style: italic;">timestampsToSearch</span>);
</pre>
</div></li>
<li><p>
下面的例子就是获取一天前的消息位置,然后使用seek()方法追溯并消费
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">Long</span>&gt; <span style="color: #87c095; font-style: italic;">timestampToSearch</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">HashMap</span>&lt;&gt;();
<span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">TopicPartition</span> <span style="color: #87c095; font-style: italic;">tp</span> : assignment) {
    timestampToSearch.put(tp, System.currentTimeMillis() - 1 * 24 * 3600 * 1000);
}

<span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartition</span>, <span style="color: #d9bb80;">OffsetAndTimestamp</span>&gt; <span style="color: #87c095; font-style: italic;">offsets</span> =
    consumer.offsetsForTimes(timestampToSearch);

<span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">TopicPartition</span> <span style="color: #87c095; font-style: italic;">tp</span> : assignment) {
    <span style="color: #d9bb80;">OffsetAndTimestamp</span> <span style="color: #87c095; font-style: italic;">offsetAndTImestamp</span> = offsets.get(tp);
    <span style="color: #e68183;">if</span> (offsetAndTImestamp != <span style="color: #d3a0bc;">null</span>) {
        consumer.seek(tp, offsetAndTimestamp.offset());
    }
}
</pre>
</div></li>
<li><p>
位移如果越界设置,也会触发auto.offset.reset参数(earliest, latest, none)的执行
</p>
<pre class="example" id="org7b36b18">
所谓位移越界,是指知道消费位置,却无法在实际分区中查到
</pre></li>
<li>seek()的出现,让我们的位移存储突破了原有的存储方法(0.9之后kafka的offset信息
都存储在boroker的一个名为__consumer_offsets的topic中)限制,现在,我们可以使用其他
持久化存储来完成,比如我们可以把offset存储到数据库或者文件系统,下次消费的时候
从数据库或者文件中读取,然后seek()到这个位置进行消费</li>
</ul>
</div>
</div>
<div id="outline-container-org1e2b570" class="outline-4">
<h4 id="org1e2b570"><span class="section-number-4">3.2.8</span> 再均衡</h4>
<div class="outline-text-4" id="text-3-2-8">
<ul class="org-ul">
<li>再均衡是指分区所属权从一个消费者转移到另外一个消费者的行为</li>
<li>再均衡有很多的缺点:
<ul class="org-ul">
<li>再均衡发生期间,消费组不可用</li>
<li>当一个分区被重新分配个另外一个消费者的时候,消费者当前状态会消失,这通常会导致
重复消费,比如:消费者完成某个分区中的一部分消息消费,但是还没来得及提交消费位移
就发生了再均衡操作.之后这个分区被分配给了另一个消费者,原来被消费完(但是没有提交)
的消息又被消费了一遍</li>
</ul></li>
<li>所以,一般情况下,我们尽量避免不必要的再均衡发生</li>
<li>subscribe()函数里面涉及到再均衡监听器:
<ul class="org-ul">
<li>onPartitionRevoked:这是是在消费者停止读取之后,再均衡发生之前被调用,可以用
这个回调方法来处理消费位移的提交,以此来避免一些不必要的重复消费发生</li>
<li>onPartitionAssegned:这是是在冲洗分配分区之后,消费者开始读取消费之前被调用</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org255854e" class="outline-4">
<h4 id="org255854e"><span class="section-number-4">3.2.9</span> 消费者拦截器</h4>
<div class="outline-text-4" id="text-3-2-9">
<ul class="org-ul">
<li>消费者拦截器会在:
<ul class="org-ul">
<li>poll()方法返回之前调用拦截器的onConsume()方法,来对消息进行定制化操作,比如按照某种
规则过滤消息(可能让poll()方法返回的消息个数减小).</li>
<li>提交完消费位移之后,会调用拦截器的onCommit()方法,可以使用这个方法来记录所
提交的位移信息,比如commitSync()完成时,我们不知道提交的具体细节,这时候能从
onCommit()方法中读取这些信息</li>
</ul></li>
<li><p>
下面我们来看一个拦截器使用的例子:在某些场景下,消息收到后,如果和当前的时间戳差距过大,
那么会被认为是无效消息,那么就不会从poll()中返回
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">public</span> <span style="color: #e68183;">class</span> <span style="color: #d9bb80;">ConsumerInterceptorTTL</span> <span style="color: #e68183;">implements</span> <span style="color: #d9bb80;">ConsumerInterceptor</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; {
    <span style="color: #e68183;">private</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">long</span> <span style="color: #87c095; font-style: italic;">EXPIRE_INTERVAL</span> = 10 * 1000;
    <span style="color: #d3a0bc;">@Override</span>
    <span style="color: #e68183;">public</span> <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095;">onConsume</span>(<span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span>) {
        <span style="color: #d9bb80;">long</span> <span style="color: #87c095;">now</span> System.currentTImeMillis();
        <span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartiton</span>, <span style="color: #d9bb80;">List</span>&lt;<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt;&gt;&gt; <span style="color: #87c095; font-style: italic;">newRecords</span>
            = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">HashMap</span>&lt;&gt;();
        <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">TopicPartition</span> <span style="color: #87c095; font-style: italic;">tp</span> : records.partitions()) {
            <span style="color: #d9bb80;">List</span>&lt;<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt;&gt; <span style="color: #87c095; font-style: italic;">tpRecords</span> =
                records.records(tp);
            <span style="color: #d9bb80;">List</span>&lt;<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt;&gt; <span style="color: #87c095; font-style: italic;">newTpRecords</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">ArrayList</span>&lt;&gt;();
            <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">consumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">record</span> : tpRecords) {
                <span style="color: #e68183;">if</span> (now - record.timestamp() &lt; EXPIRE_INTERVAL) {
                    newTpRecords.add(record);
                }
            }
            <span style="color: #e68183;">if</span> (<span style="color: #87c095; font-weight: bold;">!</span>newTpRecords.isEmpty()) {
                newRecords.put(tp, newTpRecords);
            }
        }
        <span style="color: #e68183;">return</span> <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">ConsumerRecords</span>&lt;&gt;(newRecords);
    }

    <span style="color: #d3a0bc;">@Override</span>
    <span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">onCommit</span>(<span style="color: #d9bb80;">Map</span>&lt;<span style="color: #d9bb80;">TopicPartiton</span>, <span style="color: #d9bb80;">OffsetAndMetadata</span>&gt; <span style="color: #87c095; font-style: italic;">offsets</span>) {
        offsets.forEach((tp, offset) -&gt;
                        System.out.println(tp + <span style="color: #87af87;">":"</span> + offset.offset()));
    }

}
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-orgbee25aa" class="outline-4">
<h4 id="orgbee25aa"><span class="section-number-4">3.2.10</span> 多线程实现</h4>
<div class="outline-text-4" id="text-3-2-10">
<ul class="org-ul">
<li>KafkaProducer是线程安全的,但是KafkaConsumer却是非线程安全的</li>
<li>KafkaConsumer内部实现了个私有的方法acquire()来检测当前是否只有一个线程在操作,
如果不是的话,会抛出ConcurrentModifcationException异常</li>
<li>acquire()类似轻量级的获取锁的操作,与之对应的释放锁的操作叫做release()</li>
<li>KafkaConsumer非线程安全并不意味着我们在消费的时候只能以单线程的方式执行,而
且单线程显然无法处理kafka对应的海量数据,我们下面就介绍下Kafka消费所用到的几种
多线程消费模型:
<ol class="org-ol">
<li><p>
一个线程对应一个KafkaConsumer实例,一个线程对应一个或者多个分区(通常的对应一个分区)
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">package</span> org.harri.kafka.<span style="color: #d3a0bc;">demo_3_11</span>;

<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">consumer</span>.<span style="color: #d9bb80;">ConsumerConfig</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">consumer</span>.<span style="color: #d9bb80;">ConsumerRecord</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">consumer</span>.<span style="color: #d9bb80;">ConsumerRecords</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">consumer</span>.<span style="color: #d9bb80;">KafkaConsumer</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">common</span>.<span style="color: #d3a0bc;">serialization</span>.<span style="color: #d9bb80;">StringDeserializer</span>;

<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">time</span>.<span style="color: #d9bb80;">Duration</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d9bb80;">Arrays</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d9bb80;">Properties</span>;

<span style="color: #e68183;">public</span> <span style="color: #e68183;">class</span> <span style="color: #d9bb80;">FirstMultiConsumerThreadDemo</span> {

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">brokerList</span> = <span style="color: #87af87;">"localhost:9092"</span>;
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span> = <span style="color: #87af87;">"harri-test-topic"</span>;
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">groupId</span> = <span style="color: #87af87;">"group.demo2"</span>;

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095;">initConfig</span>() {
        <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">Properties</span>();
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.KEY_DESERIALIZER_CLASS_CONFIG,
                StringDeserializer.<span style="color: #e68183;">class</span>.getName());
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.VALUE_DESERIALIZER_CLASS_CONFIG,
                StringDeserializer.<span style="color: #e68183;">class</span>.getName());
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.BOOTSTRAP_SERVERS_CONFIG, brokerList);
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.GROUP_ID_CONFIG, groupId);
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.ENABLE_AUTO_COMMIT_CONFIG, <span style="color: #d3a0bc;">true</span>);
        <span style="color: #e68183;">return</span> props;
    }

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">main</span>(<span style="color: #d9bb80;">String</span>[] <span style="color: #87c095; font-style: italic;">args</span>) {
        <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span> = initConfig();
        <span style="color: #d9bb80;">int</span> <span style="color: #87c095; font-style: italic;">consumerThreadNum</span> = 4;
        <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">int</span> <span style="color: #87c095; font-style: italic;">i</span> = 0; i &lt; <span style="color: #d9bb80;">consumerThreadNum</span>; i++) {
            <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaConsumerThread</span>(props, topic).start();
        }
    }

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">class</span> <span style="color: #d9bb80;">KafkaConsumerThread</span> <span style="color: #e68183;">extends</span> <span style="color: #d9bb80;">Thread</span> {
        <span style="color: #e68183;">private</span> <span style="color: #d9bb80;">KafkaConsumer</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">kafkaConsumer</span>;

        <span style="color: #e68183;">public</span> <span style="color: #87c095;">KafkaConsumerThread</span>(<span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span>, <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span>) {
            <span style="color: #e68183;">this</span>.kafkaConsumer = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaConsumer</span>&lt;&gt;(props);
            <span style="color: #e68183;">this</span>.kafkaConsumer.subscribe(Arrays.asList(topic));
        }

        <span style="color: #d3a0bc;">@Override</span>
        <span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">run</span>() {
            <span style="color: #e68183;">try</span> {
                <span style="color: #e68183;">while</span> (<span style="color: #d3a0bc;">true</span>) {
                    <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span> = kafkaConsumer.poll(Duration.ofMillis(100));
                    <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">record</span> : records) {
                        System.out.printf(<span style="color: #87af87;">"thread-%s-value-%s-part-%s\n"</span>, Thread.currentThread().getName(), record.value(), record.partition());
                    }
                }
            } <span style="color: #e68183;">catch</span> (<span style="color: #d9bb80;">Exception</span> <span style="color: #87c095; font-style: italic;">e</span>) {
                e.printStackTrace();
            } <span style="color: #e68183;">finally</span> {
                kafkaConsumer.close();
            }
        }
    }
}
</pre>
</div></li>
<li>多个线程对应一个分区,这种模型需要精准控制位移提交和顺序控制,非常复杂</li>
<li><p>
一个线程一个KafkaConsumer,但是消息处理使用线程库,多线程处理消息,出现这种
处理的方式的原因是因为poll()一般比较快,整个系统的瓶颈出现在消息处理方面
</p>
<div class="org-src-container">
<pre class="src src-java"><span style="color: #e68183;">package</span> org.harri.kafka.<span style="color: #d3a0bc;">demo_3_12</span>;

<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">consumer</span>.<span style="color: #d9bb80;">ConsumerConfig</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">consumer</span>.<span style="color: #d9bb80;">ConsumerRecord</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">consumer</span>.<span style="color: #d9bb80;">ConsumerRecords</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">clients</span>.<span style="color: #d3a0bc;">consumer</span>.<span style="color: #d9bb80;">KafkaConsumer</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">org</span>.<span style="color: #d3a0bc;">apache</span>.<span style="color: #d3a0bc;">kafka</span>.<span style="color: #d3a0bc;">common</span>.<span style="color: #d3a0bc;">serialization</span>.<span style="color: #d9bb80;">StringDeserializer</span>;

<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">time</span>.<span style="color: #d9bb80;">Duration</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d9bb80;">Collections</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d9bb80;">Properties</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d3a0bc;">concurrent</span>.<span style="color: #d9bb80;">ArrayBlockingQueue</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d3a0bc;">concurrent</span>.<span style="color: #d9bb80;">ExecutorService</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d3a0bc;">concurrent</span>.<span style="color: #d9bb80;">ThreadPoolExecutor</span>;
<span style="color: #e68183;">import</span> <span style="color: #d3a0bc;">java</span>.<span style="color: #d3a0bc;">util</span>.<span style="color: #d3a0bc;">concurrent</span>.<span style="color: #d9bb80;">TimeUnit</span>;

<span style="color: #e68183;">public</span> <span style="color: #e68183;">class</span> <span style="color: #d9bb80;">ThirdMultiConsumerThreadDemo</span> {
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">brokerList</span> = <span style="color: #87af87;">"localhost:9092"</span>;
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span> = <span style="color: #87af87;">"harri-test-topic"</span>;
    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">groupId</span> = <span style="color: #87af87;">"group.demo"</span>;

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095;">initConfig</span>() {
        <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">Properties</span>();
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.KEY_DESERIALIZER_CLASS_CONFIG,
                StringDeserializer.<span style="color: #e68183;">class</span>.getName());
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.VALUE_DESERIALIZER_CLASS_CONFIG,
                StringDeserializer.<span style="color: #e68183;">class</span>.getName());
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.BOOTSTRAP_SERVERS_CONFIG, brokerList);
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.GROUP_ID_CONFIG, groupId);
        props.put(<span style="color: #d3a0bc;">ConsumerConfig</span>.ENABLE_AUTO_COMMIT_CONFIG, <span style="color: #d3a0bc;">true</span>);
        <span style="color: #e68183;">return</span> props;
    }

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">main</span>(<span style="color: #d9bb80;">String</span>[] <span style="color: #87c095; font-style: italic;">args</span>) {
        <span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span> = initConfig();
        <span style="color: #d9bb80;">KafkaConsumerThread</span> <span style="color: #87c095; font-style: italic;">consumerThread</span> = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaConsumerThread</span>(props, topic,
                Runtime.getRuntime().availableProcessors());
        consumerThread.start();
    }


    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">class</span> <span style="color: #d9bb80;">KafkaConsumerThread</span> <span style="color: #e68183;">extends</span> <span style="color: #d9bb80;">Thread</span> {
        <span style="color: #e68183;">private</span> <span style="color: #d9bb80;">KafkaConsumer</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">kafkaConsumer</span>;
        <span style="color: #e68183;">private</span> <span style="color: #d9bb80;">ExecutorService</span> <span style="color: #87c095; font-style: italic;">executorService</span>;
        <span style="color: #e68183;">private</span> <span style="color: #d9bb80;">int</span> <span style="color: #87c095; font-style: italic;">threadNumber</span>;

        <span style="color: #e68183;">public</span> <span style="color: #87c095;">KafkaConsumerThread</span>(<span style="color: #d9bb80;">Properties</span> <span style="color: #87c095; font-style: italic;">props</span>, <span style="color: #d9bb80;">String</span> <span style="color: #87c095; font-style: italic;">topic</span>, <span style="color: #d9bb80;">int</span> <span style="color: #87c095; font-style: italic;">threadNumber</span>) {
            kafkaConsumer = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">KafkaConsumer</span>&lt;&gt;(props);
            kafkaConsumer.subscribe(Collections.singletonList(topic));
            <span style="color: #e68183;">this</span>.threadNumber = threadNumber;
            executorService = <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">ThreadPoolExecutor</span>(threadNumber, threadNumber,
                    0L, <span style="color: #d3a0bc;">TimeUnit</span>.MILLISECONDS, <span style="color: #e68183;">new</span> <span style="color: #d9bb80;">ArrayBlockingQueue</span>&lt;&gt;(1000),
                    <span style="color: #e68183;">new</span> <span style="color: #d3a0bc;">ThreadPoolExecutor</span>.<span style="color: #d9bb80;">CallerRunsPolicy</span>());
        }

        <span style="color: #d3a0bc;">@Override</span>
        <span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">run</span>() {
            <span style="color: #e68183;">try</span> {
                <span style="color: #e68183;">while</span> (<span style="color: #d3a0bc;">true</span>) {
                    <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span> = kafkaConsumer.poll(Duration.ofMillis(100));
                    <span style="color: #e68183;">if</span> (<span style="color: #87c095; font-weight: bold;">!</span>records.isEmpty()) {
                        executorService.submit(<span style="color: #e68183;">new</span> <span style="color: #d9bb80;">RecordsHandler</span>(records));
                    }
                }
            } <span style="color: #e68183;">catch</span> (<span style="color: #d9bb80;">Exception</span> <span style="color: #87c095; font-style: italic;">e</span>) {
                e.printStackTrace();
            } <span style="color: #e68183;">finally</span> {
                kafkaConsumer.close();
            }
        }
    }

    <span style="color: #e68183;">public</span> <span style="color: #e68183;">static</span> <span style="color: #e68183;">class</span> <span style="color: #d9bb80;">RecordsHandler</span> <span style="color: #e68183;">extends</span> <span style="color: #d9bb80;">Thread</span> {
        <span style="color: #e68183;">public</span> <span style="color: #e68183;">final</span> <span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span>;

        <span style="color: #e68183;">public</span> <span style="color: #87c095;">RecordsHandler</span>(<span style="color: #d9bb80;">ConsumerRecords</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">records</span>) {
            <span style="color: #e68183;">this</span>.records = records;
        }

        <span style="color: #d3a0bc;">@Override</span>
        <span style="color: #e68183;">public</span> <span style="color: #d9bb80;">void</span> <span style="color: #87c095;">run</span>() {
            <span style="color: #e68183;">for</span> (<span style="color: #d9bb80;">ConsumerRecord</span>&lt;<span style="color: #d9bb80;">String</span>, <span style="color: #d9bb80;">String</span>&gt; <span style="color: #87c095; font-style: italic;">record</span> : records) {
                System.out.printf(<span style="color: #87af87;">"thread-%s-value-%s\n"</span>, Thread.currentThread().getName(), record.value());
            }
        }
    }
}
</pre>
</div></li>
</ol></li>
</ul>
</div>
</div>
<div id="outline-container-org618508b" class="outline-4">
<h4 id="org618508b"><span class="section-number-4">3.2.11</span> 重要的消费者参数</h4>
<div class="outline-text-4" id="text-3-2-11">
</div>
<ol class="org-ol">
<li><a id="org216d605"></a>fetch.min.bytes<br />
<div class="outline-text-5" id="text-3-2-11-1">
<ul class="org-ul">
<li>该参数用来配置Consumer在一次拉取请求中能从Kafka中拉取的最小数据量,more是1(B)</li>
<li>Kafka在收到Consumer拉取请求的时候,如果返回给Consumer的数据量小于这个值,那
么就要进行等待</li>
<li>可以适度提高这个值,但是会造成额外的延迟</li>
</ul>
</div>
</li>
<li><a id="orgfb8c543"></a>fetch.max.bytes<br />
<div class="outline-text-5" id="text-3-2-11-2">
<ul class="org-ul">
<li>该参数设置为一次拉取最大的值,默认是50MB</li>
<li>如果这个参数比任何一条kafka消息都小,也是可以拉取的</li>
<li>kafka中message的最大值是由服务端message.max.bytes</li>
</ul>
</div>
</li>
<li><a id="org17d28dc"></a>fetch.max.wait.ms<br />
<div class="outline-text-5" id="text-3-2-11-3">
<ul class="org-ul">
<li>拉取不可能一直参考fetch.min.bytes,必须有一个等待超时时间,默认值是500ms</li>
</ul>
</div>
</li>
<li><a id="org23316c2"></a>max.partition.fetch.bytes<br />
<div class="outline-text-5" id="text-3-2-11-4">
<ul class="org-ul">
<li>参数用来设置每个分区给Consumer的最大数据量,more是1MB</li>
</ul>
</div>
</li>
<li><a id="orga5f96ed"></a>max.poll.records<br />
<div class="outline-text-5" id="text-3-2-11-5">
<ul class="org-ul">
<li>参数用来配置Consumer在一次拉取中请求的最大的消息数目,默认是500条</li>
</ul>
</div>
</li>
<li><a id="orgcb498a7"></a>connections.max.idle.ms<br />
<div class="outline-text-5" id="text-3-2-11-6">
<ul class="org-ul">
<li>参数指定多久之后关闭限制的连接,默认是9分钟</li>
</ul>
</div>
</li>
<li><a id="orgad699e0"></a>exclude.internal.topics<br />
<div class="outline-text-5" id="text-3-2-11-7">
<ul class="org-ul">
<li>kafka内部有两个主题__consumer_offsets和__transaction_state</li>
<li>exclude.internal.topics 默认值为true</li>
<li>如果为true,只能用subscribe(Collection),而不能用subscribe(Pattern)来订阅内部主题</li>
</ul>
</div>
</li>
<li><a id="orga9396da"></a>receive.buffer.bytes<br />
<div class="outline-text-5" id="text-3-2-11-8">
<ul class="org-ul">
<li>设置Socket接受消息缓冲区(O_RECBUF)的大小,more是64KB</li>
</ul>
</div>
</li>
<li><a id="org3c2718a"></a>send.buffer.bytes<br />
<div class="outline-text-5" id="text-3-2-11-9">
<ul class="org-ul">
<li>设置Socket发送消息缓冲区(O_RECBUF)的大小,more是128KB</li>
</ul>
</div>
</li>
<li><a id="org11ac58f"></a>request.timeout.ms<br />
<div class="outline-text-5" id="text-3-2-11-10">
<ul class="org-ul">
<li>用来配置Consumer等待请求的最长时间</li>
</ul>
</div>
</li>
<li><a id="orge2add64"></a>metadata.max.age.ms<br />
<div class="outline-text-5" id="text-3-2-11-11">
<ul class="org-ul">
<li>元数据过期时间,默认是五分钟</li>
</ul>
</div>
</li>
<li><a id="orgc74975f"></a>reconnect.backoff.ms<br />
<div class="outline-text-5" id="text-3-2-11-12">
<ul class="org-ul">
<li>重新连接指定主机之前的等待时间</li>
</ul>
</div>
</li>
<li><a id="org26ec1a4"></a>retry.backoff.ms<br />
<div class="outline-text-5" id="text-3-2-11-13">
<ul class="org-ul">
<li>重新发送失败请求到指定主题分区之前的等待时间</li>
</ul>
</div>
</li>
<li><a id="org74e416a"></a>isolation.level<br />
<div class="outline-text-5" id="text-3-2-11-14">
<ul class="org-ul">
<li>消费者的事物隔离级别</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org024fe1b" class="outline-2">
<h2 id="org024fe1b"><span class="section-number-2">4</span> 第四章 主题与分区</h2>
<div class="outline-text-2" id="text-4">
<ul class="org-ul">
<li>从kafka的底层实现来说,主题和分区都是逻辑上的概念:
<ul class="org-ul">
<li>分区可以有一至多个副本</li>
<li>每个副本对应一个日志文件</li>
<li>每个日志文件对应一个或者多个日志分段(LogSegment)</li>
<li>每个日志分段还可以细分为:索引文件,日志存储文件和快照文件</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org87ce8ee" class="outline-3">
<h3 id="org87ce8ee"><span class="section-number-3">4.1</span> 主题的管理</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li>主题的挂历包括:
<ul class="org-ul">
<li>创建主题</li>
<li>查看主题信息</li>
<li>修改主题</li>
<li>删除主题</li>
</ul></li>
<li>所有这些操作可以使用位于$KAFKA_HOME/bin/目录下的kafka-topics.sh来执行</li>
<li>除了使用命令行来管理topic还可以通过KafkaAdminClient的方式来实现</li>
</ul>
</div>
<div id="outline-container-orgbc1d3e8" class="outline-4">
<h4 id="orgbc1d3e8"><span class="section-number-4">4.1.1</span> 创建主题</h4>
<div class="outline-text-4" id="text-4-1-1">
<ul class="org-ul">
<li>如果broker端配置参数auto.create.topics.enable为true:
<ul class="org-ul">
<li>那么生产者发送的topic, 如果从来没有创建过的话,会自动创建一个分区数目为
num.partitions(默认为1),副本为default.replication.factor(默认
值为1)的主题</li>
<li>消费者消费没创建的topic也会自动创建</li>
<li>客户端向未知主题发送元数据,也会自动创建</li>
</ul></li>
</ul>
<p>
n    + 很多时候这种自动创建主题的行为都是非预期的,所以不建议设置auto.create.topics.enable为true
</p>
<ul class="org-ul">
<li><p>
更加推荐使用kafka-topics.sh脚本来创建主题,下面来创建一个名为topic-create的topic
</p>
<div class="org-src-container">
<pre class="src src-shell">bin/kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-crate --partitions 4 --replication-factor 2
</pre>
</div></li>
<li><p>
上面的代码创建的topic,副本因子为2,分区数为4, 而我们的broker节点只有三个,这说明
</p>
<pre class="example" id="org399662c">
分区数目可以高于节点数目,但是副本数目必须小于等于节点数
</pre></li>
<li>执行完上面的创建脚本之后,kafka会在log.dir(或者log.dirs)下面创建相应的主题分区,默认情况下是在/tmp/kafka-logs/</li>
<li><p>
我们前面说了我们至于三个broker,而有四个分区,那么是不是必然有个broker里面存储会超过一个分区呢?
</p>
<pre class="example" id="org2939dcf">
其实这么思考是不对的,我们的broker不仅仅要考虑到分区数目,还要考虑到副本因子,
我们分区数目是4,副本因子是2,那么就要创建8个文件夹来存储数据
</pre></li>
<li>具体8个文件夹如下分布:
<ul class="org-ul">
<li><p>
在node1下面就会发现两个分区
</p>
<div class="org-src-container">
<pre class="src src-shell">Node1&gt; ls -a /tmp/kafka-logs/ | grep topic-create
topic-create-0
topic-create-1
</pre>
</div></li>
<li><p>
在node2下面就会发现3个分区
</p>
<div class="org-src-container">
<pre class="src src-shell">Node2&gt; ls -a /tmp/kafka-logs/ | grep topic-create
topic-create-1
topic-create-2
topic-create-3
</pre>
</div></li>
<li><p>
在node3下面就会发现两个分区
</p>
<div class="org-src-container">
<pre class="src src-shell">Node3&gt; ls -a /tmp/kafka-logs/ | grep topic-create
topic-create-0
topic-create-2
topic-create-3
</pre>
</div></li>
</ul></li>
<li>主题,分区,副本,log日志这四个概念的关系如下图,这四个概念中:
<ul class="org-ul">
<li><p>
图4-1
</p>

<div id="org696a113" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-4-1.jpg" alt="ki-4-1.jpg" />
</p>
<p><span class="figure-number">Figure 15: </span>kafka/ki-4-1.jpg</p>
</div></li>
<li>主题和分区是提供给上层用户的抽象</li>
<li>副本层,更具体点是log层才有实际的物理上的存在</li>
<li>同一个分区的多个副本要存储在不同的broker里面,这样才能提供有效的冗余</li>
</ul></li>
<li><p>
前面我们看到再broker的文件夹里面能通过文件夹名字,来查找创建的topic的副本的情况,另外一种方法是去zookeeper
客户端来获取,比如我们创建了一个名字叫topic-create的topic,那么我们可以使用如下zookeeper客户端命令来获取
topic-create这个主题的分区副本分配方案:
</p>
<div class="org-src-container">
<pre class="src src-shell">[zk] get /brokers/topics/topic-create
{<span style="color: #87af87;">"version"</span>: 1,<span style="color: #87af87;">"partitions"</span>:{<span style="color: #87af87;">"2"</span>:[1,2],<span style="color: #87af87;">"1"</span>:[0,1],<span style="color: #87af87;">"3"</span>:[2,1],<span style="color: #87af87;">"0"</span>:[2,0]}}
</pre>
</div></li>
<li>"2":[1,2], 表示partition2分配了两个副本,分别存在了broker1和broker2节点中</li>
<li><p>
可以通过describe 指令类型来查看分区副本的分配细节
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-create
Topic: topic-create PartitionCount:4 ReplicationFactor:2 Configs:
  Topic: topic-create Partition: 0 Leader: 2 Replicas: 2, 0 Isr: 2,0
  Topic: topic-create Partition: 1 Leader: 0 Replicas: 0, 1 Isr: 0,1
  Topic: topic-create Partition: 2 Leader: 1 Replicas: 1, 2 Isr: 1,2
  Topic: topic-create Partition: 3 Leader: 2 Replicas: 2, 1 Isr: 2,1
</pre>
</div></li>
<li>我们来解释下这个结果:
<ul class="org-ul">
<li>Topic: topic-create -&gt; 这个表示topic的名字</li>
<li>PartitionCount: 4 -&gt; 这个表示分区数目是4</li>
<li>ReplicationFactor:2 -&gt; 这个表示副本因子是2,也就是leader副本和follower副本总共是2个(其中leader副本有且只有一个)</li>
<li>Configs表示创建或者修改主题时候指定的参数:
<ol class="org-ol">
<li>Topic: 主题名字</li>
<li>Partition: 分区的id,从0开始</li>
<li>Leader: 分区的leader副本对应的brokerID</li>
<li>Replicas: 表示所有的副本的分配情况(也就是AR集合, AR=ISR+OSR),数字为brokerID</li>
<li>Isr: 表示In-Sync Replicas集合,数字为brokerID</li>
</ol></li>
</ul></li>
<li><p>
使用kafka-topics.sh脚本创建主题的命令格式归纳如下:
</p>
<div class="org-src-container">
<pre class="src src-shell">kafka-topics.sh --zookeeper &lt;String:hosts&gt; -create --topic [String:topic]
--partitions &lt;Integer: <span style="color: #5b5b5b;"># </span><span style="color: #5b5b5b;">of partition&gt; -replication-factor &lt;Integer: replication factor&gt;</span>
</pre>
</div></li>
<li><p>
上面的命令中,没有指定如何分配不同的副本到不同的broker(是系统自动指定的),我们可以使用额外的参数
来指定副本对应的broker. 分区内以":"分割,不同分区以","分割
</p>
<div class="org-src-container">
<pre class="src src-shell">--replica-assignment &lt;String: broker_id_for_part1_replica1: broker_id_for_part_1replica2,
broker_id_for_part2_replica1: broker_id_for_part2_replica2,...&gt;
</pre>
</div></li>
<li>我们还可以使用config参数来设置所要创建的topic主题相关的参数,这个参数会覆盖原本的默认设置
<ul class="org-ul">
<li><p>
使用方法如下:
</p>
<pre class="example" id="org4eeb4b1">
--config &lt;String:name=value1&gt; --config &lt;String:name=value2&gt;
</pre></li>
<li><p>
一个设置cleanup.policy和max.message.bytes的参数如下
</p>
<div class="org-src-container">
<pre class="src src-shell">bin/kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-config <span style="color: #87af87;">\</span>
                    --replication-factor 1 --partitions 1 <span style="color: #87af87;">\</span>
                    --config cleanup.policy=compact <span style="color: #87af87;">\</span>
                    --config max.message.bytes=10000

</pre>
</div></li>
<li><p>
使用这种方法创建的topic,在describe的时候,会把&#x2013;config的设置给标记出来
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka -describe --topic topic-config
Topic:topic-config PartitionCount:1 ReplicationFactor:1
Configs:cleanup.policy=compact,max.message.bytes=10000
Topic: topic-config Partition: 0 Leader: 0 Replicas: 0 Isr: 0
</pre>
</div></li>
<li><p>
我们还可以使用zookeeper客户端来查看配置的参数
</p>
<div class="org-src-container">
<pre class="src src-shell">[zk: localhost:2181/kafka(CONNECTED) 7] get /config/topics/topic-config
{<span style="color: #87af87;">"version"</span>: 1, <span style="color: #87af87;">"config"</span>: {<span style="color: #87af87;">"max.message.bytes"</span>: <span style="color: #87af87;">"10000"</span>,<span style="color: #87af87;">"cleanup.policy"</span>:<span style="color: #87af87;">"compact"</span>}}
</pre>
</div></li>
</ul></li>
<li>创建主题时候的topic名字也有很多要求
<ol class="org-ol">
<li><p>
首先是不能使用已经存在的topic名字:
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeepr localhost:2181/kafka --create --topic topic-create --replication-factor 1 --partitions 1
Error while executing topic command: Topic <span style="color: #87af87;">'topic-create'</span> already exists.
</pre>
</div>
<ul class="org-ul">
<li><p>
如果不想再创建的时候报错(TopicExistsException),那么我们要使用if-not-exists参数,这个参数设置了以后,
如果已经有这个topic了,那么什么也不做(下面的例子就是,虽然命令指定了新的topic的partition,但是describe
出来还是老的配置,说明什么也没做),如果没有这个topic name,则会创建新的topic
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeepr localhost:2181/kafka --create --topic topic-create --replication-factor 1 --partitions 1 --if-not-exists
&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-create
Topic: topic-create PartitionCount:4 ReplicationFactor:2 Configs:
  Topic: topic-create Partition: 0 Leader: 2 Replicas: 2, 0 Isr: 2,0
  Topic: topic-create Partition: 1 Leader: 0 Replicas: 0, 1 Isr: 0,1
  Topic: topic-create Partition: 2 Leader: 1 Replicas: 1, 2 Isr: 1,2
  Topic: topic-create Partition: 3 Leader: 2 Replicas: 2, 1 Isr: 2,1
</pre>
</div></li>
</ul></li>
<li>其次,脚本在创建主题的时候会检查名字是否包含"."或者"<code>_</code>",而且提示不允许同时使用这个两个字符串,
因为kafka在命名自己内部metric的时候,会把"."转换为"<code>_</code>".
<ul class="org-ul">
<li>比如下面两个主题的metric都会是"topic_1_2":
<ul class="org-ul">
<li>topic.1_2</li>
<li>topic_1.2</li>
</ul></li>
<li>如果先创建了topic.1_2, 那么系统只是warning说你不要同时使用"."和"_", 然后再创建topic_1.2的话,
那么,kafka直接就告诉你创建失败.</li>
</ul></li>
<li>再次,虽然"__"开头的topic是可以创建的,但不建议这样做,因为"<code>__</code>"开头的主题通常被看成是kafka内部的主题,比如:
<ul class="org-ul">
<li>__consumer_offsets</li>
<li>__transaction_state</li>
</ul></li>
</ol></li>
<li>kafka从0.10.x版本开始,还支持设置机架信息,如果指定了机架信息,那么则在分区副本分配时,会尽可能地让分区副本分配到不同的机架上</li>
<li>kafka-topics.sh实质上是调用了kfaka.admin.TopicCommand类,我们也可以使用java代码来实现上面提到的功能</li>
</ul>
</div>
</div>
<div id="outline-container-orge97186f" class="outline-4">
<h4 id="orge97186f"><span class="section-number-4">4.1.2</span> 分区副本的分配</h4>
<div class="outline-text-4" id="text-4-1-2">
<ul class="org-ul">
<li>创建主题的时候:
<ul class="org-ul">
<li>如果使用了replica-assignment参数,那么就按照既定方案分配</li>
<li>如果没有使用replica-assignment参数,那么按照内部逻辑来计算分配方案,具体实现在kafka.admin.AdminUtils.scala
文件中的assignReplicasToBrokersRackUnaware()方法</li>
</ul></li>
<li>创建一个主题的时候,无论是通过kafka-topics.sh脚本,还是通过其他方法,比如后面介绍的KafkaAdminClient,其实质是:
<ul class="org-ul">
<li>在Zookeeper的/brokers/topics节点下创建与该主题对应的子节点,并且写入分区副本分配方案</li>
<li>同时在/config/topics/节点下创建与该主题对应的配置信息(可以不做)</li>
</ul></li>
<li><p>
知道了kafka-topics.sh的脚本实质之后,我们其实可以直接使用ZooKeeper的客户端在/brokers/topics节点
创建相应的节点.这种创建主题的方式还可以绕过一些原本使用kafka-topics.sh创建脚本的一些限制(比如分区序号可以不用从0
开始累加),例子如下
</p>
<div class="org-src-container">
<pre class="src src-shell">[zk: localhost:2181/kafka(CONNECTED) 29] create /brokers/topic/topic-create-zk <span style="color: #87af87;">\</span>
                                         {<span style="color: #87af87;">"version"</span>: 1, <span style="color: #87af87;">"partition"</span>: {<span style="color: #87af87;">"2"</span>:[1,2],<span style="color: #87af87;">"1"</span>:[0,1],<span style="color: #87af87;">"3"</span>:[2,1],<span style="color: #87af87;">"0"</span>:[2,0]}}
Created /brokers/topics/topic-create-zk
</pre>
</div></li>
<li><p>
我们通过describe来看,和使用kafka-topics.sh创建topic没有什么不同
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; /bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-create-zk
Topic:topic-create-zk PartitionCount:4 ReplicationFactor:2 Configs:
  Topic:topic-create-zk Partition:0 Learder: 2 Replicas: 2, 0 Isr: 2,0
  Topic:topic-create-zk Partition:1 Learder: 0 Replicas: 2, 0 Isr: 0,1
  Topic:topic-create-zk Partition:2 Learder: 1 Replicas: 2, 0 Isr: 1,2
  Topic:topic-create-zk Partition:3 Learder: 2 Replicas: 2, 0 Isr: 2,1
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-org9165994" class="outline-4">
<h4 id="org9165994"><span class="section-number-4">4.1.3</span> 查看主题</h4>
<div class="outline-text-4" id="text-4-1-3">
<ul class="org-ul">
<li>kafka-topics.sh一共有如下五种指令类型:
<ul class="org-ul">
<li>create</li>
<li>list</li>
<li>describe</li>
<li>alter</li>
<li>delete</li>
</ul></li>
<li><p>
通过list可以查看当前所有可用的主题
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka -list
__consumer_offsets
topic-create
topic-demo
topic-config
</pre>
</div></li>
<li><p>
通过describe可以查看单个主题的信息,如果不使用&#x2013;topic则会展示所有主题的信息,&#x2013;topic可以指定一个
或者多个topic
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-crate,topic-demo

Topic: topic-create PartitionCount:4 ReplicationFactor: 2 Configs:
Topic:topic-create Partition: 0 Leader: 2 Replicas: 2,0 Isr: 2,0
Topic:topic-create Partition: 1 Leader: 0 Replicas: 0,1 Isr: 0,1
Topic:topic-create Partition: 2 Leader: 2 Replicas: 1,2 Isr: 2,1
Topic:topic-create Partition: 3 Leader: 2 Replicas: 2,1 Isr: 2,1
Topic: topic-demo PartitionCount:4 ReplicationFactor: 3 Configs:
Topic:topic-demo Partition: 0 Leader: 2 Replicas: 2,1,0 Isr: 2,0,1
Topic:topic-demo Partition: 1 Leader: 2 Replicas: 0,2,1 Isr: 2,0,1
Topic:topic-demo Partition: 2 Leader: 2 Replicas: 1,0,2 Isr: 2,0,1
Topic:topic-demo Partition: 3 Leader: 2 Replicas: 2,0,1 Isr: 2,0,1
</pre>
</div></li>
<li>使用decribe还可以指定如下三个惨:
<ul class="org-ul">
<li><p>
topic-with-overrids: 找出那些于集群配置不一样的主题:
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeepr localhost:2181/kafka --describe --topics-with-overrids
Topic:__consumer_offsets PartitionCount:50 ReplicationFactor:1
Configs:segment.byte=104857600,cleanup.policy=comapct,compression.type=producer
Topic:toipc-config PartitionCount:1 ReplicationFactor:1
Configs:cleanup.policy=compact,max.message.bytes=10000
</pre>
</div></li>
<li><p>
unser-replicated-partitions: 找到所有主题中,包含失效副本的分区,换句话说就是此时ISR小于AR. 失效副
本可能是正在同步,也有可能是发送同步异常
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-create --unser-replicated-partitions
Topic: topic-crate Partition: 1 Leader: 0 Replicas: 0, 1 Isr: 0
Topic: topic-crate Partition: 2 Leader: 2 Replicas: 1, 2 Isr: 2
Topic: topic-crate Partition: 3 Leader: 2 Replicas: 2, 1 Isr: 2
</pre>
</div></li>
<li><p>
unavailable-partitions: 找到所有主题中,没有leader副本的分区,这些分区已经处于离线状态,对于外
界的生产者和消费者来说,处于不可用状态
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; /bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-create --unavailable-partitions
Topic: topic-create Partition: 2 Leader: -1 Replicas: 1, 2 Isr: 1
Topic: topic-create Partition: 3 Leader: -1 Replicas: 2, 1 Isr: 1
</pre>
</div></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgc4ceb2c" class="outline-4">
<h4 id="orgc4ceb2c"><span class="section-number-4">4.1.4</span> 修改主题</h4>
<div class="outline-text-4" id="text-4-1-4">
<ul class="org-ul">
<li>当一个主题被创建之后,依然允许我们对其做一定的修改,比如修改分区个数,修改配置等,这时候使用kafka-topics.sh
脚本中的alter</li>
<li><p>
我们首先来看看如何增加分区的个数,比如topic-config当前分区数为1,修改为3,代码如下
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --alter --topic topic-config --partitions 3
WARNING: If partitions are increased for a topic that has a key, the partition
logic or ordering of the messesages will be affected
Adding partitions succeeded!

&gt; bin/kafka-topics.sh --zookeeper loccalhost:2181/kafka --describe --topic topic-config
Topic:topic-config PartitionCount:3 ReplicationFactor:1 Configs:
  Topic: topic-config Partition: 0 Leader: 2 Replicas: 2 Isr: 2
  Topic: topic-config Partition: 1 Leader: 0 Replicas: 0 Isr: 0
  Topic: topic-config Partition: 2 Leader: 1 Replicas: 1 Isr: 1
</pre>
</div></li>
<li>目前kafka只支持增加分区数二不支持减少分区数</li>
<li>为什么不支持介绍分区?
<ul class="org-ul">
<li>因为需要考虑的因素太多,收益却太低,所以暂时不支持</li>
<li>如果确实需要减少分区,可以重新创建一个分区较小的主题,然后将现在主题的内容复制过去</li>
</ul></li>
<li>kafka-topics.sh的alter,在修改分区时也可以使用&#x2013;if-exists</li>
<li>kafka-topics.sh的alter,还可以使用和创建时候一样的&#x2013;config,来修改配置</li>
<li><p>
kafka-topics.sh的alter,还可以使用delete-config参数来删除之前的覆盖配置,使其恢复默认值
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --alter --topic topic-config --delete-config segment.bytes
WARNING: Altering topic configuration from this script has been deprecated and may be remove din future releases
Going forward, please use kafka-configs.sh for this functionality Updated config for topic <span style="color: #87af87;">"topic-config"</span>
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-org163681c" class="outline-4">
<h4 id="org163681c"><span class="section-number-4">4.1.5</span> 配置管理</h4>
<div class="outline-text-4" id="text-4-1-5">
<ul class="org-ul">
<li>kafka-config.sh 是专门用来对配置进行修改的.其修改范围比"kafka-topics.sh &#x2013;alter"(只能修改topic配置)大,
可以修改:
<ul class="org-ul">
<li>topic配置</li>
<li>broker配置</li>
<li>用户配置</li>
<li>客户端配置</li>
</ul></li>
<li><p>
kafka-config使用entity-type和entity-name来标记key:value,比如配合&#x2013;describe查看topics配置可以如下写:
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-configs.sh --zookeepr localhost:2181/kafka --describe --entity-type topics --eneity-name topic-config
</pre>
</div></li>
<li><p>
entity-type和entity-name内容有一定的范围:
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">entity type</th>
<th scope="col" class="org-left">entity-name</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">topics</td>
<td class="org-left">topic name</td>
</tr>

<tr>
<td class="org-left">brokers</td>
<td class="org-left">broker ID</td>
</tr>

<tr>
<td class="org-left">clients</td>
<td class="org-left">clientID, KafkaProducer, KafkaConsumer client.id</td>
</tr>

<tr>
<td class="org-left">users</td>
<td class="org-left">specific username</td>
</tr>
</tbody>
</table></li>
<li>下面来看看kafka-config配合&#x2013;alter
<ul class="org-ul">
<li>add-config用来实现配置的增,改(也就是覆盖原有配置)</li>
<li>delete-config用来实现配置的删除,即删除覆盖配置,使用默认配置</li>
</ul></li>
<li><p>
使用kafka-config.sh脚本来alter配置的时候,会在zookeeper中创建一个命名形式为/config/&lt;entity-type&gt;/&lt;entity-name&gt;
的节点,并将改动写入到这个节点
</p>
<div class="org-src-container">
<pre class="src src-shell">[zk: localhost:2181/kafka (CONNECTED) 1] get /config/topics/topic-config
{<span style="color: #87af87;">"version"</span>:1,<span style="color: #87af87;">"config"</span>:{<span style="color: #87af87;">"cleanup.policy"</span>:<span style="color: #87af87;">"compact"</span>,<span style="color: #87af87;">"max.message.bytes"</span>:<span style="color: #87af87;">"1000"</span>}}
</pre>
</div></li>
<li><p>
节点的内容数据格式为
</p>
<div class="org-src-container">
<pre class="src src-js">{<span style="color: #87af87;">"version"</span>:1,<span style="color: #87af87;">"config"</span>:{&lt;property-name&gt;:&lt;property-value&gt;}}
</pre>
</div></li>
<li>增加配置其实就是向这个json里面增加key-value,修改配置是修改里面的key-value,删除配置是删除对应的配置</li>
<li><p>
变更配置还会在ZooKeeper中的/config/changes/节点下创建一个以"config_change_&lt;seqNumber&gt;"为前缀的
持久顺序节点,其中seqNumber为十位数字,比如主题copic-config的对应节点为
</p>
<div class="org-src-container">
<pre class="src src-shell">[zk: localhost:2181/kafka (CONNECTED) 3] get /config/changes/config_change_0000000010
{<span style="color: #87af87;">"version"</span>:2,<span style="color: #87af87;">"entity_path"</span>:<span style="color: #87af87;">"topics/topic-config"</span>}
</pre>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-orga927c9e" class="outline-4">
<h4 id="orga927c9e"><span class="section-number-4">4.1.6</span> 主题端参数</h4>
<div class="outline-text-4" id="text-4-1-6">
<ul class="org-ul">
<li>与主题相关的所有配置参数在broekr层面都有对应的参数,比如:
<ul class="org-ul">
<li>主题段参数cleanup.policy 对应</li>
<li>broker层面的log.cleanup.policy</li>
</ul></li>
<li>如果没有修改过主题的任何配置参数,那么就会使用broker端的对应参数作为默认值:
<ul class="org-ul">
<li>比如,创建主题的是没有指定cleanup.policy参数的值,那么就使用log.cleanup.policy作为其默认值</li>
</ul></li>
<li>如果修改了主题的任何配置参数,那么就使用配置的值</li>
<li><p>
所有的主题端和broker层面参数一一对应表如下:
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Topic para</th>
<th scope="col" class="org-left">broker para</th>
<th scope="col" class="org-left">meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">cleanup.policy</td>
<td class="org-left">log.cleanup.policy</td>
<td class="org-left">日志压缩策略, 默认值是delete,还可以配置为compact</td>
</tr>

<tr>
<td class="org-left">compression.type</td>
<td class="org-left">compression.type</td>
<td class="org-left">消息压缩类型, 默认为producer,表示保留生产者设置的类型</td>
</tr>

<tr>
<td class="org-left">delete.retention.ms</td>
<td class="org-left">log.cleaner.delete.retention.ms</td>
<td class="org-left">被删除的数据保留多久,默认是1天</td>
</tr>

<tr>
<td class="org-left">file.delete.delay.ms</td>
<td class="org-left">log.segment.delete.delay.ms</td>
<td class="org-left">清理文件之前可以等到多长时间,默认是1分钟</td>
</tr>

<tr>
<td class="org-left">flush.messages</td>
<td class="org-left">log.flush.interval.messages</td>
<td class="org-left">需要多少消息才会强制刷新到磁盘</td>
</tr>

<tr>
<td class="org-left">flush.ms</td>
<td class="org-left">log.flush.interval.ms</td>
<td class="org-left">需要多久才强制刷新到磁盘</td>
</tr>

<tr>
<td class="org-left">follower.replication.throttled.replicas</td>
<td class="org-left">follower.replication.throttled.replicas</td>
<td class="org-left">配置被限制速率的follower副本列表</td>
</tr>

<tr>
<td class="org-left">index.interval.bytes</td>
<td class="org-left">log.index.interval.bytes</td>
<td class="org-left">控制添加索引的频率</td>
</tr>

<tr>
<td class="org-left">leader.replication.throttled.replicas</td>
<td class="org-left">leader.replication.throttled.replicas</td>
<td class="org-left">用来配置限制速率的leader副本列表</td>
</tr>

<tr>
<td class="org-left">max.message.bytes</td>
<td class="org-left">message.max.bytes</td>
<td class="org-left">消息的最大字节数</td>
</tr>

<tr>
<td class="org-left">message.format.version</td>
<td class="org-left">log.message.format.version</td>
<td class="org-left">消息版本格式</td>
</tr>

<tr>
<td class="org-left">message.timestamp.difference.max.ms</td>
<td class="org-left">logmessage.timestamp.difference.max.ms</td>
<td class="org-left">消息中自带的时间戳与broker收到的时间戳之间的最大差值</td>
</tr>

<tr>
<td class="org-left">message.timestamp.type</td>
<td class="org-left">log.message.timestamp.type</td>
<td class="org-left">消息的时间戳类型,more是CreateTIme,还可以是LogAppendTime</td>
</tr>

<tr>
<td class="org-left">min.cleanable.dirty.ratio</td>
<td class="org-left">log.cleaner.min.clanable.ratio</td>
<td class="org-left">日志清理是的最小污浊率,默认是0.5</td>
</tr>

<tr>
<td class="org-left">min.compation.lag.ms</td>
<td class="org-left">log.cleaner.min.compaction.lag.ms</td>
<td class="org-left">日志再次被清理前的最小保留时间</td>
</tr>

<tr>
<td class="org-left">min.insync.replicas</td>
<td class="org-left">min.insync.replicas</td>
<td class="org-left">分区ISR集合中至少要有多少副本,默认是1</td>
</tr>

<tr>
<td class="org-left">preallocate</td>
<td class="org-left">log.preallocate</td>
<td class="org-left">在创建日志分段的时候,是否要预分配空间,默认值是false</td>
</tr>

<tr>
<td class="org-left">retention.bytes</td>
<td class="org-left">log.retention.byts</td>
<td class="org-left">分区中所能保留的消息的总量,more是-1,即没有限制</td>
</tr>

<tr>
<td class="org-left">retention.ms</td>
<td class="org-left">log.retention.ms</td>
<td class="org-left">使用delete的日志清理策略,消息能够保留多长时间,more是7天,如果设置-1就是没有限制</td>
</tr>

<tr>
<td class="org-left">segment.bytes</td>
<td class="org-left">log.segment.bytes</td>
<td class="org-left">日志分段的最大值,默认是1GB</td>
</tr>

<tr>
<td class="org-left">segment.index.bytes</td>
<td class="org-left">log.index.size.max.bytes</td>
<td class="org-left">日志分段索引的最大值,默认是10MB</td>
</tr>

<tr>
<td class="org-left">segment.jitter.ms</td>
<td class="org-left">log.roll.jitter.ms</td>
<td class="org-left">滚动日志分段时,在segment.ms基础上增加的随机数,默认是0</td>
</tr>

<tr>
<td class="org-left">segment.ms</td>
<td class="org-left">log.roll.ms</td>
<td class="org-left">最长多久滚动一次日志分配,默认是7天</td>
</tr>

<tr>
<td class="org-left">unclean.leader.election.enable</td>
<td class="org-left">unclean.leader.election.enable</td>
<td class="org-left">是否可以从非ISR结合中选举leader副本,默认是false.如果设置为true,可能造成数据丢失</td>
</tr>
</tbody>
</table></li>
</ul>
</div>
</div>
<div id="outline-container-org2ca0330" class="outline-4">
<h4 id="org2ca0330"><span class="section-number-4">4.1.7</span> 删除主题</h4>
<div class="outline-text-4" id="text-4-1-7">
<ul class="org-ul">
<li><p>
如果确定不再使用一个主题,那么最好的方式是将其删除,可以释放一些资源,比如磁盘,句柄,kafka-topics.sh
里面使用delete来删除主题,比如删除主题topic-delete
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --delete --topic topic-delete
Topic topic-delete is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
</pre>
</div></li>
<li>后面的说明告诉我们,必须设置broker端的参数delete.topic.enable=true才能真正删除,这个参数默认值就是true</li>
<li>删除kafka内部的主题(比如__consumer_offsets和__transaction_state)会报错</li>
<li>删除不存在的主题也会报错,但是这里可以使用&#x2013;if-exists来忽略异常</li>
<li>使用kafka-topics.sh删除主题的行为本质上是在ZooKeeper的/admin/delete_topics路径下创建一个和待删
除主题同名的节点,一次标记该主题的待删除状态,真正的删除主题动作是有Kafka的控制器完成的.</li>
<li><p>
了解这个原理后,我们可以直接通过ZooKeepr客户端来删除主题:
</p>
<div class="org-src-container">
<pre class="src src-shell">[zk: localhost:2181/kafka (CONNECTED) 15] create /admin/delete_topics/topic-delete
Created /admin/delete_topics/topic-delete
</pre>
</div></li>
<li>我们还可以完全手动删除某个topic,就是把topic的所有物理存储位置都删除,这个动作比较危险,共分三步,
顺序不能乱:
<ol class="org-ol">
<li>删除ZooKeeper中的节点 /config/topics/topic-delete</li>
<li>删除ZooKeeper中/brokers/topics/topic-delete及其子节点</li>
<li><p>
删除集群中与主题topic-delete有关的文件
</p>
<div class="org-src-container">
<pre class="src src-shell">[root@node1 kafka_2.11-2.0.0]# rm -rf /tmp/kafka-logs/topic-delete*
[root@node2 kafka_2.11-2.0.0]# rm -rf /tmp/kafka-logs/topic-delete*
[root@node3 kafka_2.11-2.0.0]# rm -rf /tmp/kafka-logs/topic-delete*
</pre>
</div></li>
</ol></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgfe16065" class="outline-3">
<h3 id="orgfe16065"><span class="section-number-3">4.2</span> 初识KafkaAdminClient</h3>
<div class="outline-text-3" id="text-4-2">
<ul class="org-ul">
<li>一般情况下,我们倾向于使用kafka-topics.sh脚本来管理主题,但是有时候我们有些过于定制化的开发,这个
时候,我们就要使用API来完成,也就是KafkaAdminClient</li>
</ul>
</div>
<div id="outline-container-org9d0239c" class="outline-4">
<h4 id="org9d0239c"><span class="section-number-4">4.2.1</span> 基本使用</h4>
<div class="outline-text-4" id="text-4-2-1">
<ul class="org-ul">
<li>从0.11.0.0开始,Kafka提供了一个工具类org.apache.kafka.clients.admin.KafkaAdminClient来对kafka管
理,管理的范围包括:
<ul class="org-ul">
<li>管理broker</li>
<li>管理主题</li>
<li>配置</li>
<li>Access Control List</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org624b7a3" class="outline-3">
<h3 id="org624b7a3"><span class="section-number-3">4.3</span> 分区的管理</h3>
<div class="outline-text-3" id="text-4-3">
</div>
<div id="outline-container-org21a9ab2" class="outline-4">
<h4 id="org21a9ab2"><span class="section-number-4">4.3.1</span> 优先副本的选举</h4>
<div class="outline-text-4" id="text-4-3-1">
<ul class="org-ul">
<li>分区使用多副本机制来提升可靠性,只有leader副本对外提供读写服务</li>
<li>如果一旦一个分区的leader副本不可用,那么就需要Kafka从剩下的follower副本里面挑选一个新的副本来对
外提供服务</li>
<li>从某种程度上说,broker节点中leader副本的多少,决定了这个节点负载的高低</li>
<li><p>
在创建主题的时候,该主题的副本会尽可能均匀的分布到Kafka集群的各个broker上,比如一个名叫
topic-partitions的主题,我们为他设定其分区数为3,副本因子也为3的话,创建之后的信息如下:
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-partitions
Topic:topic-partitions PartitionCount:3 ReplicationFactor:3 Configs:
Topic: topic-partitions Partition: 0 Leader: 1 Replicas: 1,2,0 Isr: 1,2,0
Topic: topic-partitions Partition: 1 Leader: 2 Replicas: 2,0,1 Isr: 2,0,1
Topic: topic-partitions Partition: 2 Leader: 0 Replicas: 0,1,2 Isr: 0,1,2
</pre>
</div></li>
<li>kafka几区中一个broker最多只能有它的一个副本</li>
<li>我们可以将leader副本所在的broker节点叫做分区的leader节点</li>
<li>我们可以将follower副本所在的broker节点叫做分区的follower节点</li>
<li>随着时间的更替,kafka集群中的broker节点,不可避免的会宕机,当分区leader节点发生故障的时候,其中一个
follower节点就会成为新的leader节点.而当老的leader副本恢复正常的时候,它回来只能做leader节点了</li>
<li>这会导致有些节点充当了多个主题的leader节点,但是有些节点只作为follower节点.一旦出现上述的情况下,
就会导致集群的负载不均衡,从而影响整体的健壮性和稳定性</li>
<li><p>
我们来模拟下上面的情况,将brokerId=2的节点重启,之后的主题分布如下
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-partitions
Topic:topic-partitions PartitionCount:3 ReplicationFactor:2 Configs:
 Topic: topic-partitions Partition: 0 Leader: 1 Replicas: 1,2,0 Isr, 1,0,2
 Topic: topic-partitions Partition: 1 Leader: 0 Replicas: 2,0,1 Isr, 0,1,2
 Topic: topic-partitions Partition: 2 Leader: 0 Replicas: 0,1,2 Isr, 0,1,2
</pre>
</div></li>
<li>如此一来,在只有这一主题的情况下,节点0做了两个分区的leader节点,负载最高,节点1没有做任何分区的leader节点,负载最低</li>
<li><p>
Kafka中其实有优先副本(preferred replica)的概念,优先副本就是AR集合中的第一个部分,比如下面这一行
中的Replicas就是AR,其内容"1,2,0"就表示优先副本是1
</p>
<div class="org-src-container">
<pre class="src src-shell">Topic: topic-partitions Partition: 0 Leader: 1 Replicas: 1,2,0 Isr, 1,0,2
</pre>
</div></li>
<li>理想情况下,优先副本就应该是该分区的leader副本(新建topic的时候,就是一种理想情况).</li>
<li>当然了一旦有broker宕机,就无法维持这种理想情况</li>
<li>kafka可以进行"分区平衡",从而让优先副本成为分区leader副本.需要注意的是"分区平衡":
<ul class="org-ul">
<li>仅仅是让优先副本成为分区leader副本</li>
<li>而不是说能够达到负载均衡.因为不同的topic的leader副本的压力是不一样的</li>
</ul></li>
<li>这种分区平衡可以有两种方式:
<ul class="org-ul">
<li>分区自动平衡
<ul class="org-ul">
<li>这个需要在broker端设置auto.leader.rebalance.enable(默认值就是true)</li>
<li>这个设置为true的情况下,kafka的控制器会启动一个定时任务,定期轮询所有broker节点,计算分区不平
衡率,超过10%,就会自动执行优先副本的选举动作</li>
<li>执行周期由leader.imbalance.check.interval.seconds控制,默认是5分钟</li>
<li>在生产环境中不建议将auto.leader.rebalance.enable设置为true,这会引起性能问题,因为执行时间无
法自主掌控</li>
</ul></li>
<li>分区手动平衡:
<ul class="org-ul">
<li>使用kafka-perferred-replica-election.sh脚本提供对分区leader副本进行重新平衡的功能.优先副本
的选举过程是一个安全的过程,kafka客户端(比如消费者)可以自动感知leader副本的变更</li>
<li><p>
使用方法如下:
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-preferred-replica-election.sh --zookeeper localhost:2181/kafka
Created preferred replica election path with topic-demo-3,__consumer_offsets-22....

&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-partitions
Topic:topic-partitions PartitionCount:3 ReplicationFactor:2 Configs:
 Topic: topic-partitions Partition: 0 Leader: 1 Replicas: 1,2,0 Isr, 1,0,2
 Topic: topic-partitions Partition: 1 Leader: 2 Replicas: 2,0,1 Isr, 0,1,2
 Topic: topic-partitions Partition: 2 Leader: 0 Replicas: 0,1,2 Isr, 0,1,2
</pre>
</div></li>
<li>上述过程如果涉及的分区数很多,可能会失败.原因在于上述操作的原理,是吧要进行的操作元数据先存
储在ZooKeeper的/admin/preferred_replica_election节点,这个节点最多只能存储1MB数据,
如果超过1MB,那么存储就会失败,我们的分区平衡也会失败.</li>
<li><p>
为了应对这个问题,我们可以使用配置文件来选定一部分的分区先执行分区平衡操作.配置文件名为election.json,
内容如下
</p>
<div class="org-src-container">
<pre class="src src-js">{
  <span style="color: #87af87;">"partitions"</span>:[
    {
      <span style="color: #87af87;">"partition"</span>: 0,
      <span style="color: #87af87;">"topic"</span>: <span style="color: #87af87;">"topic-partitions"</span>
    },
    {
      <span style="color: #87af87;">"partition"</span>: 1,
      <span style="color: #87af87;">"topic"</span>: <span style="color: #87af87;">"topic-partitions"</span>
    },
    {
      <span style="color: #87af87;">"partition"</span>: 2,
      <span style="color: #87af87;">"topic"</span>: <span style="color: #87af87;">"topic-partitions"</span>
    },
  ]
}
</pre>
</div></li>
<li><p>
然后通过kafka-perferred-replica-election.sh配合path-to-json-file参数来对主题topic-partition
执行优先副本的选举操作:
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-preferred-replica-election.sh --zookeeper localhost:2181/kafka --path-to-json-file election.json
Created preferred replica election path with topic-partitions-0,topic-prtitions-1,topic-partions-2
Successfully started preferred replica election for partitions Set(topic-partitions-0,
                                                                   topic-prtitions-1,topic-partions-2

&gt; bin/kafka-topics.sh --zookeeper localhsot:2181
Topic:topic-partitions PartitionCount:3 ReplicationFactor:2 Configs:
 Topic: topic-partitions Partition: 0 Leader: 1 Replicas: 1,2,0 Isr, 1,0,2
 Topic: topic-partitions Partition: 1 Leader: 2 Replicas: 2,0,1 Isr, 0,1,2
 Topic: topic-partitions Partition: 2 Leader: 0 Replicas: 0,1,2 Isr, 0,1,2
</pre>
</div></li>
<li>其他的topic并没有被执行选举操作</li>
<li>实际生产环境中,一般采用path-to-json-file参数来分批,手动的执行优先副本的选举操作,同时操作应
该避开业务高峰期</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org3d3837b" class="outline-4">
<h4 id="org3d3837b"><span class="section-number-4">4.3.2</span> 分区重新分配</h4>
<div class="outline-text-4" id="text-4-3-2">
<ul class="org-ul">
<li><p>
前面我们解决的问题是
</p>
<pre class="example" id="org29d89b9">
由于宕机等因素,分区的leader过分的集中在了某些broker上面
</pre></li>
<li>而我们本节想解决的问题,就是由于某些原因,我们要把分区移动到固定的broker上面,某些原因包括:
<ul class="org-ul">
<li>如果某个节点突然宕机,那么这个节点上的所有副本都处于功能失效状态,kafka并不会把这些失效的分区
副本移动到剩余可用的broker上面</li>
<li>如果要对集群中的节点进行有计划的下线操作时,我们也需要把将要下线的broker上面的分区移动到其他broker上面</li>
<li>当集群中新增加节点的时候,只有新创建的分区才有可能被分配到这个节点,老的分区如果想分配到这个
broker,已达到新老节点负载均衡,也需要手动操作</li>
</ul></li>
<li>为了解决移动分区到指定broker这一问题,kafka提供了kafka-reassign-partitions.sh脚本类执行这项工作.
这个脚本使用分成三个步骤:
<ol class="org-ol">
<li>创建一个包含主题清单的json文件</li>
<li>根据主题清单和broker节点清单生成一份重分配方案</li>
<li>根据这份方案执行具体的重分配动作</li>
</ol></li>
<li>下面我们来用例子展示下这整个过程</li>
<li><p>
提前在在一个三节点(broker0, broker1, broker2)组成的集群中,创建一个topic-reassign,包含4个分区和2个副本
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; /bin/kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-reassign <span style="color: #87af87;">\</span>
  --replication-factor 2 --partitions 4
Created topic <span style="color: #87af87;">"topic-reassign"</span>.

&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-reassign
Topic:topic-reassign PartitionCount:4 ReplicationFactor:2 Configs:
Topic: topic-reassign Partition: 0 Leader: 0 Replicas: 0, 2 Isr: 0,2
Topic: topic-reassign Partition: 1 Leader: 1 Replicas: 1, 0 Isr: 1,0
Topic: topic-reassign Partition: 2 Leader: 2 Replicas: 2, 1 Isr: 2,1
Topic: topic-reassign Partition: 3 Leader: 0 Replicas: 0, 1 Isr: 0,1
</pre>
</div></li>
<li><p>
首先,我们假设需要下线broker1,那么我们首先要把broker1上的分区迁移出去,我们第一步就是要创建一个json
文件(reassign.json),文件内容为要进行分区重分配的主题清单
</p>
<div class="org-src-container">
<pre class="src src-js">{
  <span style="color: #87af87;">"topics"</span>: [
    {
      <span style="color: #87af87;">"topic"</span>: <span style="color: #87af87;">"topic-reassign"</span>
    }
  ],
  <span style="color: #87af87;">"version"</span>:1
}
</pre>
</div></li>
<li><p>
第二步就是根据这个json文件和指定索要分配的broker节点来生成一份候选的重新分配方案
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-reassign-partitions.sh --zookeeper localhost:2181/kafka --generate --topics-to-move-json-file reassign.json --broker-list 0,2
Current partition replica assignment
{<span style="color: #87af87;">"version"</span>: 1,<span style="color: #87af87;">"partitions"</span>:[{<span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,<span style="color: #87af87;">"partition"</span>:2,<span style="color: #87af87;">"replicas"</span>:[2,1],<span style="color: #87af87;">"log_dirs"</span>:[<span style="color: #87af87;">"any"</span>,<span style="color: #87af87;">"any"</span>]},
                            {<span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,<span style="color: #87af87;">"partition"</span>:1,<span style="color: #87af87;">"replicas"</span>:[1,0],<span style="color: #87af87;">"log_dirs"</span>:[<span style="color: #87af87;">"any"</span>,<span style="color: #87af87;">"any"</span>]},
                            {<span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,<span style="color: #87af87;">"partition"</span>:3,<span style="color: #87af87;">"replicas"</span>:[0,2],<span style="color: #87af87;">"log_dirs"</span>:[<span style="color: #87af87;">"any"</span>,<span style="color: #87af87;">"any"</span>]},
                            {<span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,<span style="color: #87af87;">"partition"</span>:4,<span style="color: #87af87;">"replicas"</span>:[2,0],<span style="color: #87af87;">"log_dirs"</span>:[<span style="color: #87af87;">"any"</span>,<span style="color: #87af87;">"any"</span>]}]}
Proposed partition reassignment configuration
{<span style="color: #87af87;">"version"</span>: 1,<span style="color: #87af87;">"partitions"</span>:[{<span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,<span style="color: #87af87;">"partition"</span>:2,<span style="color: #87af87;">"replicas"</span>:[2,0],<span style="color: #87af87;">"log_dirs"</span>:[<span style="color: #87af87;">"any"</span>,<span style="color: #87af87;">"any"</span>]},
                            {<span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,<span style="color: #87af87;">"partition"</span>:1,<span style="color: #87af87;">"replicas"</span>:[0,2],<span style="color: #87af87;">"log_dirs"</span>:[<span style="color: #87af87;">"any"</span>,<span style="color: #87af87;">"any"</span>]},
                            {<span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,<span style="color: #87af87;">"partition"</span>:3,<span style="color: #87af87;">"replicas"</span>:[0,2],<span style="color: #87af87;">"log_dirs"</span>:[<span style="color: #87af87;">"any"</span>,<span style="color: #87af87;">"any"</span>]},
                            {<span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,<span style="color: #87af87;">"partition"</span>:4,<span style="color: #87af87;">"replicas"</span>:[2,0],<span style="color: #87af87;">"log_dirs"</span>:[<span style="color: #87af87;">"any"</span>,<span style="color: #87af87;">"any"</span>]}]}
</pre>
</div></li>
<li>上面的代码并不是真的分配,而是提供了分配方案:
<ul class="org-ul">
<li>第一部分Current partition replica assignment是当前的配置,真正执行reassign之前需要把这个保存
起来,以备后续的回滚操作</li>
<li>第二部分Proposed partition对应的json为重分配的候选方案,我们需要把这部分保存成json文件,假设为
project.json,为后面使用</li>
</ul></li>
<li><p>
第三步,就是执行具体的重分配动作
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-reassign-partitions.sh --zookeeper localhost:2181/kafka -execute --reassignment-json-file project.json
Current partition replica assignment
{<span style="color: #87af87;">"version"</span>: 1,<span style="color: #87af87;">"partitions"</span>:[{<span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,<span style="color: #87af87;">"partition"</span>:2,<span style="color: #87af87;">"replicas"</span>:[2,1],<span style="color: #87af87;">"log_dirs"</span>:[<span style="color: #87af87;">"any"</span>,<span style="color: #87af87;">"any"</span>]},
                            {<span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,<span style="color: #87af87;">"partition"</span>:1,<span style="color: #87af87;">"replicas"</span>:[1,0],<span style="color: #87af87;">"log_dirs"</span>:[<span style="color: #87af87;">"any"</span>,<span style="color: #87af87;">"any"</span>]},
                            {<span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,<span style="color: #87af87;">"partition"</span>:3,<span style="color: #87af87;">"replicas"</span>:[0,2],<span style="color: #87af87;">"log_dirs"</span>:[<span style="color: #87af87;">"any"</span>,<span style="color: #87af87;">"any"</span>]},
                            {<span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,<span style="color: #87af87;">"partition"</span>:4,<span style="color: #87af87;">"replicas"</span>:[2,0],<span style="color: #87af87;">"log_dirs"</span>:[<span style="color: #87af87;">"any"</span>,<span style="color: #87af87;">"any"</span>]}]}

Save this to use as the --reassignment-json-file option during rollback
Successfully started reassignment of partitions.

</pre>
</div></li>
<li><p>
做完这些操作后,我们再来看看分区的情况,所有的分区只在broker0和broker2上分布了
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-reassign
Topic:topic-reassign PartitionCount:4 ReplicationFactor:2 Configs:
Topic: topic-reassign Partition: 0 Leader: 0 Replicas: 2, 0 Isr: 0,2
Topic: topic-reassign Partition: 1 Leader: 0 Replicas: 0, 2 Isr: 0,2
Topic: topic-reassign Partition: 2 Leader: 2 Replicas: 2, 0 Isr: 2,0
Topic: topic-reassign Partition: 3 Leader: 0 Replicas: 0, 2 Isr: 0,2
</pre>
</div></li>
<li><p>
第四步(可选),验证查看分区重分配的进度
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-reassign-partitions.sh --zookeeper localhost:2181/kafka --verify --reassignment-json-file project.json
Status of partition reassignment:
Reassignment of partition topic-reassign-2 completed successfully
Reassignment of partition topic-reassign-1 completed successfully
Reassignment of partition topic-reassign-3 completed successfully
Reassignment of partition topic-reassign-0 completed successfully
</pre>
</div></li>
<li>重分配对集群性能有很大影响,需要额外的资源,比如网络和磁盘,所以推荐分批(每次几个topic)来执行,这一点和
优先副本的选举有异曲同工之妙</li>
</ul>
</div>
</div>
<div id="outline-container-orgbb25dd8" class="outline-4">
<h4 id="orgbb25dd8"><span class="section-number-4">4.3.3</span> 复制限流</h4>
<div class="outline-text-4" id="text-4-3-3">
<ul class="org-ul">
<li>分区重新分配的本质在于数据复制,先增加新的副本,然后进行数据同步,最后删除旧的副本.</li>
<li>如果重分配的量太大,肯定会影响性能,这也是为什么推荐分批来执行</li>
<li>如果某个topic或者某个分区单个的量就很大,分批执行也不够.需要有限流的机制(也就是对副本间的复制流
量加以限制),复制限流的方式有两种:
<ul class="org-ul">
<li>kafka-config.sh脚本</li>
<li>kafka-reassign-partitions.sh脚本</li>
</ul></li>
<li>kafka-config.s主要以动态配置的方式来达到限流的目的,主要更改两个和复制限流相关的参数:
<ul class="org-ul">
<li>follower.replication.throttled.rate: 设置follower副本的复制的速度</li>
<li>leader.replication.throttled.rate: 设置leader副本的复制速度</li>
<li><p>
下面的代码将两者的复制速度限制在1024B/s(也就是1KB/s)以内
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-configs.sh --zookeepr locahost:2181/kafka --entity-type brokers --eneity-name 1
--alter --add-config follower.replication.throttled.rate=1024,leader.replication.throttled.rate=1024
Completed Updating config ofr entity: brokers <span style="color: #87af87;">'1'</span>
</pre>
</div></li>
<li><p>
查看下配置
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-configs.sh --zookeepr localhost:2181/kafka --entity-type brokers --eneity-name 1 --describe
Configs for brokers <span style="color: #87af87;">'1'</span> are leader.reaplication.throttled.rate=1024,follower.replication.throttled.rate=1024
</pre>
</div></li>
<li><p>
配置变更还会在ZooKeeper中创建/config/brokers/1的信息
</p>
<div class="org-src-container">
<pre class="src src-shell">[zk: localhost:2181/kafka (CONNECTED) 6] get /config/brokers/1
{<span style="color: #87af87;">"version"</span>:1,<span style="color: #87af87;">"config"</span>:{<span style="color: #87af87;">"leader.replication.throttled.rate"</span>:<span style="color: #87af87;">"1024"</span>,<span style="color: #87af87;">"follower.replication.throttled.rate"</span>:<span style="color: #87af87;">"1024"</span>}}
</pre>
</div></li>
<li><p>
删除刚才的配置也很简单
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-config.sh --zookeeper localhost:2181/kafka --entity-type brokers --entity-name 1 --alter
--delete-config follower.replication.throttled.rate,leader.replications.throttled.rate
Completed Updating config for entity: brokers <span style="color: #87af87;">'1'</span>.
</pre>
</div></li>
</ul></li>
<li>在主题级别,也有两个同名参数:
<ul class="org-ul">
<li>leader.replication.throttled.replicas</li>
<li>follower.repilcation.throttled.replicas</li>
<li>主题级别的设置是用来限制不同broker上的特定topic所对应的leader副本和follower副本</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgc353262" class="outline-4">
<h4 id="orgc353262"><span class="section-number-4">4.3.4</span> 修改副本因子</h4>
<div class="outline-text-4" id="text-4-3-4">
<ul class="org-ul">
<li>分区数目可以更改(只能增加不能减小)</li>
<li>分区的副本因子也可以更改(不仅仅能增加,也能减小)</li>
<li><p>
我们通常使用kafka-reassign-partition.sh脚本(加&#x2013;execute)来完成副本因子的更改(和刚才重分配分区
时候的方法一样).当然了,json文件要相应的增加一些内容
</p>
<div class="org-src-container">
<pre class="src src-js">diff --git a/prev.js b/prev.js
index 21baf43..8390693 100644
--- a/prev.js
+++ b/prev.js
@@ -4,9 +4,11 @@
      <span style="color: #87af87;">"topic"</span>:<span style="color: #87af87;">"topic-reassign"</span>,
      <span style="color: #87af87;">"partition"</span>:1,
      <span style="color: #87af87;">"replicas"</span>:[
+       2,
        1,
        0],
      <span style="color: #87af87;">"log_dirs"</span>:[
+       <span style="color: #87af87;">"any"</span>,
        <span style="color: #87af87;">"any"</span>,
        <span style="color: #87af87;">"any"</span>
      ]
</pre>
</div></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgd38a69b" class="outline-3">
<h3 id="orgd38a69b"><span class="section-number-3">4.4</span> 如何选择合适的分区数</h3>
<div class="outline-text-3" id="text-4-4">
<ul class="org-ul">
<li>这个问题没有固定的答案,需要从某些角度进行具体分析,最终还是要根据如下条件选择:
<ul class="org-ul">
<li>实际的业务场景</li>
<li>软件条件</li>
<li>硬件条件</li>
<li>负载情况</li>
</ul></li>
</ul>
</div>
<div id="outline-container-orga1e2090" class="outline-4">
<h4 id="orga1e2090"><span class="section-number-4">4.4.1</span> 性能测试工具</h4>
<div class="outline-text-4" id="text-4-4-1">
<ul class="org-ul">
<li>本章主要介绍kafka自带性能测试工具kafka-producer-perf-test.sh</li>
<li><p>
我们使用kafka-producer-perf-test.sh向一个只有一个分区和一个副本的主题topic-1中发送100万条消息,
并且每个消息大小为1024B,生产者对应的acks参数为1,详细内容如下
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-producer-perf-test.sh --topic topic-1 --num-records 1000000 --record-size 1024
--throughput -1 --producer-props bootstrap.servers=localhost:9092 <span style="color: #87c095; font-style: italic;">acks</span>=1
273616 records sent,54723.2 records/sec (53.44 MB/sec), 468.6 ms avg latency,544.0 max latency.
337410 records sent,67482.0 records/sec (65.90 MB/sec), 454.4 ms avg latency,521.0 max latency.
341910 records sent,68382.0 records/sec (66.78 MB/sec), 449.4 ms avg latency,478.0 max latency.
1000000 records sent, 63690.210815 records/sec (62.20 MB/sec), 456.17 ms avg latency, 544.00 ms max latency,
458ms 50th, 517 ms 95th, 525 ms 99th, 543 ms 99.99th
</pre>
</div></li>
<li><p>
我们还可以使用throughput来进行限流,设定值小于0的时候不限流,大于0的时候会限定速度,比如限流100字节
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-producer-perf-test.sh --topic topic-1 --num-records 1000000 --record-size 1024 --throughput 100 --producer-props bootstrap.servers=localhost:9092 <span style="color: #87c095; font-style: italic;">acsk</span>=1
502 records sent, 100.3 records/sec(0.10MB/sec), 2.5ms avg latency,266.0 max latency.
501 records sent, 100.0 records/sec(0.10MB/sec), 0.9ms avg latency,11.0 max latency.
...
</pre>
</div></li>
<li><p>
上面都是测试producer,还有对应的测试consumer的脚本: kafka-consumer-perf-test.sh
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-consumer-perf-test.sh --topic topic-1 --messages 1000000 --broker-list localhost:9092
start.time, end.time, date.consumed.in.MB, MB.sec, data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec
2018-09-22 12:27:49:827,2018-09-22 12:27:57:068,  976.5625, 134.8657, 1000000, 138102.4720, 105, 7136, 136.8501, 140134.5291
</pre>
</div></li>
</ul>
</div>
<ol class="org-ol">
<li><a id="org18d9399"></a>分区数越多吞吐量就越高吗<br />
<div class="outline-text-5" id="text-4-4-1-1">
<ul class="org-ul">
<li>理论上分区数目越多,吞吐量就越大,但是实际上并非如此</li>
<li>我们分别创建如下topic,副本因子都设置为1:
<ul class="org-ul">
<li>分区数为1的topic: topic-1</li>
<li>分区数为20的topic: topic-20</li>
<li>分区数为50的topic: topic-50</li>
<li>分区数为100的topic: topic-100</li>
<li>分区数为200的topic: topic-200</li>
<li>分区数为500的topic: topic-500</li>
<li>分区数为1000的topic: topic-1000</li>
</ul></li>
<li><p>
使用如下命令向这些主题中发送100万条大小为1KB的消息
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-producer-perf-test.sh --topic topic-xxx --num-records 1000000 --record-size 1024 --throughput -1 --producer-props bootstrap.servers-localhost:9092 <span style="color: #87c095; font-style: italic;">acks</span>=1
</pre>
</div></li>
<li><p>
测试结果如图4-2所示
</p>

<div id="org90cad5b" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka-4-2.jpg" alt="kafka-4-2.jpg" />
</p>
<p><span class="figure-number">Figure 16: </span>kafka-4-2.jpg</p>
</div></li>
<li>我们可以看到,分区数为1时,吞吐量最低,随着分区数的增长,相应的吞吐量也跟着上涨.</li>
<li>但是分区数超过一定的阈值之后,整体的吞吐量是不升反降的</li>
<li><p>
使用如下脚本测试消息生产者
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-consumer-perf-test.sh --topic topic-xxx --messages 1000000 --broker-list localhost:9092
</pre>
</div></li>
<li><p>
得到的性能测试结果如下图4-3,和producer的结果类似,也存在类似的阈值
</p>

<div id="org4607b68" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-4-3.jpg" alt="ki-4-3.jpg" />
</p>
<p><span class="figure-number">Figure 17: </span>kafka/ki-4-3.jpg</p>
</div></li>
</ul>
</div>
</li>
</ol>
</div>
<div id="outline-container-orge7b7778" class="outline-4">
<h4 id="orge7b7778"><span class="section-number-4">4.4.2</span> 分区数的上限</h4>
<div class="outline-text-4" id="text-4-4-2">
<ul class="org-ul">
<li>一味地增加分区并不能使得吞吐量一直得到提升, 而且分区数目特别大还会引起kafka进程的崩溃</li>
<li><p>
比如下面我们创建一个topic: topic-bomb, 其包含10000个分区
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-bomb --replication-factor 1 --partitions 10000
Created topic <span style="color: #87af87;">"topic-bomb"</span>.
</pre>
</div></li>
<li><p>
显示创建topic成功后,我们会发现kafka进程崩溃了,通过查看kafka日志文件($KAFKA_HOME/logs/server.log)
我们会发现日志中出现大量的异常
</p>
<pre class="example" id="org3be2064">
java.io.IOException: Too many open files
</pre></li>
<li><p>
"Too many open files"是一种常见的Linux系统错误.我们来查看下当前机器的ulimit
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; ulimit -n
1024
&gt; ulimit -Sn
1024
&gt; ulimit -Hn
4096
</pre>
</div></li>
<li>这里我们来分析下三个设置:
<ul class="org-ul">
<li>Hn (Hard Limit): 对于硬限制:
<ol class="org-ol">
<li>root可以朝任意方向设置硬限制(当然要大于soft limit)</li>
<li>非root用户只可以朝低的方向更改硬限制(当然要大于soft limit)</li>
</ol></li>
<li>Sn (Soft Limit): 软限制是真正其作用的限制,它是在[0,hard_limit]之间浮动:
<ol class="org-ol">
<li>非root用户可以再[0,hard_limit]之间来更改软限制</li>
</ol></li>
<li>n (当前的限制): 一般情况下就是打印Sn(真实的限制)</li>
</ul></li>
<li><p>
可以在命令行修改limit
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; ulimit -n 65535
</pre>
</div></li>
<li>更推荐修改/etc/security/limits.conf(需要重启)</li>
</ul>
</div>
</div>
<div id="outline-container-orgd683b49" class="outline-4">
<h4 id="orgd683b49"><span class="section-number-4">4.4.3</span> 考量因素</h4>
<div class="outline-text-4" id="text-4-4-3">
<ul class="org-ul">
<li>从吞吐量的考量,我们要通过性能测试找到分区数目的"阈值",因为超过"阈值"后,增加分区数目只能起到反作用</li>
<li>由于key的重要作用(比如相同的key会进入同一个分区,压缩的时候会用到key),所以如果应用中key比较重要,
那么开始的时候需要申请多几个分区,以应对以后两年内的流量增长</li>
<li>有些应用场景会要求主题中的消息能够保证顺序性,这种情况下,可以设定分区数目为1</li>
<li>如果一定要有个准则,那么建议把分区设定为集群中broker的倍数:
<ul class="org-ul">
<li>假设集群中有3个broker,可以设定分区数为3,6,9</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-orga50dd59" class="outline-2">
<h2 id="orga50dd59"><span class="section-number-2">5</span> 第五章: 日志存储</h2>
<div class="outline-text-2" id="text-5">
</div>
<div id="outline-container-orgaa8a192" class="outline-3">
<h3 id="orgaa8a192"><span class="section-number-3">5.1</span> 文件目录布局</h3>
<div class="outline-text-3" id="text-5-1">
<ul class="org-ul">
<li>kafka中的消息是以主题为基本单位进行归类的,各个主题在逻辑上是相互独立的</li>
<li>每个主题又可以分为一个或者多个分区,分区的数量可以在创建时候指定,也可以后续修改</li>
<li>每条消息在发送的时候,会根据分区规则被追加到指定分区中</li>
<li>分区中的没条消息都会被分配一个唯一的序列号,也就是offset</li>
<li>假设分区副本是1的话,那么一个分区对应一个日志(log)</li>
<li>为了防止log过大,kafka又引入了日志分段(LogSegment)的概念,将一个log分成多个LogSegment,相当于
把一个巨型文件平均分成多个相对较小的文件</li>
<li>Log以文件夹的形式存储</li>
<li>LogSegment对应于磁盘上的一个日志文件和两个索引文件,以及其他可能的文件</li>
<li><p>
下图就是上述所有关系的总结
</p>

<div id="org4a2a0ad" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-5-1.jpg" alt="ki-5-1.jpg" />
</p>
<p><span class="figure-number">Figure 18: </span>kafka/ki-5-1.jpg</p>
</div></li>
<li><p>
我们继续来看个例子,假设我们有一个名叫topic-log的主题,这个主题有四个分区,那么实际物理存储上的表现
如下
</p>
<div class="org-src-container">
<pre class="src src-shell">[root@node1 kafka-logs]# ls -al | grep topic-logs
drwxr-xr-x 2 root root 4096 May 16 18:33 topic-log-0
drwxr-xr-x 2 root root 4096 May 16 18:33 topic-log-1
drwxr-xr-x 2 root root 4096 May 16 18:33 topic-log-2
drwxr-xr-x 2 root root 4096 May 16 18:33 topic-log-3
</pre>
</div></li>
<li>向Log中追加消息是顺序写入,只有最后一个LogSegment才能执行写入操作,在此之前所有的LogSegment都不能
写入数据</li>
<li>我们将最后一个LogSegment称之为"activeSegment",当activeSegment满足一定条件后,就需要创建新的activeSegment
之后的数据都追加到新的activeSegment</li>
<li>为了便于检索,每个LogSegment文件都有两个索引文件:
<ul class="org-ul">
<li>偏移量索引文件(以.index为后缀)</li>
<li>时间戳索引文件(以.timeindex为文件后缀)</li>
</ul></li>
<li><p>
每个LogSegment都有一个基准编译量baseOffset来标识当前LogSegment中第一条消息的offset,固定为20位数
字.向主题topic-log中发送一定量的消息,某一时刻topic-log-0目录下的布局如下
</p>
<div class="org-src-container">
<pre class="src src-shell">-rw-r--r-- 1 root root       400 May 15 19:43 00000000000000000000.index
-rw-r--r-- 1 root root      5111 May 15 19:43 00000000000000000000.log
-rw-r--r-- 1 root root       600 May 15 19:43 00000000000000000000.timeindex
-rw-r--r-- 1 root root       296 May 15 19:43 00000000000000000133.index
-rw-r--r-- 1 root root      4085 May 15 19:43 00000000000000000133.log
-rw-r--r-- 1 root root       444 May 15 19:43 00000000000000000133.timeindex
</pre>
</div></li>
<li>示例中第二个LogSegment对应的基准位移是133,也说明了该LogSegment中第一条消息偏移量为133,同时说明
第一个LogSegment中共有133条消息</li>
<li>当第一次有消费者消费时,会自动创建内部主题__consumer_offsets,同时也会在log文件夹下创建
__consumer_offsets-xx的文件夹</li>
<li><p>
每一个根目录下面都会抱恨最基本的四个检查文件xxx-checkoutpoint和meta.properties文件,如图5-2
</p>

<div id="orgfd87d06" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-5-2.jpg" alt="ki-5-2.jpg" />
</p>
<p><span class="figure-number">Figure 19: </span>kafka/ki-5-2.jpg</p>
</div></li>
</ul>
</div>
</div>
<div id="outline-container-org81446a1" class="outline-3">
<h3 id="org81446a1"><span class="section-number-3">5.2</span> 日志格式的演变</h3>
<div class="outline-text-3" id="text-5-2">
<ul class="org-ul">
<li>随着Kafka的发展,其消息格式也经历了3个版本的变化:
<ul class="org-ul">
<li>v0</li>
<li>v1</li>
<li>v2</li>
</ul></li>
<li>下面的讨论,如果特殊说明我们讨论的都是消息未压缩的形式</li>
</ul>
</div>
<div id="outline-container-org96b82e3" class="outline-4">
<h4 id="org96b82e3"><span class="section-number-4">5.2.1</span> v0版本</h4>
<div class="outline-text-4" id="text-5-2-1">
<ul class="org-ul">
<li>在Kafka 0.10.0之前都采用这个消息格式.</li>
<li><p>
图5-3详细介绍了消息格式
</p>

<div id="orgeca25ee" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-5-3.jpg" alt="ki-5-3.jpg" />
</p>
<p><span class="figure-number">Figure 20: </span>kafka/ki-5-3.jpg</p>
</div></li>
<li>RECORD部分就是v0版本的消息格式</li>
<li>Offset和messge size两个部分加起来叫做LOG_OVERHEAD</li>
<li>RECORD和LOG_OVERHEAD一起用来描述一条消息</li>
<li>与消息对应的还有消息集的概念,消息集中包含一条或者多条消息,消息集不仅是存储在磁盘上的基本形式,也
是压缩的基本单元</li>
<li>下面来介绍下RECORD的各个字段:
<ul class="org-ul">
<li>crc32(4B): 校验magic到value之间的值</li>
<li>magic(1B): 消息版本好,这里为0</li>
<li>atributes(1B): 低三位表示压缩类型: 0:None, 1:Gzip, 2:SNAPPY, 3表示LZ4</li>
<li>key length(4B): 表示key的长度,如果为-1,表示没有设置key,也就是key=null</li>
<li>key: 可选</li>
<li>value length(4B):实际消息长度,如果为-1,则表示是空消息</li>
<li>value: 消息体,可以为空</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org4ab3d50" class="outline-4">
<h4 id="org4ab3d50"><span class="section-number-4">5.2.2</span> V1版本</h4>
<div class="outline-text-4" id="text-5-2-2">
<ul class="org-ul">
<li>从0.10.版本开始,到0.11.0版本之前的消息格式为v1</li>
<li>比v0版本就多了一个timestamp字段,表示消息的时间戳</li>
<li>v1版本的magic为1</li>
<li>v1版本的attributes的低三位是压缩类型,第4bit也利用起来了:
<ul class="org-ul">
<li>0 表示timestamp类型为CreateTime</li>
<li>1 表示timestamp类型为LogAppendTIme</li>
</ul></li>
<li>timestamp类型由broker端参数log.messaage.timestamp.type类配置,默认为CreateTime,如果在创建ProducerRecord
时没有显式的指定消息的时间戳,那么KafkaProducer也会在发送这条消息之前自动添加上</li>
</ul>
</div>
</div>
<div id="outline-container-orgba0129f" class="outline-4">
<h4 id="orgba0129f"><span class="section-number-4">5.2.3</span> V2版本</h4>
<div class="outline-text-4" id="text-5-2-3">
<ul class="org-ul">
<li>v2版本中的消息称之为Record Batch,而不是之前的Message Set</li>
</ul>
</div>
</div>
<div id="outline-container-org225c57b" class="outline-4">
<h4 id="org225c57b"><span class="section-number-4">5.2.4</span> 消息压缩</h4>
<div class="outline-text-4" id="text-5-2-4">
<ul class="org-ul">
<li>常见的压缩算法是数据量越大效果越好(因为相同的东西更多)</li>
<li>Kafka的一条消息通常不是太大,这就导致要想压缩效果好,必须将多条消息一起压缩</li>
<li>生产者发送的压缩数据:
<ul class="org-ul">
<li>在broker也是保持压缩状态</li>
<li>消费者从服务端获取来的也是压缩的消息</li>
<li>消费者在处理之前才会解压缩</li>
</ul></li>
<li>Kafka日志中使用哪种压缩方式是通过参数compression.type来配置的,默认值是producer,表示使用生产者的
压缩方式,这个值还可以是:
<ul class="org-ul">
<li>gzip</li>
<li>snappy</li>
<li>lz4</li>
<li>uncompressed: 不压缩</li>
</ul></li>
<li><p>
如果设置了压缩的话,那么是将整个消息集压缩之后,作为inner message. inner message整体作为wrapper message
的value,如下图5-5
</p>

<div id="orgeb6c5cb" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-5-5.jpg" alt="ki-5-5.jpg" />
</p>
<p><span class="figure-number">Figure 21: </span>kafka/ki-5-5.jpg</p>
</div></li>
<li>压缩后的wrapper message中的key为null</li>
<li><p>
当生产者创建压缩消息的时候,对内部压缩消息设置的offset从0开始分配内部消息的offset,如下图
</p>

<div id="org6ea7e1d" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-5-6.jpg" alt="ki-5-6.jpg" />
</p>
<p><span class="figure-number">Figure 22: </span>kafka/ki-5-6.jpg</p>
</div></li>
<li>外部的offset,保留了内部消息最后一条消息的absolute offset(绝对位移),这个绝对位移是相对于整个分
区而言的,比如上图5-6中,最右下角的message的内部message offset是5,但是其实它真正的绝对位移是1030,这
个1030,就被保留在了wrapper message里面</li>
<li>当前wrapper message的offset是1030,上一个wrapper message的offset是1024,刚好差6个offset,也就是我
们的inner message offset(从0到5,这六个)</li>
<li>v1版本多了timestamp,对于压缩情形,外层消息的timestamp设置为:
<ul class="org-ul">
<li>如果外层timestamp类型是CreateTime,那么设置内层消息中最大的时间戳</li>
<li>如果外层timestamp类型是LogAppendTIme,那么设置的是Kafka服务器当前的时间戳</li>
</ul></li>
<li>内层消息的timestamp设置为:
<ul class="org-ul">
<li>如果外层消息timestamp类型是CreateTime,那么设置的是生产者创建时候的时间戳</li>
<li>如果外层消息timestamp类型是LogAppendTime,那么所有内层消息的时间戳都会被忽略</li>
</ul></li>
<li>内层消息的timestamp类型永远是CreateTime</li>
</ul>
</div>
</div>
<div id="outline-container-org3ce504c" class="outline-4">
<h4 id="org3ce504c"><span class="section-number-4">5.2.5</span> 变长字段</h4>
<div class="outline-text-4" id="text-5-2-5">
<ul class="org-ul">
<li>kafka v2版本里面参考了Protocol Buffer,引入了变长整形和ZigZag编码</li>
<li>首先来看看变长整形Varints:
<ul class="org-ul">
<li>是使用一个或者多个字节来序列化整数的方法</li>
<li>数值越小,其占用字节数就越小</li>
<li>Varints中每个字节都有一个位于最高位的msb(most sigificant bity),除最后一个字节外,其余msb都设置为1,
最后一个字节的msb设置为0</li>
<li>剩下的7位用于存储数,称之为base128(可以表示128个数字)</li>
</ul></li>
<li>假设我们有个数字300,存储如下:
<ul class="org-ul">
<li>300 = 256+32+8+4</li>
<li>0000 0001 0010 1100 = 256 + 32 + 8 +4</li>
<li>然后把(0000 0001 0010 1100)转成little endian,最后在除了最后一个字节外的字节第一位置1</li>
</ul></li>
<li>再来看看ZigZag编码,其实就是为了解决负数由于其使用补码的话,其实相当于一个非常大的正整数,很浪费
空间.ZigZag的解决办法就是把正数n和负数-n挨着存储,比如:
<ul class="org-ul">
<li>-1编码是1,</li>
<li>1编码是2</li>
<li>-2编码是3</li>
<li>2147483647编码是4294967294</li>
<li>-2147483647编码是4294967295</li>
</ul></li>
<li>前面讲Varint中一个字节只有7位是有效数值位,转变成ZigZag这种绝对值的设置之后,其实每个字节只能表示64个数值</li>
<li>根据前面的规则可言推导出,使用了ZigZag的Varint:
<ul class="org-ul">
<li>0-63之间的数字占1个字节</li>
<li>64-8191之间的数字占2个字节</li>
<li>8192-1048575之间的数字占3个字节</li>
</ul></li>
<li>kafka broker端的message.max.bytes默认大小为100012(占有3个字节),会节省一个字节</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgaf593bc" class="outline-3">
<h3 id="orgaf593bc"><span class="section-number-3">5.3</span> 日志索引</h3>
<div class="outline-text-3" id="text-5-3">
<ul class="org-ul">
<li>每个日志分段文件有两个索引:
<ul class="org-ul">
<li>偏移量索引用来建立消息偏移量offset到物理地址之间的映射,方便快速定位消息所在的物理文件位置</li>
<li>时间戳索引用来查找对应时间内的偏移量信息</li>
</ul></li>
<li>我们的日志分段文件达到一定条件时,要进行切分,其对应的索引文件也要切分.日志分段文件切分包含如下几
个条件,满足其一就可以切分:
<ol class="org-ol">
<li>日志文件大小超过了broker端参数log.segment.bytes,这个默认值是1GB</li>
<li>当前日志分段中消息的最大时间戳与当前系统的时间戳差值大于log.roll.ms(log.roll.hours优先级低)
的值,默认是7天</li>
<li>偏移量索引文件或时间戳索引文件的大小达到broker端参数log.index.size.max.bytes配置的值(默认是10MB)</li>
<li>追加的消息的偏移量与当前日志分段的偏移量之间的差值大于Integer.MAX_VALUE</li>
</ol></li>
<li>对于非活跃的日志分段而言,其对应的索引文件因为已经固定,不需要改变,索引会被设置为只读</li>
<li>对于活跃的日志分段(activeSegment)而言,索引文件还会追加更多的索引项,所以被设定为可读写</li>
<li>在索引文件切分的时候,Kafka会关闭当前正在写入的索引文件,并且设置为只读模式.然后创建新的可读写的索引文件</li>
<li>索引文件的大小是一开始就固定好的(申请完硬盘空间),大小是broker端参数log.index.size.max.bytes决定的
然后在所有文件进行切分的时候,才剪裁到实际大小</li>
<li>换句话说,当前活跃的日志分段的索引文件大小为固定的log.index.size.max.bytes,其他日志分段对应的索引
文件为实际的占用空间</li>
</ul>
</div>
<div id="outline-container-org95d83b5" class="outline-4">
<h4 id="org95d83b5"><span class="section-number-4">5.3.1</span> 偏移量索引</h4>
<div class="outline-text-4" id="text-5-3-1">
<ul class="org-ul">
<li>偏移量索引占用八个字节,分两个部分:
<ul class="org-ul">
<li>relativeOffset: 相对偏移量,表示消息相对于baseOffset的偏移量.当前索引文件的文件名即为baseOffset
的值,相当于hashmap的key</li>
<li>position: 物理地址,也就是消息在日志分段文件中对应的物理地址,相当于hashmap的value</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org3445710" class="outline-4">
<h4 id="org3445710"><span class="section-number-4">5.3.2</span> 时间戳索引</h4>
<div class="outline-text-4" id="text-5-3-2">
<ul class="org-ul">
<li>每个时间戳索引占用12个字节,分为两个部分:
<ul class="org-ul">
<li>timestamp: 当前日志分段最大的时间戳</li>
<li>relativeOffset: 时间戳所对应的相对偏移量</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgcb65ec3" class="outline-3">
<h3 id="orgcb65ec3"><span class="section-number-3">5.4</span> 日志清理</h3>
<div class="outline-text-3" id="text-5-4">
<ul class="org-ul">
<li>Kafka把消息存储在磁盘上,为了控制磁盘占用空间的不断增加,就需要对消息进行清理操作</li>
<li>Kafka中每一个分区副本都对应一个Log,每个Log又可以分为多个日志分段</li>
<li>Kafka提供了两种日志清理策略:
<ol class="org-ol">
<li>日志删除: 按照一定的保留策略直接删除不符合条件的日志分段</li>
<li>日志压缩: 针对每个消息的key进行整合,对于有相同key的不同value值,只保留最后一个版本</li>
</ol></li>
<li>我们可以通过broker端参数log.cleanup.policy来设置日志清理策略:
<ul class="org-ul">
<li>默认值是delete,即日志删除的清理策略</li>
<li>想要使用日志压缩,需要首先把log.cleanup.policy改为compact,把log.cleaner.enable设置为true</li>
<li>如果想要两者都支持,还可以把log.cleanup.policy改为 <span class="underline">delete,compact</span> ,可以在主题级别控制</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org41c622a" class="outline-4">
<h4 id="org41c622a"><span class="section-number-4">5.4.1</span> 日志删除</h4>
<div class="outline-text-4" id="text-5-4-1">
<ul class="org-ul">
<li>Kafka的日志管理器中,会有一个专门的日志删除任务来周期性的检查和删除不符合保留条件的日志分段文件</li>
<li>这个周期可以通过broker端参数log.retention.check.interval.ms来配置,默认值为5分钟</li>
<li>当前日志分段的保留策略有三种:
<ul class="org-ul">
<li>基于时间:
<ul class="org-ul">
<li>日志删除任务会检查当前的日志文件中,是否有保留时间超过retentionMs的日志分段</li>
<li>retentionMs可以通过如下三个值配置log.retention.ms &gt; log.retention.minutes &gt; log.retention.hours</li>
<li>默认情况下retentionMs的值为7天</li>
<li>查找过期的日志分段文件,并不是简单的根据lastModifiedTime来计算,而是更加日志分段中最大的时间戳
largestTimeStamp来计算</li>
<li>如果一共有n个待删除的日志段,而当前一共就只有n个日志段,那么说明所有的日志段都要被删除,这个时候,要记得
先切分出 一共新的日志段做activeSegment,然后执行删除</li>
<li>删除日志分段时,会先从跳跃表中移除日志分段,然后将日志分段和其索引文件加上".delete"后缀,最后
交给一个延时任务来删除这些文件</li>
</ul></li>
<li>基于日志大小:
<ul class="org-ul">
<li>日志任务会检查当前的日志文件总大小是否超过设定的阈值(retentionSize)</li>
<li>这个阈值由log.retention.bytes来配置,默认是-1</li>
<li>注意,这个阈值是所有日志文件的总大小,而不是单个日志分段</li>
<li>单个日志分段的大小由broker端参数log.segment.bytes来限制,默认值为1GB</li>
</ul></li>
<li>基于日志起始偏移量
<ul class="org-ul">
<li>activeSegment往后数n个offset进行删除</li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org0eef95b" class="outline-4">
<h4 id="org0eef95b"><span class="section-number-4">5.4.2</span> 日志压缩</h4>
<div class="outline-text-4" id="text-5-4-2">
<ul class="org-ul">
<li>Log Compaction(翻译成日志压缩,但是翻译不准确,其实不是压缩),而是定期清理value值,保证同一个key只有一个value值</li>
<li>Message Compression(翻译成消息压缩,这个翻译的比较准确,因为会使用gzip,Snappy来减小message大小)</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgbc57758" class="outline-3">
<h3 id="orgbc57758"><span class="section-number-3">5.5</span> 磁盘存储</h3>
<div class="outline-text-3" id="text-5-5">
<ul class="org-ul">
<li>Kafka依赖文件系统(也就是磁盘)来存储和缓存消息.</li>
<li>传统消息中间件比如RabbitMQ,由于速度的考量,就使用内存作为默认介质,磁盘作为备选介质</li>
<li>磁盘的特性决定了,顺序写很快(高达600MB/s),随机写很慢(只有100KB/s),性能相差6000倍.线性写可以有很
多优化的地方,比如:
<ul class="org-ul">
<li>预读(read-ahead): 提前将一个比较大的磁盘读入内存</li>
<li>后写(write-ahead): 将很多小的逻辑写合并起来做一个大的物理写</li>
</ul></li>
<li>顺序写磁盘的速度,快于随机写内存的速度</li>
<li>Kafka在性能上具备竞争力的唯一因素,就是只允许顺序写:即只能在日志文件的尾部追加新消息,并且也不允许
修改已写入的消息</li>
</ul>
</div>
<div id="outline-container-org6119b56" class="outline-4">
<h4 id="org6119b56"><span class="section-number-4">5.5.1</span> 页缓存</h4>
<div class="outline-text-4" id="text-5-5-1">
<ul class="org-ul">
<li>页缓存是操作系统实现的主要磁盘缓存,用来减少I/O操作.具体来说就是:
<ul class="org-ul">
<li>把磁盘上的数据缓存到内存中,把对磁盘访问变成对内存的访问</li>
<li>当一个进程准备读取磁盘上的内容的时候,操作系统会先查看需要读取的数据所在的page,是否在页缓存(pagecache):
<ol class="org-ol">
<li>如果存在,直接返回数据,就避免了物理磁盘的I/O操作</li>
<li>如果不存在,操作系统会要求把这个page存储pagecache,之后再从pagecache返回数据给进程</li>
</ol></li>
<li>写入也是同样的过程,首先会检查数据对应的page是否在pagecache:
<ol class="org-ol">
<li>如果存在,那么写入到页缓存</li>
<li>如果不存在,操作系统会先把这个page载入到pagecache里面,然后写入页缓存</li>
<li>写和读不一样,一旦页缓存被修改了之后,就变成了脏页,操作系统会在合适的时机把脏页写入磁盘,以
保证数据一致性</li>
<li>在处理脏页的时候,新的I/O请求会被阻挡,直至所有的脏页都被冲刷到磁盘中</li>
</ol></li>
</ul></li>
<li>对于一个进程而言,它在进程内部会缓存处理所需要的数据,同样一份数据还能缓存在操作系统的页缓存中,所
以一份数据可能被缓存了两次</li>
<li>一旦进程重启,页缓存依然保持有效,进程内的缓存却需要重建.所以使用操作系统提供的页缓存更加安全有效</li>
<li>Kafka中大量使用了页缓存,这是kafka实现高吞吐的重要因素.</li>
<li>除了操作系统的刷盘任务,kafka自己也同样提供了同步刷盘,以及间断性刷盘的功能.同步刷盘可以提高消息
的可靠性,防止由于机器掉电等异常造成的数据丢失,不过作者不建议使用kafka的这些功能,原因有二:
<ul class="org-ul">
<li>刷盘任务就应该交由操作系统去调配</li>
<li>消息可靠性应该由多副本机制来保障</li>
</ul></li>
<li>Kafka应该尽量避免使用swap:
<ul class="org-ul">
<li>vm.swappiness参数上限是100,表示积极使用swap分区</li>
<li>vm.swappiness参数下限是0,表示任何情况下都不要使用swap分区,这样一来,当内存耗尽时,就会根据一定
的规则突然中止某些进程</li>
<li>作者建议设置vm.swappiness为1</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgf281d26" class="outline-4">
<h4 id="orgf281d26"><span class="section-number-4">5.5.2</span> 零拷贝</h4>
<div class="outline-text-4" id="text-5-5-2">
<ul class="org-ul">
<li><p>
除了消息顺序追加,页缓存等技术,kafka还使用零拷贝(Zero-Copy)技术来进一步提升性能
</p>
<pre class="example" id="org7e68c96">
所谓零拷贝,是指将数据直接从磁盘文件复制到网卡设备中,而不经由应用程序之手
</pre></li>
<li>我们来对比一下传统方法和零拷贝的区别,场景是"读取一个文件,并且将内容通过网络传输出去":
<ul class="org-ul">
<li>传统方法:
<ul class="org-ul">
<li><p>
首选需要把静态内容从磁盘复制到一个内存buffer中.context switch从user space到kernel space,
然后再从kernel space返回user space, 一共两次
</p>
<div class="org-src-container">
<pre class="src src-c"><span style="color: #87c095;">read</span>(file, tmp_buf, len);
</pre>
</div></li>
<li><p>
然后将这个buf通过Socket传输给用户. context switch 从user space到kernel space,然后再从kernel
space返回user space, 一共两次,总共四次了
</p>
<div class="org-src-container">
<pre class="src src-c"><span style="color: #87c095;">write</span>(socket, tmp_buf, len);
</pre>
</div></li>
<li>整个过程文件A经历了4次复制:
<ol class="org-ol">
<li>调用read()时,文件A中的内容被复制到了内核模式下的Read Buffer中</li>
<li>CPU控制将内核模式数据复制到用户模式下</li>
<li>调用write()时,将用户模式下的内容复制到内核模式下的Socket Buffer中</li>
<li>将内核模式下的Socket Buffer的数据复制到网卡设备中传送</li>
</ol></li>
<li><p>
整个过程总共四次拷贝,四次context switch,如图5-23
</p>

<div id="org4e4c765" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-5-23.jpg" alt="ki-5-23.jpg" />
</p>
<p><span class="figure-number">Figure 23: </span>kafka/ki-5-23.jpg</p>
</div></li>
</ul></li>
<li>零拷贝:
<ul class="org-ul">
<li>零拷贝通过DMA(Dirrect Memory Access)技术,将文件内容复制到内核模式下的Read Buffer</li>
<li>DMA引擎直接将数据从内核模式中传递到网卡设备</li>
<li>整个过程没有把数据复制到Socket Buffer(只有数据的meta信息和文件描述符传给Socket Buffer,没有
实际的数据传输)</li>
<li><p>
整个过程总共两次拷贝,两次context switch,如图5-24
</p>

<div id="org29f456d" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-5-24.jpg" alt="ki-5-24.jpg" />
</p>
<p><span class="figure-number">Figure 24: </span>kafka/ki-5-24.jpg</p>
</div></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org8499379" class="outline-2">
<h2 id="org8499379"><span class="section-number-2">6</span> 第六章: 深入服务端</h2>
<div class="outline-text-2" id="text-6">
</div>
<div id="outline-container-org1abb69f" class="outline-3">
<h3 id="org1abb69f"><span class="section-number-3">6.1</span> 协议设计</h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>在实际应用中,Kafka经常被用作高性能,可扩展的消息中间件.为了提供高性能,Kafka自定义了一组基于TCP的二进制协议</li>
<li>在目前的Kafka 2.0.0中,一共包含了43种协议类型,每种协议都包含:
<ul class="org-ul">
<li>请求Request:包括:
<ol class="org-ol">
<li>RequestHeader</li>
<li>RequestBody</li>
</ol></li>
<li>响应Response:
<ol class="org-ol">
<li>ResponseHeader</li>
<li>ResponseBody</li>
</ol></li>
</ul></li>
<li>RequestHeader包括4个域:
<ul class="org-ul">
<li>api_key: API 标识,比如PRODUCE表示发送消息,FETCH表示拉取消息,int16类型</li>
<li>api_version: API版本,int16类型</li>
<li>correlation_id: 客户端指定的一个数字作为这次请求的id,服务端处理返回时,也会在Response加上这个id,
这样客户端就能把某个请求和相应对应起来了,int32类型</li>
<li>client_id: 客户端id,string类型</li>
</ul></li>
<li>ResponseHeader中只包含一个field:
<ul class="org-ul">
<li>correlation_id, int32类型</li>
</ul></li>
<li>我们下面来看看几个例子,首先是消息发送的协议,也就是ProduceRequest/ProduceResponse:
<ul class="org-ul">
<li>api_key = 0, 表示PRODUCE</li>
<li>RequestBody如下图6-3,图中各个参数意义如下:
<ul class="org-ul">
<li>#+CAPTION: kafka/ki-6-3.jpg
<img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-6-3.jpg" alt="ki-6-3.jpg" /></li>
<li>transactional_id: 事务id,从0.11.0开始支持,如果不使用事务功能,那么该值为null</li>
<li>acks: 对应客户端参数acks</li>
<li>timeout: 请求超时时间,对应客户端参数request.timeout.ms,默认30秒</li>
<li>topic_data: 是个数组,每个数组的成员是:
<ol class="org-ol">
<li>topic: 主题名称</li>
<li>data: 也是个数组,每个数组的成员是:
<ul class="org-ul">
<li>partition: 分区编号</li>
<li>record_set: 与分区对应的数据</li>
</ul></li>
</ol></li>
</ul></li>
</ul></li>
<li>我们在2.2.1中了解到:
<ul class="org-ul">
<li>消息累加器RecordAccumulator中的消息以&lt;Partition, Deque&lt;ProducerBatch&gt;&gt; 形式进行存储</li>
<li>之后Sender线程把上述形式转换为&lt;Node, List&lt;ProducerBatch&gt;&gt;的形式</li>
<li>发送之前,针对每个Node, Sender线程会把对应的List&lt;ProducerBatch&gt;形式再转换为ProducerRequest的具体形式:
<ol class="org-ol">
<li>List&lt;ProducerBatch&gt;中的内容首先按照主题进行分类(PruduceRequest中的topic)</li>
<li>然后按照分区编号进行分类(对应ProduceRequest中的partition)</li>
<li>之后ProducerBatch集合就对应ProduceRequest中的record_set</li>
</ol></li>
<li>在客户端按照分区归纳之后,在服务器端就不用转换了,这样将负载的压力分摊给了客户端,提升了整体的性能</li>
</ul></li>
<li>如果acks设置非0值,那么生产者在客户端发送ProduceRequest请求之后,就需要(异步)等待服务端的响应
ProduceResponse</li>
<li>V6版本的ProduceResponse组织结果如图,6-4各部分的含义如下:
<ul class="org-ul">
<li><p>
图6-4
</p>

<div id="org3d26ba1" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-6-4.jpg" alt="ki-6-4.jpg" />
</p>
<p><span class="figure-number">Figure 25: </span>kafka/ki-6-4.jpg</p>
</div></li>
<li>throttle_time_ms: 如果超过了配额(quota)限制,则需要延迟该请求的处理时间,如果没有配置配额,那么该字段的值为0</li>
<li>responses: 是个数组,每个数组的成员是:
<ol class="org-ol">
<li>topic: 主题名字</li>
<li>partition_responses: 主题中所有分区的响应,是个数组,每个数组的成员是:
<ul class="org-ul">
<li>partition: 分区编号</li>
<li>error_code: 错误码</li>
<li>base_offset: 消息集的起始偏移量</li>
<li>log_apppend_time: 消息写入broker端的时间</li>
<li>log_start_offset: 所在分区的起始偏移量</li>
</ul></li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org5a30526" class="outline-3">
<h3 id="org5a30526"><span class="section-number-3">6.2</span> 时间轮:</h3>
<div class="outline-text-3" id="text-6-2">
<ul class="org-ul">
<li>Kafka中存在大量的延时操作,比如延时生产,延时拉取,和延时删除</li>
<li>Kafka并没有使用JDK自带的Timer或DelayQueue来实现延时功能,而是基于时间轮的概念自定义实现了一个用
于延时功能的定时器</li>
<li><p>
如图6-7所示,Kafka中的时间轮是一个存储定时任务的环形队列,底层采用数组实现,数组中的每个元素都可以存放
一个定时任务列表
</p>

<div id="orgaa3b42e" class="figure">
<p><img src="https://raw.githubusercontent.com/harrifeng/image/master/kafka/ki-6-7.jpg" alt="ki-6-7.jpg" />
</p>
<p><span class="figure-number">Figure 26: </span>kafka/ki-6-7.jpg</p>
</div></li>
<li>每个定时任务列表是一个环形的双向链表,链表中每个项都是定时任务项TimerTaskEntry,其中封装了真正的定时任务TimerTask</li>
</ul>
</div>
</div>
<div id="outline-container-org90d4854" class="outline-3">
<h3 id="org90d4854"><span class="section-number-3">6.3</span> 延时操作</h3>
<div class="outline-text-3" id="text-6-3">
<ul class="org-ul">
<li>如果在使用生产者客户端发送消息的时候将acks参数设置为-1,那么就意味着要等待ISR集合中所有的副本都
确认收到消息后才能正确的收到响应的结果,或者是超时异常</li>
<li>我们下面来看一个例子的第一步:
<ul class="org-ul">
<li>图6-9</li>
<li>分区有三个副本: leader, follower1和follower2</li>
<li>他们都在ISR集合中</li>
<li>当前三个副本的的HW和LEO都在3(注意是2的后面)</li>
<li>生产者请求写入消息3和4,那么肯定是写入到leader副本的</li>
</ul></li>
<li>第二步
<ul class="org-ul">
<li>图6-10</li>
<li>生产者把数据写入到leader副本后,follower1和follower2都来leader副本拉取数据</li>
<li>由于acks为-1,那么必须要等到follower1和follower2都收到消息3,4之后,才能告知客户端正确接收了所有消息</li>
</ul></li>
<li>第三步
<ul class="org-ul">
<li>图6-11</li>
<li>消息3和4,被成功同步到follower1和follower2,那么他们就可以通知客户端自己接收到了所有消息</li>
<li>如果在一定时间里,follower1或follower2没有完全拉取到消息3,4,那么就要返回超时异常给客户端</li>
<li>生产请求的超时时间由参赛request.timeout.ms设置,默认是30秒</li>
</ul></li>
<li>Kafka中有多种延时操作:
<ul class="org-ul">
<li>延时生产</li>
<li>延时拉取</li>
<li>延时数据删除</li>
</ul></li>
<li>延时操作创建之后,会被加入延时操作管理器(DelayedOperationPurgatory)来做专门的处理</li>
<li>延时操作管理器(DelayedOperationPurgatory)都会配备一个定时器(SystemTimer)来做超时管理,
定时器(SystemTimer)的底层就是采用时间轮(TimingWheel)来实现</li>
<li>图6-12描绘了客户端在请求写入消息到收到响应结果之间的细节:
<ul class="org-ul">
<li>图6-12</li>
<li>如果没有成功的消息写入,或者acks参数不是-1(也就是有一个日志写入就可以返回),那么就在写入日志后,直接返回</li>
<li>否则,就要创建延时生产操作,并且归延时操作管理器管理</li>
<li>延时操作超时了,就直接返回给客户端超时的信息</li>
<li>延时操作满足了条件(这个条件的满足需要配备一个监听池来负责监听外部事件),可以正常返回给客户端</li>
</ul></li>
<li>图6-13介绍了和延时生产对应的延时拉取:
<ul class="org-ul">
<li>图6-13</li>
<li>两个follower副本都已经拉取到了leader副本的最新位置</li>
<li>此后,如果leader副本没有更新,那么follower副本频繁的请求拉取,则会是浪费资源的操作</li>
<li>kafka的做法是在处理拉取请求的时候:
<ol class="org-ol">
<li>首先读取一次日志文件,如果搜集不到足够多的消息(fetch.min.bytes,默认值为1),换句话说,就是一拉
取值就是0,那么就会创建一个延时拉取操作(DelayedFetch),等待拉取到足够多的消息</li>
<li>当等待到足够多的消息后(要么是超时,要么是外部事件触发:消息追加到了leader副本的本地文件中),
会出发延时拉取执行,再读取一次日志文件,然后将拉取结果返回给follower副本</li>
<li>如果follower副本总是跟不上leader副本,那么拉取的时候,每次都不会为0,那么就永远都大于fetch.min.bytes
所以也就永远不会创建延时拉取</li>
</ol></li>
</ul></li>
<li>目前版本的kafka还引入了事务的概念,对于消费者或者followe副本而言,其默认的事务隔离级别为"read_uncommitted",
可以通过更改客户端参数isolation.level将事务级别更改为"read_committed",两者区别:
<ul class="org-ul">
<li>read_uncommitted: 可以读取生产者已经写入却未提交的信息</li>
<li>read_committed: 不可以读取生产者已经写入却未提交的信息</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgada1d03" class="outline-3">
<h3 id="orgada1d03"><span class="section-number-3">6.4</span> 控制器</h3>
<div class="outline-text-3" id="text-6-4">
<ul class="org-ul">
<li>在kafka集群中会有一个或者多个broker,其中一个broker会被选举为控制器,它负责管理整个集群中所有分区
和副本的状态</li>
<li>当某个分区的leader副本出现故障时,由控制器为该分区选举新的leader副本</li>
<li>当检测到某个分区的ISR集合发生变化时,由控制器负责通知所有的broker更新元数据</li>
<li>当使用kafka-topics.sh脚本为某个topic增加分区数量时,同样还是由控制器负责分区的重新分配</li>
</ul>
</div>
<div id="outline-container-orgc559461" class="outline-4">
<h4 id="orgc559461"><span class="section-number-4">6.4.1</span> 控制器的选举及异常恢复</h4>
<div class="outline-text-4" id="text-6-4-1">
<ul class="org-ul">
<li><p>
Kafka中的控制器选举工作依赖于Zookeeper,成功选举为控制权的broker会在ZooKeeper中创建/controller
这个临时节点,一个可能的内容如下
</p>
<div class="org-src-container">
<pre class="src src-js">{<span style="color: #87af87;">"version"</span>:1,<span style="color: #87af87;">"brokerid"</span>:0,<span style="color: #87af87;">"timestamp"</span>:<span style="color: #87af87;">"1529210278988"</span>}
</pre>
</div>
<ul class="org-ul">
<li>version固定为1</li>
<li>brokerid表示成为控制器的broker的id</li>
<li>timestamp表示竞选成为控制权时的时间戳</li>
</ul></li>
<li>在任意时刻,集群中有且仅有一个控制器,每个broker启动的时候都会去尝试读取/controler节点的brokerid值:
<ul class="org-ul">
<li>如果读到的brokerid不为-1,则表示已经有其他的broker成功成为控制器,当前broker就放弃竞选</li>
<li>如果ZooKeeper里面不存在这个节点,或者节点数据异常,那么就去尝试创建/controller</li>
<li>可能会有多个broker去同时创建/controller,只有一个broker会成功</li>
<li>所有broker都要在内存里面保存当前控制器的brokerid,叫做activeControllerId</li>
</ul></li>
<li>ZooKeeper里面还有一个与控制器相关的节点/controller_epoch节点,存放的是控制器变更的次数</li>
<li>controller_epoch起始值为1,当控制器发生变更时,每选出一个控制器,这个值就更新一次</li>
<li>每个和控制器交互的请求,都会携带controller_epoch这个字段:
<ul class="org-ul">
<li>如果请求中的controller_epoch值小于内存中的controller_epoch,则认为这个是已经过期的控制器所发
的请求,那么就会被认为是无效请求</li>
<li>如果请求中的controller_epoch值大于内存中的controller_epoch,那么就说明有新的控制器当选了</li>
</ul></li>
<li>具备控制器身份的broker需要比普通的broker多了如下责任:
<ul class="org-ul">
<li>监听分区变化情况</li>
<li>监听主题变化情况</li>
<li>监听broker变化情况</li>
<li>从ZooKeeper中读取获取当前所有的主题,分区,以及broker有关的信息并进行相应的管理</li>
<li>启动并管理分区状态机和副本状态机</li>
<li>更新集群的元数据信息</li>
<li>如果参数auto.leader.rebalance.enable设置为true,还会开一个一个名为auto-leader-rebalance-task的
定时任务来负责维护分区的优先副本的均衡</li>
</ul></li>
<li>Kafka早期版本中,并没有采用Kafka Controller的概念来对分区和副本状态进行管理,而是依赖于ZooKeeper:
<ul class="org-ul">
<li>每个broker都会在ZooKeeper上位分区和副本注册大量的监听器</li>
<li>当分区和副本变化时,会唤醒很多不必要的监听器</li>
<li>这种严重依赖ZooKeeper的设计会有脑裂,羊群效应,且容易造成ZooKeeper的过载隐患</li>
</ul></li>
<li>新版本的设计中,只有Kafka controller在ZooKeeper上注册相应的监听器,其他的broker极少再需要监听ZooKeeper中的数据变化,
不过,每个broker还是会对/controller节点天剑监听器,以此来监听此节点的数据变化,如图6-14</li>
<li>手动删除/controller临时节点会触发新一轮的选举</li>
</ul>
</div>
</div>
<div id="outline-container-orgaea8259" class="outline-4">
<h4 id="orgaea8259"><span class="section-number-4">6.4.2</span> 如何优雅的关闭</h4>
<div class="outline-text-4" id="text-6-4-2">
<ul class="org-ul">
<li>不要使用kill -9 $KAFKA_PID 这种办法关闭</li>
<li>请使用kill -15 $KAFKA_PID 这种办法关闭,因为:
<ul class="org-ul">
<li>Kafka会捕捉信号后执行kafka-shutdown-hock钩子,除了正常关闭一些必要资源</li>
<li>还会执行一个ControlledShutdown的动作:
<ol class="org-ol">
<li>让消息完全同步到磁盘</li>
<li>会对其上的leader副本进行迁移</li>
</ol></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgeac90fa" class="outline-4">
<h4 id="orgeac90fa"><span class="section-number-4">6.4.3</span> 分区leader的选举</h4>
<div class="outline-text-4" id="text-6-4-3">
<ul class="org-ul">
<li>分区leader副本的选举由控制器具体负责实施,实施的时间点有:
<ul class="org-ul">
<li>创建分区(创建主题和增加分区)</li>
<li>分区上线(比如原来的leader副本下线,需要选举一个新的leader上线来对外提供服务)</li>
</ul></li>
<li>选举策略为OfflinePartitionLeaderElectionStrategy,基本策略是:
<ul class="org-ul">
<li>按照AR集合中副本的顺序查找第一个存货的副本(并且这个副本在ISR集合中)</li>
<li>一个分区的AR集合在分配的时候就被指定,并且质押不发生重分配的情况,集合内部副本的顺序是保持不变的</li>
<li>而分区ISR结合中副本的数据可能改变</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org52b77e8" class="outline-3">
<h3 id="org52b77e8"><span class="section-number-3">6.5</span> 参数解密</h3>
<div class="outline-text-3" id="text-6-5">
<ul class="org-ul">
<li>如果broker端没有显示的配置listeners(或者advertised.listeners)使用IP地址,那么最好将bootstrap.server
配置成主机名,而不要使用IP地址,因为Kafka内部使用的是全称域名</li>
</ul>
</div>
<div id="outline-container-orgb1435bc" class="outline-4">
<h4 id="orgb1435bc"><span class="section-number-4">6.5.1</span> broker.id</h4>
<div class="outline-text-4" id="text-6-5-1">
<ul class="org-ul">
<li>broker.id是在broker启动之前必须设置的参数,kafka集群中,每个broker都有一个唯一的id</li>
<li>broker启动的时候,会在ZooKeeper的/brokers/ids下面创建一个以brokerid为名称的虚节点
broker的健康状态检查就依赖于此虚节点</li>
<li>broker下线时,这个虚节点会自动删除,其他broker节点或客户端通过/brokers/ids来判断broker的健康状况</li>
</ul>
</div>
</div>
<div id="outline-container-orge6b481b" class="outline-4">
<h4 id="orge6b481b"><span class="section-number-4">6.5.2</span> bootstrap.servers</h4>
<div class="outline-text-4" id="text-6-5-2">
<ul class="org-ul">
<li>bootstrap.servers是新版本的kafka用来指定broker地址的地方</li>
</ul>
</div>
</div>
<div id="outline-container-orgf647bd2" class="outline-4">
<h4 id="orgf647bd2"><span class="section-number-4">6.5.3</span> 服务端参数列表:</h4>
<div class="outline-text-4" id="text-6-5-3">
<ul class="org-ul">
<li>auto.create.topics.enable,默认值true,是否开启自动创建主题的功能</li>
<li>auto.leader.rebalance.enable,默认是true,是否开始自动leader再均衡</li>
<li>background.threads,默认值是10,指定后台任务线程数</li>
<li>compression.type,默认值producer,消息的压缩类型,默认值producer表示根据生产者使用的压缩类型压缩
uncompressed表示不启用压缩</li>
<li>delete.topic.enable,默认值true,是否可以删除主题</li>
<li>leader.imbalance.check.interval.seconds,默认值300,检查leader是否分布不均匀的周期</li>
<li>leader.imbalance.per.broker.percentage,默认值10,允许leader不均衡的比例</li>
<li>log.flush.interval.messages,默认值Long.MAX_VALUE,如果日志中的消息存入磁盘前达到这个参数设置
的阈值,则会强制将这些日志文件刷新到磁盘.消息在写入磁盘前还要经历一层操作系统的页缓存,如果期间
发生掉电,则这页缓存中的数据会丢失</li>
<li>log.flush.interval.ms,默认值null,刷新日志文件的时间间隔,如果没有值,则使用log.flush.scheduler.interval.ms
来运行</li>
<li>log.flush.scheduler.interval.ms,默认值Long.MAX_VALUE,检查日志文件是否需要刷新时间间隔</li>
<li>log.retention.bytes,默认值-1,日志文件的最大保留大小</li>
<li>log.retention.hours,默认值7天,日志文件的留存时间,单位为小时</li>
<li>log.retention.minutes,默认值null,日志文件的留存时间,单位为分钟</li>
<li>log.retention.ms,默认值null,日志文件的留存时间,单位为毫秒.这个优先级最高,minutes此致,hours最低</li>
<li>log.roll.hours,默认值7天,经过多长时间会强制创建一个新的日志分段</li>
<li>log.roll.ms,默认值null,同上,不过单位为毫秒,优先级最高</li>
<li>log.segment.bytes,默认值1GB,日志分段文件的最大值,超过这个值会强制创建一个新的日志分段</li>
<li>log.segment.delete.delay.ms,默认值60秒,从操作系统删除文件的等待时间</li>
<li>min.insync.replicas,默认值1,ISR集合中最少的副本数</li>
<li>num.io.threads,默认值8,处理请求的线程数,包括磁盘IO</li>
<li>num.network.threads,默认值3,处理接受和返回相应的线程数</li>
<li>log.cleaner.enable,默认值true,是否开启日志清理功能</li>
<li>log.cleaner.min.cleanable.ratio,默认值0.5,限定可执行清理操作的最小污浊率</li>
<li>log.cleaner.threads,默认值1,用于日志清理的后台线程数</li>
<li>log.cleanup.policy,默认值delete,日志清理策略,还有一个可选项为compact,表示日志压缩</li>
<li>log.index.interval.bytes,默认值4096,每隔多少个字节消息写入量就添加一条索引</li>
<li>log.index.size.max.byts,默认值10MB,索引文件的最大值</li>
<li>log.message.format.version,默认值2.0-IV1,消息格式的版本</li>
<li>log.message.timestamp.type,默认值CreateTime,消息中的时间戳类型,另一个可选项为LogAppendTIme.
CreateTime表示消息的创建时间,LogAppendTime表示消息追加到日志中的时间</li>
<li>log.retention.check.interval.ms,默认值5分钟,日志清理的检查周期</li>
<li>num.partitions,默认值1,主题中默认的分区数</li>
<li>reserved.broker.max.id,默认值1000,broker.id能配置的最大值</li>
<li>create.topic.polic.class.name,默认值null,主题名字合法性策略,需要实现
org.apache.kafka.server.policy.CreateTopicPolicy接口</li>
<li>broker.id.generation.enable,默认值true,是否开启自动生成broker.id的功能</li>
<li>broker.rack,默认值null,配置broker的机架信息</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-orgcdd35c0" class="outline-2">
<h2 id="orgcdd35c0"><span class="section-number-2">7</span> 第7章 深入客户端</h2>
<div class="outline-text-2" id="text-7">
</div>
<div id="outline-container-org43136a1" class="outline-3">
<h3 id="org43136a1"><span class="section-number-3">7.1</span> 分区分配策略</h3>
<div class="outline-text-3" id="text-7-1">
<ul class="org-ul">
<li>kafka提供了消费者客户端参数partition.assignment.strategy来设置消费者与订阅主题之间的分区分配策略,</li>
<li>默认情况下这个数的值为org.apache.kafka.clients.consumer.RangeAssignor,除此之外还有两个策略:
<ul class="org-ul">
<li>RoundRobinAssignor</li>
<li>StickyAssignor</li>
</ul></li>
<li>参数partition.assignment.strategy可以配置多个值,不同值之间使用逗号隔开</li>
</ul>
</div>
<div id="outline-container-org89e4781" class="outline-4">
<h4 id="org89e4781"><span class="section-number-4">7.1.1</span> RangeAssignor分配策略</h4>
<div class="outline-text-4" id="text-7-1-1">
<ul class="org-ul">
<li>RangeAssignor分配策略的原理:
<ul class="org-ul">
<li>假设n = 分区数/消费者数量</li>
<li>m = 分区数%消费者数量</li>
<li>那么前m个消费者每人分配n+1个分区,后面的消费者每人分配n个分区</li>
<li>比如分区数是10,消费者是3,那么n=3,m=1, 第一个消费者分3+1个,第二个消费者分3个,第三个消费者分3个</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgf9d3e85" class="outline-4">
<h4 id="orgf9d3e85"><span class="section-number-4">7.1.2</span> RoundRobinAssignor分配策略</h4>
<div class="outline-text-4" id="text-7-1-2">
<ul class="org-ul">
<li>原理是将消费组内所有的消费者及消费者订阅的所有主题按照字典序排序,然后通过轮询的方式逐个将分区依
次分配给每个消费者</li>
</ul>
</div>
</div>
<div id="outline-container-orgc2ce938" class="outline-4">
<h4 id="orgc2ce938"><span class="section-number-4">7.1.3</span> StickyAssignor分配策略</h4>
<div class="outline-text-4" id="text-7-1-3">
<ul class="org-ul">
<li>从0.11.x版本开始引入,其目的有两个:
<ul class="org-ul">
<li>分区尽可能的均匀</li>
<li>分区的分配尽可能的和上次分配的保持相同</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgdd72592" class="outline-3">
<h3 id="orgdd72592"><span class="section-number-3">7.2</span> 消费者协调器和组协调器</h3>
<div class="outline-text-3" id="text-7-2">
<ul class="org-ul">
<li>了解了kafka中消费者的分区分配策略后,会有如下的疑问:
<ul class="org-ul">
<li>如果消费者客户端中配置了两个分配策略,那么以哪个为准呢?</li>
<li>如果有多个消费者,彼此所配置的分配策略并不完全相同,那么以哪个为准?</li>
<li>多个消费者之间的分区分配是需要协同的,那么这个协同的过程又是怎样的?</li>
</ul></li>
<li>上面问题的答案就是这一切交由如下两个部分来完成:
<ul class="org-ul">
<li>消费者协调器ConsumerCoordinator</li>
<li>组协调器GroupCoordinator</li>
</ul></li>
</ul>
</div>
<div id="outline-container-org49c2018" class="outline-4">
<h4 id="org49c2018"><span class="section-number-4">7.2.1</span> 旧版消费者客户端的问题</h4>
<div class="outline-text-4" id="text-7-2-1">
<ul class="org-ul">
<li>旧版客户端太过依赖ZooKeeper,容易发生如下问题:
<ul class="org-ul">
<li>羊群效应</li>
<li>脑裂问题</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org61b5d11" class="outline-4">
<h4 id="org61b5d11"><span class="section-number-4">7.2.2</span> 再均衡的原理</h4>
<div class="outline-text-4" id="text-7-2-2">
<ul class="org-ul">
<li>新版本客户端重新进行了设计:
<ul class="org-ul">
<li>将全服的消费组分成了多个子集</li>
<li>每个子集在服务端对应一个GroupCoordinator对其进行管理</li>
<li>消费者中的ConsumerCoordinator组件负责与GroupCoordinator进行交互</li>
</ul></li>
<li>ConsumerCoordinator和GroupCoordinator的最重要职责就是负责执行消费者的再均衡,如下的情况会触发这
个再均衡:
<ul class="org-ul">
<li>有新的消费者加入消费组</li>
<li>有消费者宕机下线,遇到长时间GC没有想GroupCoordinator发送心跳等也被GroupCoordinator认为是下线</li>
<li>有消费者主动提出退出消费组(发送LeaveGroupRequest请求)</li>
<li>消费组对应的GroupCoorinator节点发生变化</li>
</ul></li>
<li>下面是一个例子来讲解当有消费者加入消费组的时候,消费者,消费组和GroupCoordinator会经理以下几个阶段</li>
</ul>
</div>
<ol class="org-ol">
<li><a id="orgcfb0a35"></a>第一阶段FIND_COORDINATOR<br />
<div class="outline-text-5" id="text-7-2-2-1">
<ul class="org-ul">
<li>消费者需要确定,其消费组对应的GroupCoordinator所在的broker</li>
<li>然后与这个broker建立网络连接,如果之前建立过连接,就可以进入第二阶段</li>
<li>否则就要向集群中的某个节点发送FINDCoordinatorRequest来查找对应的GroupCoordinator,这个请求包含
两个field:
<ul class="org-ul">
<li>coordinator_key:其实就是group_id</li>
<li>coordinator_type: 当前都是0</li>
</ul></li>
<li><p>
kafka收到这请求后,会根据coordinator_key(group_id)来查找对应的GroupCoordinator节点,具体查找
方式如下
</p>
<div class="org-src-container">
<pre class="src src-java">Utils.abs(groupId.<span style="color: #d9bb80;">hashCode</span>) % groupMetadataTopicpartitionCount
</pre>
</div></li>
<li>其中groupMetadataTopicpartitionCount就是主题__consumer_offset的分区个数(默认是50)</li>
<li>这样找到对应的__consumer_offset分区之后,在寻找此分区对应的分区leader副本所在的broker节点,该
broker节点即为这个groupId所对应的GroupCoordinator节点</li>
</ul>
</div>
</li>
<li><a id="orgdaa9962"></a>第二阶段JOIN_GROUP<br />
<div class="outline-text-5" id="text-7-2-2-2">
<ul class="org-ul">
<li>在成功找到消费组对应的GroupCoordinator之后,就进入了加入消费组的阶段,在此阶段,消费者会向GroupCoordinator
发送JoinGroupRequest请求,其包含如下field:
<ul class="org-ul">
<li>group_id消费组的id</li>
<li>session_timeout,对应消费端参数session.timeout.ms默认值10000(10秒),GroupCoordinator对超过
session_timeout还没有收到心跳报文的消费者,以下线对待之</li>
<li>rebalance_timeout,对应消费端参数max.poll.interval.ms,默认值五分钟,表示当消费组再平衡的时候,
GroupCoordinator等待各消费者重新加入的最长等待时间</li>
<li>member_id表示GroupCoordinator分配给消费者的id标识</li>
<li>protocol_type表示消费组实现的协议,对于消费者而言这个字段为consumer</li>
</ul></li>
<li>消费者在发送JoinGroupRequest之后,会阻塞等待Kafka服务端的响应.</li>
<li>服务端在收到JoinGroupRequest之后,会交由GroupCoordinator来进行处理,如果是第一次请求,则member_id为
null,那么GroupCoordinator会为这个消费者请求一个member_id</li>
<li>GroupCoordinator还要为消费组内的消费者选出一个leader:
<ul class="org-ul">
<li>如果消费组里面没有leader,那么第一个进入的消费者就是leader</li>
<li>如果原有leader退出了,那么随机选择一个</li>
</ul></li>
<li>每个消费者都会带不同的选举策略,把这些消费者的策略总结开来,投票,最终决定策略是哪个</li>
</ul>
</div>
</li>
<li><a id="org39fb7b9"></a>第三阶段SYNC_GROUP<br />
<div class="outline-text-5" id="text-7-2-2-3">
<ul class="org-ul">
<li>leader消费者根据第二阶段选举出来的分区分配策略来实施具体的分区分配,在此之后要将方案同步给各个
消费者(同步的方式,是各个消费者给GroupCoordinator发送SyncGroupRequest请求同步分配方案)</li>
</ul>
</div>
</li>
<li><a id="org46486b8"></a>第四阶段HEARTBEAT<br />
<div class="outline-text-5" id="text-7-2-2-4">
<ul class="org-ul">
<li>消费者通过向GroupCoordinator发送心跳来维持他们于消费者的从属关系,以及他们对分区的所有权关系</li>
</ul>
</div>
</li>
</ol>
</div>
</div>
<div id="outline-container-org4c644c0" class="outline-3">
<h3 id="org4c644c0"><span class="section-number-3">7.3</span> __consumer_offsets剖析</h3>
<div class="outline-text-3" id="text-7-3">
<ul class="org-ul">
<li>位移提交是消费者客户端中,比较重要的特性.位移提交的内容最终会被保存在kafka内部的主题__consumer_offsets中</li>
<li>一般情况下,当集群中第一次有消费者(集群的第一消费者,每个集群只有一个)消费消息时会自动创建主题
__consumer_offsets</li>
<li>__consumer_offsets的副本因子受到offsets.topic.replication.factor参数的约束,默认值是3</li>
<li>__consumer_offsets的分区数受到offsets.topic.num.partitions参数的约束,默认值是50</li>
<li>客户单端提交消费位移是使用OffsetCommitRequest请求实现的,这里只介绍这个request的几个特殊的field:
<ul class="org-ul">
<li>retention_time表示当前提交的消费位移所能保留的时长(对于消费者而言,这个值始终是-1,也就是按照broker端的
offsets.rentention.minutes来确定保留时长,默认是7天).注意,这个值的默认值曾经不是-1,而是1天,这个
造成过很多问题</li>
</ul></li>
<li>最终提交的消费位移也会以消息的形式(把上面的request解析成消息)发送到主题__consumer_offsets,key,value
如图7-17所示</li>
<li>在处理完消费位移之后,Kafka返回OffsetCommitReponse,如图7-18</li>
<li><p>
我们可以通过kafka-console-consumer.sh脚本来查看__consumer_offsets中的内容,不过要设定formatter参数,如下
</p>
<div class="org-src-container">
<pre class="src src-shell">&gt; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic __consumer_offsets --partition 20 --formatter <span style="color: #87af87;">\</span>
  <span style="color: #87af87;">'kafka.coordinator.group.GroupMetadataManager$OffsetsMessageFormatter'</span>

[consumerGroupId,topic-offsets,30]::[OffsetMetadata[2130,NO_METADATA],Commit TIme 1438843128354,ExpirationTime 1539447928354]
</pre>
</div></li>
<li><p>
使用OffsetsMessageFormatter打印的格式可以概括为
</p>
<pre class="example" id="org4661838">
"[%s,%s,%d]:: [OffsetMetadata[%d,%s],CommitTime %d,ExpirationTime %d]".format(group,topic,partition,offset,metadata,commitTimestamp, expireTimestamp)
</pre></li>
<li><p>
如果某个key(version+group+topic+partition的组合)对应的消费位移过期了,那么对应的value就是null,也
就是墓碑消息,对应的打印结果也会变成如下的形式
</p>
<pre class="example" id="org4c240d8">
" [%s,%s,%d]::null".format(group, topic, partition)
</pre></li>
<li><p>
比如,在有时候查看__consumer_offsets中会有如下的内容,说明这个消费位移已经过期了
</p>
<pre class="example" id="org66ff3be">
[consumerGroupId,topic-offsets,21]::null
</pre></li>
<li>在kafka中,有个名叫delete-expired-group-metadata的定时任务来负责清理过期的消费位移,每十分钟执行一次</li>
<li>还有metadata,一般情况下,它的值要么为null,要么是空字符串(空的时候,OffsetsMessageFormatter会展示位NO_METADATA]</li>
</ul>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: harrifeng@outlook.com</p>
<p class="date">Created: 2021-06-28 Mon 11:43</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
